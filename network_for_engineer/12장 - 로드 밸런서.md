# 12 로드 밸런서



[toc]



# 12.1 부하 분산이란?

단일 서버를 구성하거나, 서버를 이중화해 서비스 호출을 분리한 경우 서버 장애에 따라 서비스 장애가 발생한다.

<img src="./images/12장 - 로드 밸런서//image-20230819225801834.png" width = 600 hegiht = 450>

이런 문제점을 해결하기 위해 L4 or L7 스위치(로드밸런서)를 사용한다.

로드밸런서는 동일한 서비스를 하는 다수의 서버를 등록하고 사용자별로 다수의 서버로 요청을 분산시킨다.

로드밸런서에는 가상 IP (Virtual IP)를 하나 제공하고, 사용자는 가상 IP로만 접근한다.

<img src="./images/12장 - 로드 밸런서//image-20230819225921931.png" width = 600 height = 450>

> FWLB
>
> 서버 뿐만 아니라 방화벽도 로드밸런서를 사용한다
>
> \-SLB (Server Load Banalncing) : 서버 부하 분산
>
> \-FWLB(FireWall Load Balancing) : 방화벽 부하 분산
>
>
> 방화벽을 이중화 할 경우, 개인의 세션 테이블에 패킷 정보 없을시 패기하여 문제가 발생할 수 있는데,
> FWLB가 세션을 인식하고 특정 알고리즘을 이용하여 한번 방화벽을 지나갔던 세션이 다시 같은곳을 거치도록 트래픽을 분산하는것을 도와준다. 

# 12.2 부하 분산 방법

로드밸런서에는 서비스를 제공하는 서버의 진짜 IP인 Real IP와 로드밸런서에서 대표하는 VIP가 있다.

* 장비가 여러대인데 사용자는 여러 IP에 요청을 보내기 어려우므로, 한곳의 가상 IP에 집중한다

로드밸런서를 L4 스위치라고도 한다.  

왜냐하면 로드 밸런서에서 부하 분산을 위한 그룹을 만들 때는OST 3계층 정보인 IP 주소뿐 만 아니라 4계층 정보인 서비스 포트까지 지정해 만든다.

L4스위치가 여기서 이용하는 정보는 

1. 3계층의 IP 주소를 이용하여 각 서버의 IP 주소를 이용해 트래픽을 여러 서버로 분산시킨다.
2. 4계층 전송 계층의 서비스 포트를 이용하는데, TCP 또는 UDP 포트는 특정 서비스나 어플리케이션이 사용하는 포트 정보를 이용해 해당 서비스에 대한 트래픽을 적절한 서버로 라우팅한다.

> 즉 전송 프로토콜, IP주소, MAc주소 포트번호에 따라 부하 분산

 7계층 정보까지 확인해 처리하는 기능이 포함되는 경우도 있어 L7 스위치라고도 하지 만 보통 로드 밸런서를 L4 스위치라고 부른다. 

L7 스위치가 여기서 이용하는 정보는 (콘텐츠 기반 스위치라고 부른다)

1. **HTTP/HTTPS 헤더**: 사용자 에이전트, 쿠키, 참조자 등의 HTTP 헤더를 기반으로 트래픽을 라우팅
2. **URL 경로**: 요청된 URL의 특정 경로나 패턴에 기반하여 트래픽을 라우팅
3. **쿠키**: 사용자 세션 또는 기타 쿠키 정보를 통해 트래픽을 특정 서버로 유도
4. **요청 메서드**: HTTP 요청 메서드 (예: GET, POST, PUT 등)에 기반하여 트래픽을 분산
5. **호스트명**: HTTP 요청의 호스트 헤더를 사용하여 트래픽을 특정 서버로 라우팅
6. **컨텐츠 유형**: 요청 또는 응답의 컨텐츠 유형 (예: JSON, XML 등)을 기반으로 트래픽을 라우팅
7. **쿼리 문자열**: URL의 쿼리 문자열을 기반으로 트래픽을 분산
8. **SSL/TLS 정보**: 클라이언트 인증서나 기타 SSL/TLS 정보를 기반으로 트래픽을 라우팅



즉, L4 스위치랑 L7 스위치는 각각의 특성과 사용사례에 따라 다르다.

### L4 로드밸런서 (계층 4 - 전송 계층, 전송계층 스위치)

- **작동 계층**: OSI 모델의 4계층인 전송 계층에서 작동
- **라우팅 기준**: IP 주소와 TCP/UDP 포트, 맥주소, 프로토콜을 기반으로 트래픽을 라우팅합니다.
- **처리 속도**: L7에 비해 단순한 라우팅 로직을 사용하므로 일반적으로 더 빠르다
- **용도**: 애플리케이션의 로직과 무관하게 트래픽을 분산하는 경우에 적합.
- **세션 지속성**: 일반적으로 IP 주소를 기반.
- **장점**
  - ﻿﻿패킷의 헤더가 아닌 내용을 확인하지 않고 로드를 분산하므로 속도가 빠르고 효율이 높음.
  - ﻿﻿데이터의 내용을 복호화할 필요가 없기에 안전.
  - ﻿﻿L7 로드밸런서보다 가격이 저렴.
- **단점**
  - ﻿﻿패킷의 내용을 살펴볼 수 없으므로, 섬세한 라우팅 불가.
  - ﻿﻿사용자의 IP가 수시로 바뀌는 경우라면, 연속적인 서비스를 제공하기 어려움.

### L7 로드밸런서 (계층 7 - 응용 계층, 콘텐츠 기반 스위치)

- **작동 계층**: OSI 모델의 7계층인 응용 계층에서 작동
- **라우팅 기준**: 애플리케이션 계층 프로토콜, HTTP/HTTPS 헤더, URL 경로, 쿠키, 요청 메서드 등 애플리케이션 수준의 정보를 기반으로 트래픽을 라우팅
  - /api/image -> 이미지 처리 서버, /api/payment -> 결제 처리 서버  
  - 이미지 파일에 대해서는 확장자를 참조하여, 별도로 구성된 이미지 파일이 있는 서버 아 스 토리지로 직접 연결도 가능
- **처리 속도**: 더 복잡한 라우팅 로직을 사용하므로 L4에 비해 일반적으로 느릴 수 있다
- **용도**: 콘텐츠 기반 라우팅이 필요한 복잡한 분산 시나리오에 적합
- **세션 지속성**: 쿠키나 세션 정보를 기반으로 한다. 

* **장점**

  - ﻿﻿상위 계층에서 로드를 분산하기 때문에 훨씬 더 섬세한 라우팅 가능.

  - ﻿﻿캐싱(Cashing) 기능을 제공.

  - ﻿﻿비정상적인 트래픽을 사전에 필터링할 수 있어 서비스 안정성 높음.

* **단점** 

  - ﻿﻿L4 로드밸런서에 비해 비쌈.

  - ﻿패킷의 내용을 복호화하여야 하므로 더 높은 비용을 지불해야 함.

  - ﻿﻿클라이언트가 로드밸런서와 인증서를 공유해야 하기 때문에, 공격자가 로드밸런서를 통해 클라이언트의 데이터에 접근할 수 있는 보안상의 위험성 존재.



L4 Load Balancer는 단지 부하를 분산시키는 것이라면, L7 Load Balancer는 요청의 세부적인 사항을 두고 결제만 담당하는 서버, 회원가입만을 담당하는 서버 등으로 분리해서 가볍고 작은 단위로 여러 개의 서비스를 운영하고 요청을 각각의 서버에 분산할 수 있다.

## AWS 로드밸런서 종류 

### CLB (Classic Load Balancer)

Layer4, Layer7 부하 분산

listen : TCP, SSL/TLS, HTTP, HTTPS 

현재는 거의 사용되지 않음.

 

### ALB (Application Load Balancer)

Layer7 부하 분산

listen : HTTP, HTTPS, gRPC

target : IP, Instance, Lambda

레이어 7에서 작동하는 응용 프로그램 중심의 로드 밸런서로, HTTP, HTTPS, gRPC 등의 프로토콜을 지원하며 가장 일반적으로 사용

 

### NLB (Network Load Balancer)

Layer4 부하 분산

listen : TCP, UDP, TLS

target : IP, Instance

레이어 4에서 작동하는 네트워크 중심의 로드 밸런서로, TCP, UDP, TLS 프로토콜을 지원하며 높은 성능을 자랑한다.

 

### GLB (Gateway Load Balancer)

Layer3, Layer4 부하 분산

listen : IP

target : IP, Instance

레이어 3과 레이어 4에서 작동하는 게이트웨이 형태의 로드 밸런서로, IP 프로토콜을 주로 지원한다.

# 12.3 헬스 체크

헬스 체크(Health Check)는 컴퓨터 시스템, 네트워크 장치, 서비스, 어플리케이션 등의 작동 상태를 주기적으로 검사하는 과정이다. 

헬스 체크의 목적은 시스템의 정상 작동을 확인하고, 문제가 발생한 경우 이를 신속하게 탐지하여 적절한 조치를 취하는 것이다.



또한 로드밸런서에서 부하 분산을 하는 각 서버에 주기적으로 헬스체크를 하여, 비정상 서버에는 서비스 그룹에서 제외해 트래픽을 보내지 않아서 정상적인 서비스가 가능하도록 유도한다.

서비스 그룹에서 제외되더라도, 헬스 체크를 계속 수행하여 다시 정상적으로 확인되면 다시 서비스 그룹에 넣어서 트래픽을 전송할 수 있도록 도와준다. 

## 헬스 체크 방식

### ICMP - (Internet Control Message Protocol) 패킷

* ICMP는 IP 레벨에서 작동하며, 주로 네트워크 문제 진단과 보고, 라우팅 디버깅 등에 활용

VIP에 연결된 리얼 서버에 대해 ICMP(ping)로 헬스 체크를 수행하는 방법이다 

단순히 서버가 살아 있는지 여부만 체크하는 방법이므로 잘 사용하지 않는다

### TCP 서비스 포트

가장 기본적인 헬스 체크 방법은 로드 밸런서에 설정된 서버의 서비스 포트를 확인하는 것이다.

서버의 리얼 IP 서비스포트(was라면 8080)로 SYN 보내고, SYN, ACK를 받으면 ACK로 응답하고 FIN을 보내 헬스 체크를 종료한다. 

### TCP 서비스 포트: Half Open

TCP 로 헬스 체크할 시, 3way-handsahke 때문에 부하가 생길 수 있어, 정상적인 방식 대신 절반만 이용한다

* SYN를 보내고, SYN, ACK 받고 ACK 대신 RST 보내 세션을 끊는다 

### HTTP 상태 코드

포트는 정상적으로 열렸어도, 서버에 에러가 있을 수 있다. (400, 500, 502 등)

때문에 200 OK를 이용해 헬스 체크를 수행한다.

<img src="./images/12장 - 로드 밸런서//image-20230819232414884.png" width = 500>

### 콘텐츠 확인(문자열 확인)

로드밸런서에서 콘텐츠를 요청하고 응답을 확인하여 정상 응답인지 확인하는 헬스 체크 방법도 있다.

## 헬스 체크 주기와 타이머

헬스 체크 주기에 대해 다음과 같은 내용들을 고려하자. 

- ﻿﻿주기(Interval) : 로드 밸런서에서 서버로 헬스 체크 패킷을 보내는 주기
- ﻿﻿응답 시간(Response) : 로드 밸런서에서 서버로 헬스 체크 패킷을 보내고 응답을 기다리는 시간. 해당 시간까지 응답이 오지 않으면 실패로 간주
- ﻿﻿시도 횟수(Retries) : 로드 밸런서에서 헬스 체크 실패 시 최대 시도 횟수. 최대 시도 횟수 이전에 성공 시 시도 횟수는 초기화됨
- ﻿﻿타임아웃(Timeout) : 로드 밸런서에서 헬스 체크 실패 시 최대 대기 시간. 헬스 체크 패킷을 서버로 전송한 후 이 시간 내에 성공하지 못하면 해당 서버는 다운
- ﻿﻿서비스 다운 시의 주기(Dead Interval) : 서비스의 기본적인 헬스 체크 주기가 아닌, 서비스 다운 시의 헬스 체크 주기 서비스가 죽은 상태에서 헬스 체크 주기를 별도로 더 늘릴 때 사

# 12.4 부하 분산 알고리즘

로드 밸런서가 리얼 서버로 부하를 분산할 때, 로드 밸런서에서는 사전에 설정한 분산 알고리즘을 통해 부하 분산이 이루어진다.

| **알고리즘**                                               | **설명**                                                     |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| **라운드 로빈 (Round Robin)**                              | 현재 구성된 장비에 부하를 순차적으로 분산함. 총 누적 세션 수는 동일하지만 활성화 된 세션 수는 달라질 수 있음. |
| **최소 접속 방식 (Least Connection)**                      | 현재 구성된 장비 중 가장 활성화된 세션 수가 적은 장비로 부하를 분산함. |
| **가중치 기반 라운드 로빈 (Weighted Round Robin)**         | 라운드 로빈 방식과 동일하지만 각 장비에 가중치를 두어 가중치가 높은 장비에 부하를 더 많이 분산함. 처리 용량이 다른 서버에 부하를 분산하기 위한 분산 알고리즘. |
| **가중치 기반 최소 접속 방식 (Weighted Least Connection)** | 최소 접속 방식과 동일하지만 각 장비에 가중치를 부여해 가중치가 높은 장비에 부하를 더 많이 분산함. 처리 용량이 다른 서버에 부하를 분산하기 위한 분산 알고리즘. |
| **해시 (Hash)**                                            | 해시 알고리즘을 이용한 부하 분산.                            |

이외에도 다양한 알고리즘이 있긴 있따.

1. **IP 해시 (IP Hashing)**: 클라이언트의 IP 주소를 해싱하여 일관된 방식으로 특정 서버로 요청을 라우팅합니다. 이 방법은 동일한 클라이언트로부터 오는 요청이 항상 동일한 서버로 전달되도록 합니다.
2. **URL 해시 (URL Hashing)**: 요청의 URL을 해싱하여 해당 해시 값에 기반한 서버로 요청을 라우팅합니다. 이 방식은 특정 URL 패턴을 가진 요청이 항상 같은 서버로 라우팅되도록 할 수 있습니다.
3. **소스 IP 대상 (Source IP Affinity)**: 클라이언트의 IP 주소를 기반으로 요청을 처리하는 서버를 결정합니다. 이는 세션 지속성을 유지하는 데 유용할 수 있습니다.
4. **고정 경로 (Fixed Routing)**: 모든 요청을 하나의 서버 또는 서버 그룹으로 라우팅합니다. 특수한 목적이나 일시적인 상황에서 사용될 수 있습니다.
5. **랜덤 (Random)**: 각 요청을 무작위로 선택된 서버로 라우팅합니다. 이는 서버 간에 균일한 분산을 제공하지만, 세션 지속성을 유지하지 못할 수도 있습니다.
6. **QoS 기반 라우팅 (QoS-based Routing)**: 서버의 현재 처리 용량, 대기 시간, 처리 속도 등과 같은 품질 보증(QoS) 지표를 기반으로 요청을 라우팅합니다.
7. **지리적 위치 기반 (Geographic Location-based)**: 클라이언트의 지리적 위치에 가장 가까운 서버로 요청을 라우팅합니다. 이는 응답 시간을 줄이고 지역화된 콘텐츠를 제공하는 데 유용합니다.
8. **세션 지속성 (Session Persistence)**: 클라이언트 세션을 유지하면서 요청을 라우팅하는 방식입니다. 쿠키나 세션 정보를 활용하여 동일한 클라이언트의 요청을 동일한 서버로 전달할 수 있습니다.
9. **우선 순위 큐 (Priority Queueing)**: 요청의 중요도나 우선 순위를 기반으로 서버로 라우팅합니다.

### 라운드 로빈

라운드 로빈 방식은 특별한 규칙 없이 현재 구성된 장비에 순차적으로 돌아가면서 트래픽을 분산한다.

순차적으로 모든 장비에 분산하므로, `모든 장비의 총 누적 세션 수는 같아진다.`

#### 장점:

- **간단하고 예측 가능**: 라운드 로빈은 순차적으로 요청을 서버에 할당하기 때문에 구현이 간단하고 동작이 예측 가능하다
- **공평한 분산**: 모든 서버가 동일한 기회로 요청을 받으므로 특정 서버에 집중되는 현상을 방지한다.

#### 단점:

- **불균형한 서버 부하**: 서버의 성능이나 처리 용량이 다르면 불균형한 부하가 발생할 수 있다.
- **상태 기반 세션 부족**: 클라이언트의 이전 요청 상태를 기억하지 않으므로 세션 지속성을 유지하는 데 어려움이 있을 수 있다.

### 최소 접속 방식 (Least Connection)

서버가 가진 세션 테이블로 부하를 확인해 세션이 가장 적었던 장비로 부하를 분산시킨다. 

서비스별로 세션 수 를 관리하면서 분산해주므로 각 장비에서 처리되는 활성화 세션 수가 비슷하게 분산되면서 부하 를 분산하게된다.

<img src="./images/12장 - 로드 밸런서//image-20230819233248234.png" width = 700 height = 300>

**장점:**

- **부하 균형**: 현재 활성화된 연결 수가 가장 적은 서버에 요청을 분산하므로, 서버 간 부하 균형을 더 잘 유지할 수 있다.
- **동적 부하 조정**: 서버의 실시간 부하를 고려하기 때문에 동적인 환경에서 더 유연하게 대응할 수 있다.

#### 단점:

- **더 복잡한 로직**: 현재 활성 연결 수를 추적하고 관리해야 하므로 라운드 로빈보다 구현이 복잡할 수 있다.
- **오버헤드**: 연결 상태를 지속적으로 모니터링해야 하므로 추가 오버헤드가 발생할 수 있다.

### 해시 (hash)

해시 방식은 서버의 부하를 고려하지 않고 클라이언트가 같은 서버에 지속적으로 접속하도록 하 기 위해 사용하는 부하 분산 방식

서버 상태는 고려하지 않고 해시 알고리즘을 이용해 얻은 값으로 해당 장비로 부하를 분산한다.

이때 알고리즘 계산에 사용되는 값들을 지정할 수 있는데 주로 출발지 IP 주소, 목적 지 IP 주소, 출발지 서비스 포트. 목적지 서비스 포트를 사용한다.

- **즉 세션을 유지해야 하는 서비스에 유리하다**

#### 장점:

- **세션 지속성**: 클라이언트의 IP 주소나 URL과 같은 특정 값에 대해 해시를 사용하면 동일한 클라이언트 요청을 동일한 서버로 라우팅할 수 있으므로 세션 지속성을 제공한다.
- **분산의 일관성**: 동일한 해시 값은 동일한 서버를 가리키므로 요청 분산이 일관된다.

#### 단점:

- **불균형한 분산 가능성**: 해시 충돌이나 특정 해시 값의 과다 집중 등으로 인해 일부 서버에 부하가 불균형하게 분산될 수 있다.
- **복잡한 관리**: 서버 구성이 변경될 때 해시 매핑을 업데이트하고 관리해야 하는 복잡성이 증가할 수 있다.



해시 + 최소 접속 방식 을 이용해서 부하를 분산하는 방법도 있다.

# 12.5 로드 밸런서 구성 방식

로드밸런서 구성 방식은 구성 위치에 따라 2가지로 나눌 수 있다.

- ﻿﻿원암(One-Arm) 구성
- ﻿﻿인라인(Inline) 구성

<img src="./images/12장 - 로드 밸런서//image-20230819233625661.png" width = 800 height = 450>

원암과 인라인의 구분은 서버로 가는 트래픽이 모두 로드 밸런서를 경유하는지, 않아도 되는지에 대한 트래픽 흐름으로 구분한다.

반면, 인라인 구성은 부하 분산을 포함한 모든 트래픽이 로드 밸런 서를 경유하는 구성이된다. 

## 원암(One-Arm 구성)

로드 밸런서의 원암(One-Arm) 구성은 로드 밸런서가 스위치 옆에 있는 형태

원암 구성에서는 서버로 들어가거나 나오는 트래픽이 로드 밸런서를 경유하거나 경유하지 않을 수 있다. 

트래픽이 로드 밸런서를 경유하는지 여부는 부하 분산을 이용한 트래픽인지 여부로 구분할 수 있다.



**부하분산을 이용하는 트래픽의 경우**

부하 분산에 사용되는 서비스 IP를 로드 밸런서가 가지고 있어서 서버로 유입되는 트래픽은 로드밸런서를 거친다.

**부하분산을 이용하지 않는 트래픽의 경우**

필요 없는 경우 그냥 로드 밸런서 이용 안하고 바로 스위치 지나서 서버로 간다. 



원암 구성에서는 로드 밸런서를 이용하는 서비스에 대해서만 로드 밸런서를 경유하므로 불필요한 트래픽이 로드 밸런서에 유입되지 않아 로드 밸런서 부하를 줄일 수 있다. 

## 인라인 구성

로드 밸런서의 인라인 구성은 용어 그대로 그림 12-25처럼 로드 밸런서가 스위치에서 서버까지 가는 일직선상 경로에 있는 형태



모든 트래픽이 로드밸런서의 서비스를 받는지 여부 상관 없이 로드 밸런스를 통과한다.

구성이 직관적이지만, 모든 요청이 로드밸런서를 통과하므로 부하가 높아진다.

* 특히 로드밸런서는 L3장비보다 처리 용량이 적고, 높은 처리 용량을 구매하려면 가격이 비싸지므로 잘 고려해야 한다 .

 인라인으로 로드 밸런서를 선정할 때 로드 밸런싱 성능과 패킷 스루풋 성능을 구별해 디자인해야 한다. 

* **패킷 스루풋 성능**: 패킷 스루풋은 로드 밸런서가 단위 시간당 얼마나 많은 데이터 패킷을 처리할 수 있는지를 나타내는 측정치



> 물리적으로는 원암을 구성하고, 논리적으로는 인라인을 구성하는 경우도 있다.
>
> 가상화를 사용하여 논리적으로 장비를 분리할 수 있기 때문이다
>
> 그러므로 물리적 구성만 보고 원암과 인라인 구성을 구분하면 안됀다

# 12.6 로드 밸런서 동작 모드

로드 밸런서 동작 모드에 따라 패킷 통신 방식도 달라지므로 로드 밸런서 동작 모드의 이해는 로드 밸런서의 운용 및 장애조치를 위해서도 매우 중요하다.

- ﻿﻿트랜스패런트(Transparent: TP) 또는 브릿지(Bridge)
- ﻿﻿라우티드(Routed)
- ﻿﻿DSR(Direct Server Return)

## 트랜스 패런트 모드 (투명 모드)

트랜스패런트(Transparent: 투명) 구성은 로드 밸런서가 OSI 2계층 스위치처럼 동작하는 구성

로드 밸런서에서 서비스하기 위해 사용하는 VIP 주소와 실제 서버가 동일한 네트워크를 사용하는 구성이다. 

*  기존에 사용하던 네트워크 대역을 그대로 사용하므로 로드 밸런서 도입으로 인한 IP 네트워크 재설계를 고려하지 않아도 된다
* 네트워크에 L2 스위치를 추가하는 것과 동일하게 기준 망의 트래픽 흐름에 미치는 영향 없이 로드 밸런서를 손쉽게 구성할 수 있다
* 트래픽이 로드 밸런서를 지나더라도 부하 분산 서비스를 받는 트래픽인 경우에만 4계층 이상의 기능을 수행하며 부하 분산 서비스가 아닌 경우에는 기존 L2 스위치와 동일한 스위칭 기능만 수행한다

<img src="./images/12장 - 로드 밸런서//image-20230819235326384.png" width = 800 height = 350>

트랜스패런트 모드는원암과 인라인 구 성에서 모두 사용할 수 있는 동작 모드 이지만 원암 구성에서는 응답 트래픽 경로 부분이 문 제가 될 수 있어 Source NAT가 필요하다.

* Source NAT (SNAT, Source Network Address Translation)는 네트워크 주소 변환의 한 형태로, 패킷이 네트워크를 떠날 때 출발지 IP 주소를 변경하는 과정
*  사설 네트워크에서 공인 네트워크로 트래픽을 전송할 때 주로 사용된다.

### **트랜스패런트 모드에서 부하 분산 트래픽이 흐르는 방법**

<img src="./images/12장 - 로드 밸런서//image-20230819235503664.png" width = 700 height = 350>

**사용자가 요청하는 과정**

* 로드밸런서로 들어온 패킷의 `목적지 IP주소`와 `목적지 MAC 주소`가 실제 RealIP 서버로 변경된다.
  * 로드밸런서와 목적지 Real IP 서버랑 동일한 네트워크 대역이므로 출발지 MAC 주소는 바뀌지 않는다.
* 이것을 로드 밸런서에서 서비스를 위한 VIP 주소가 실제 서버 의 IP 주소로 변경해 전송하므로 목적지(Destination) NAT가 되었다고 한다.

**사용자가 응답받는 과정**

<img src="./images/12장 - 로드 밸런서//image-20230819235929853.png" width = 700 height = 350>

* 출발지의 IP주소는 실제 서버의 IP에서 로드밸런서의 VIP 주소로 변경되고, 목적지 MAC 주소는 변경되지 않는다
  * 목적지 MAC 주소가 이미 게이트웨이의 MAC 주소를 갖고 있기 때문
* L3 스위치에서 클라이언트로 응답한다. 

트랜스패런트 모드에서 주의할점은, 원암 구성인 경우 서비스에 문제가 발생할 수 있다.

로드 밸런서를 다시 거쳐야 도착 주소가 역변환 되어 잘 도착할 수 있기 때문이다.

## 라우티드 모드

로드 밸런서가 라우팅 역할을 수행하는 모드

즉, 로드 밸런서를 기준으로 사용자 방향(Client Side)과 서버 방향(Server Side)이 서로 다른 네트워크로 분리된 구성에서 사용된다.

<img src="./images/12장 - 로드 밸런서//image-20230820000218113.png" width = 700 height = 350> 

* 라우티드 모드는 보안 강화 목적으로 서버쪽 네트워크를 사설로 구성해 서버에 직접 접속하는 것을 막는 용도로 사용되기도 한다

### 라우티드 모드에서 부하 분산 트래픽이 흐르는 과정

**사용자가 요청하는 과정**

* 로드밸런서로 들어온 패킷의 목적지 IP 주소를 VIP에 바인딩된 실제 서버 RealIP로 변경하고, 출발지의 목적지의 주소도 변경한다.

**사용자가 응답받는 과정**

* 서버에서 응답하면 출발지는 서버 IP주소, 목적지는 사용자 IP주소이다.
* 다만, 목적지 IP가 외부 네트워크 이므로 목적지 MAC은 게이트웨이(외부로 나가는 로드밸런서)의 MAC주소가 된다.
* 후에 출발지 IP주소를 서버 IP에서 로드밸런서 VIP로 변경하고, 맥주소도 로드밸런서로 변경 한 후 응답한다.

## DSR 모드 (Direct Server Return)

DSR(Direct Server Return)은 사용자의 요청이 로드 밸런서를 통해 서버로 유입된 후에 다시 로드 밸런서를 통하지 않고 서버가 사용자에게 직접 응답하는 모드

로드밸런서는 요청 트래픽만 관여하고 응답 트래픽에는 관여하지 않는다.

* DSR 모드는 응답할 때. 로드 밸런서를 경유하지 않으므로 원암으로 구성한다.

DSR 모드에서는 요청 트래픽만 로드 밸런서를 통해 흐르므로 로드 밸런서 전체 트래픽이 감소해 로드 밸런서 부하가 감소한다. 

특히 일반적인 서비스 트래픽인 경우, 요청 패킷보다 응답 패킷의 크기가 더 크기 때문에 로드 밸런서의 트래픽 부하 감소에 효과적이다.

* 그러나 응답이 로드밸런서를 거치지 않으므로, 문제 발생하면 대응하기 어렵다.
* 또한 Source NAT(패킷 IP변경)을 수행할 수 없다. (거치지 않으니까)

출발지 IP가 서버의 인터페이스 IP 주소가 아닌 루프백 인터페이스의 IP 주소, 즉 사용자가 요청했던 VIP 주소로 설정해 패킷을 전송한다.

# 12.7 로드 밸런서 유의사항

## 원암 구성의 동일 네트워크 사용시 패킷 폐기 문제

원암 구성은 로드 밸런서를 이용하는 서비스에 대해서만 로드 밸런서를 경유하므로 불필요한 트래픽이 로드 밸런서에 유입되지 않아 로드 밸런서의 부하와 장애 범위를 줄일 수 있는 구성

<img src="./images/12장 - 로드 밸런서//image-20230820000906633.png" width = 700 height = 400>

원암 구성은 요청은 로드밸런서를 통과했을 떄 응답은 로드밸런서를 통과하지 않을 수 있으므로

요청과 응답의 경로가 달라, 사용자가 예상하지 않은 IP 주소로부터 응답을 받게 되는 상황이 있을 수 있다.

* 사용자는 10.10 으로 요청 -> 실제 서버인 10.11 IP가 패킷 받음 -> 사용자가 응답 패킷을 받지만 요청한 주소는 10.10인데 응답온 주소가 10.11 이므로 사용자 측에서 패킷을 폐기해버릴수도 있음.  

### 해결방법 1. 게이트웨이를 로드밸런서로 설정

로드 밸 런서를 통해 부하 분산이 이루어지는 실제 서버에 대해서는 게이트웨이를 로드 밸런서로 설정하 면 로컬 네트워크가 아닌 외부 사용자의 호출에 대한 응답이 항상 로드 밸런서를 통하므로 정상적으로 응답할 수 있다.

### 2. Source NAT 사용

사용자의 서비스 요청에 대해 로드 밸런서가 실제 서버로 가기 위해 수행하는 Destination NAT

뿐만 아니라 출발지 IP 주소를 로드 밸런서가 가진 IP로 함께 변경해버린다 .

그러면 사용자측에서 요청 / 응답이 같은곳에서 왔으므로 패킷을 폐기하지 않는다

이러면, 서비스를 호출할 때와 응답할 때 모두 Source/Destination NAT(Source NET, DNAT) 를 함께 수행하게된다

이 경우, 서버 애플리케이션 입장에서 보면 서비스를 호출한 IP가 하나의 동일한 IP로 보이기 때문에 사용자 구분이 어렵다는 문제가 있는데, 웹 서비스는 이런 문제를 해결하기 위해 HTTP 헤더의 X-Forwarded-For(XFF)를 사용해 실제 사용자 IP를 확인하는 방법을 사용하여 해결한다.

* `X-Forwarded-For` (XFF) 헤더는 HTTP 요청 헤더의 일종으로, 클라이언트의 IP 주소, 프록시 및 로드 밸런서를 거친 요청의 경로에 대한 정보를 포함한다.
* 이 정보는 클라이언트의 실제 위치를 추적하거나 로깅, 분석, 보안 등의 다양한 목적으로 사용한다.
* 그러나 이 헤더 값을 조작할 수 있으므로 무조건 신뢰하지 않는것이 좋다 

### 3. DSR 모드 사용하여 해결

DSR 모드는 사용자의 서비스 요청 트래픽에 대해 별도의 Destination NAT를 수행 하지 않고 실제 서버로 서비스 요청 패킷을 전송하는데, 서버의 IP 정보로 응답할 때, 루프백에 설정된 서비스 IP 주소를 출발지로 응답하므로 동일 요청 / 응답 IP 니까 문제를 해결할 수 있다.

## 두번째 주의사항 - 동일 네트워크 내에서 서비스 IP (VIP) 호출

동일한 네트워크 내에서 서버1, 서버2 간 Real 서비스 호출시 요청받은 서버에서 응답할 때 동일 네트워크이므로 로드밸런서를 거치지 않아서 요청/응답 IP가 달라 요청 서버에서 패킷이 폐기되는문제 

이 문제 해결 방법도 비슷하다.

서비스 요청이 로드 밸 런서를 거칠 때, 출발지 IP 주소를 로드 밸런서의 IP로 변경하는 Source NAT 방법을 사용하거나 DSR 모드를 사용해 실제 서버에서 로드 밸런서를 거치지 않고 직접 응답하면 된다.



> 결국 로드밸런서를 이용할 때의 주의사항은, 패킷 헤더에서 요청 IP와 응답 IP가 달라 응답받은 곳에서 패킷을 폐기해버리는 문제를 잘 대응해야 한다.

