# 개발자를 위한 레디스

# 목차
1. [마이크로서비스 아키텍처와 레디스](#1-마이크로서비스-아키텍처와-레디스)
2. [레디스 시작하기](#2-레디스-시작하기)
3. [레디스 기본 개념](#3-레디스-기본-개념)
4. [레디스 자료 구조 활용 사례](#4-레디스-자료-구조-활용-사례)
5. [레디스를 캐시로 사용하기](#5-레디스를-캐시로-사용하기)
6. [레디스를 메시지 브로커로 사용하기](#6-레디스를-메시지-브로커로-사용하기)
7. [레디스 데이터 백업 방법](#7-레디스-데이터-백업-방법)
8. [복제](#8-복제)
9. [센티널](#9-센티널)
10. [클러스터](#10-클러스터)
11. [보안](#11-보안)
12. [클라이언트 관리](#12-클라이언트-관리)
13. [레디스 운영하기](#13-레디스-운영하기)



레디스를 캐시 및 세션 스토어, 메시지 브로커, 영구 저장으로 사용이 가능하다.



## 레디스란?

### 레디스의 특징

### 

<img src="./images//image-20240501235124364.png" width = 400>

메인 스레드 1개와 별도의 스레드 3개, 총 4개의 스레드로 동작한다. 하지만 클라이언트의 커맨드를 처리하는 부분은 그림

1-12와 같이 이벤트 루프를 이용한 싱글 스레드로 동작한다. 최소 하나의 코어만 있 어도 레디스를 사용할 수 있어 배포가 쉬우며, CPU가 적은 서버에서도 좋은 성능을 낼 수 있다. 또한 멀티스레드 애플리케이션에서 요구되는 동기화나 잠금 메커니즘 없 이도 안정적이고 빠르게 사용자의 요청을 처리할 수 있다.

# 2. 레디스 시작하기


## 레디스 환경 구성
### 서버 환경 설정 변경



#### maxclients

레디스의 기본 maxclients 설정값은 10000이며, 최대 연결 클라이언트 개수를 의미한다.

이 값은 레디스를 실행하는 서버의 file discriptor수의 영향을 받으며, 

레디스 프로세스 내부적으로 사용하기 위해 예약한 파일 디스크립터 수는 32개로, maxclients + 32보다 최대 파일 디스크립터 수가 작으면 레디스 실행시 자동으로 그 수에 맞게 조정된다.

현재 서버의 파일 디스크립터 수

```
ulimit -a | grep open
```

위 값이 10032보다 작다면 다음 구문 추가

```
vi /etc/security/limits.conf

* hard nofile 100000

* soft nofile 100000
```

#### THP 비활성화.

레디스같은 DB는 THP가 오히려 레이턴시가 올라가므로 사용하지 않는것이 좋다

THP 비활성화

```
# 일시적으로 비활성화
echo never > /sys/kernal/mm/transparent_hugepage/enabled

## 영구적 비활성화
vi /etc/rc.local

if test -f /sys/kernel/mm/transparent_hugepage/enabled; then
    echo never > /sys/kernel/mm/transparent_hugepage/enabled
fi

# 이후 부팅 중 rc.local 파일 실행
chmod +x /etc/rc.d/rc.local
```



#### vm.overcommit_memory = 1로 변경 - fork() 백그라운드 방지

레디스는 디스크에 파일을 저장할떄 fork()해서 백그라운드 프로세스를 만드는데, 이때 메모리 사용량이 급격히 증가할 수 있다.

메모리를 초과해 할당해야 하는 상황이 생길때 vm.overcommit_memory = 1로 설정해두면 운영체제가 초과 할당을 허용해준다.

* 디폴트는 0이다

```
vi /etc/sysctl.conf
에 vm.overcommit_memory=1 추가

또는 아래 명령어를 바로 터미널에서 입력

sysctl vm.overcommit_memory=1
```



#### somaxconn과 syn_backlog 설정 변경

tcp-backlog 파라미터는 레디스 인스턴스가 클라이언트와 통신할때 사용하는 tcp backlog 큐의 크기를 지정한다.

* 이때 redis.conf에서 지정한 tcp-backlog값은 서버의 socket max connection과 syn_backlog 값보다 클 수 없다

서버 설정이 511보다 크도록 설정해야 한다. 

서버의 현재 설정값은 다음 커맨드로 확인할 수 있다.

```
$ sysctl -a | grep syn backlog
net.ipv4.tcp_max_syn_backlog = 128

$ sysctl -a | grep somaxconn
net.core.somaxconn = 128
```



/etc/sysctl.conf 파일에 다음 구문을 추가하면 영구적으로 해당 설정을 적용할 수 있다.

```
net.ipv4.tcp_max_syn_backlog = 1024

net.core.somaxconn = 1024
```



재부팅 없이 바로 설정을 적용하려면 다음 커맨드를 수행하자.

```
sysctl net.ipv4.tcp_max_syn_backlog=1024

sysctl net.core.somaxconn=1024
```



### 레디스 설정 파일 변경

#### bind

기본값 : 127.0.0.1:1

해당 값을 0.0.0.0로 설정하면 레디스는 모든 ip로 들어오는 연결을 허용함을 뜻하며, 만약 레디스가 인터넷에 노출돼 있는 경우 이렇게 설 정하는 것은 보안상 위험할 수 있으니, 서비스 운영 목적으로 사용하는 서버라면 항상 특정한 값을 지정해주는 것이 좋다.

#### requirepass / masterauth

기본값: 없음

requirepass 파라미터는 서버에 접속하기 위한 패스워드 값을 의미한다. 

masterauth 파라미터는 복제 구조를 사용할 때 필요한데, 연결될 마스터의 패스워드 값을 의미 한다. 

만약 복제 연결을 사용할 예정이라면 이 두 값은 같은 값으로 설정하는 것이 좋다.

# 3. 레디스 기본 개념
## 레디스의 자료 구조
### string

String은 키와 실제 저장되는 아이템이 1:1로 저장되는 유일한 자료구조.

string이 아닌 다른 자료구조는에서는 하나의 키에 여러 개의 아이템이 저장된다.



### list
순서를 가지는 문자열 목록. 하나의 list에는 최대 42억여개 아이템 저장 가능.

서비스에서 스택과 큐로 사용된다.

LTRIM 커맨드는 시작과 끝 아이템 인덱스를 인자로 받아 범위에 속하지 않으면 모두 제거한다.

<img src="./images//image-20240502003125507.png" width =600>

LPUSH와 LTRIM커맨드를 같이 사용하면 고정된 길이의 큐를 유지할 수 있다.

레디스의 list에 최대 1000개의 로그를 보관하고 싶다면?

```
LPUSH logdata <data>
LTRIM logdata 0 999  ->> 제일 오래된 1000번째 데이터가 삭제됌
```

LPUSH, RPUSH, LPOP, RPOP은 O(1)이지만, 인덱스나 데이터를 이용해 중간 데이터 접근시 O(n)이걸린다.



LINSERT는 BEFORE 또는 AFTER로 원하는 위치에 데이터를 넣는다

```
LINSERT mylist BEFORE B E // B 앞에 E를 넣음 
```

LSET데이터는 지정한 데이터의 위치에 덮어쓴다

```
LSET mylist 2 F // 2에 F 저장 
```

LINDEX는 원하는 데이터를 확인한다.

### hash

<img src="./images//image-20240502003541935.png" width = 550>

hash는 필드-쌍 값을 가진 아이템 집합. 필드는 하나의 hash 내에서 유일하다.

객체를 표현하기 적절한 자료구조이다. 

hash에서는 각 아이템마다 다른 필드를 가질 수 있으며, 동적으로 다양 한 필드를 추가할 수 있다는 특징이 있다.

HGET은 특정 데이터, HMGET은 다양한 필드, HGETALL은 모든 필드 값을 가져온다

```
HGET product:123 TypeID

HMGET product:234 NAME TypeID

HGETALL product:123
```

### Set

정렬되지 않은 문자열의 모음.

하나의 set 자료구조 내에서 아이템은 중복되어 저장되지 않는다.

교집합, 차집합, 합집합 등을 지원하므로 객체간의 관계를 계산하거나 유일한 원소를 구해야할 때 사용될 수 있따.

```
SADD myset A

SADD myset A A A B B C C

SMEMBER myset

SREM myset B // 삭제 
```

합집합은 SUNION 교집합은 SINTER, 차집합은 SDIFF 커맨드로 수행가능하다

![image-20240502003952786](./images//image-20240502003952786.png)

```
SINTER set:111 set:222

D

E

SDIFF set:111 set:222

SUNION set:111 set:222
```

### sorted Set
socre 값에 따라 정렬되는 고유한 문자열 집합.

모든 아이템은 스코어-값 쌍을 가지며, 저장될 때부터 스코어 값으 로 정렬돼 저장된다. 

같은 스코어를 가진 아이템은 데이터의 사전 순으로 정렬돼 저장 된다.

데이터는 중복 없이 유일하게 저장되므로 set과 유사하다고 볼 수 있으며, 각 아이템 은 스코어라는 데이터에 연결돼 있어 이 점에서 hash와 유사하다고 생각할 수 있다.

> 인덱스를 이용해 아이템이 접근할 일이 많다면 list대신 sorted set을 사용하자
>
> list의 index접근은 O(n) sorted set의 인덱스 접근은 O(log(N))

만약 저장하고자 하는 데이터가 이미 sorted set에 속해 있다면 스코어만 업데이트 된다.

스코어는 배정밀도 부동소수점 숫자couble predision toating point number를 문자열로 표현한 값이어야 한다.



ZADD 커맨드는 다양한 옵션을 지원한다.

- ﻿﻿XX: 아이템이 이미 존재할 때에만 스코어를 업데이트한다.
- ﻿﻿NX: 아이템이 존재하지 않을 때에만 신규 삽입하며, 기존 아이템의 스코어를 업데이트하지 않는다.
- ﻿﻿LT: 업데이트하고자 하는 스코어가 기존 아이템의 스코어보다 작을 때에만 업데 이트한다. 기존에 아이템이 존재하지 않을 때에는 새로운 데이터를 삽입한다.
- ﻿﻿GT: 업데이트하고자 하는 스코어가 기존 아이템의 스코어보다 클 때에만 업데이 트한다. 기존에 아이템이 존재하지 않을 때에는 새로운 데이터를 삽입한다.

ZRANGE 커맨드를 사용하면 sorted set에 저장된 데이터를 조회할 수 있으며, start 와 stop이라는 범위를 항상 입력해야 한다.

```shell
ZRANGE key start stop [BYSCORE | BYLEX] [REV] [LIMIT offset count]

[WITHSCORES]
```

**인덱스를 이용한 데이터 조회**

<img src="./images//image-20240502004349080.png" width = 550>

WITHSCORE 옵 션을 사용하면 데이터와 함께 스코어 값이 차례대로 출력되며, REV 옵션을 사용하면 데이터는 역순으로 출력된다.

```
ZRANGE score:220817 1 3 WITHSCORES

ZRANGE score:220817 1 3 WITHSOCRE REV

ZRANGE <key> 0 -1 커맨드 는 sorted set에 저장된 모든 데이터를 조회하겠다는 것을 의미
```

**스코어로 데이터 조회**

ZRANGE 커맨드에 BYSCORE 옵션을 사용하면 스코어를 이용해 데이터를 조회할 수 있다. 

start, stop 인자 값으로는 조회하고자 하는 최소, 최대 스코어를 전달해야 하 며, 전달한 스코어를 포함한 값을 조회한다

```
ZRANGE score:220817 100 150 BYSCORE WITHSCORES
```

스코어의 최솟값과 최댓값을 다음과 같이 포함할 수 있다. infinity를 의미하는 -inf, +inf라는 값

다음 예제에서는 스코어가 200보다 큰 모든 값을 출력하는 방법을 나타낸다.

```
ZRANGE score: 220817 200 +inf BYSCORE WITHSCORES
```

sorted set에 데이터를 저장할 때 스코어가 같으면 데이터는 사전 순으로 정렬 된다.

 이러한 특성을 이용해 스코어가 같을 때 BYLEX 옵션을 사용하면 사전식 순서를 이용해 특정 아이템을 조회할 수 있다

```
ZRANGE mySortedSet (b (f BYLEX

banana 
candy 
dream
egg
```

* 입력한 문자열을 포함하려면 (를, 않으려면 [를 사용한다

`ZRANGE <key> - + BYLEX 커맨드`는 sorted set에 저장 된 모든 데이터를 조회하겠다는 것을 의미한다.

### 비트맵

string 자료구조에 bit연산을 수행할 수 있도록 확장한 형태다.

비트맵을 사용할 때의 가장 큰 장점은 저장 공간을 획기적으로 줄일 수 있다는 것 이다.

 예를 들어 각각의 유저가 정수 형태의 ID로 구분되고, 전체 유저가 40억이 넘 는다고 해도 각 유저에 대한 y/n 데이터는 512MB 안에 충분히 저장할 수 있다.

SETBIT로 비트를 저장할 수 있으며, GETBIT 커맨드로 저장된 비트를 조회할 수 있다.

한 번에 여러 비트를 SET하려면 BITFIELD 커맨드를 사용하면 된다.

```
> SETBIT mybitmap 2 1
(integer) 1

> GETBIT mybitmap 2
(integer) 1

> BITFIELD mybitmap SET u1 6 1 SET u1 10 1 SET u1 14

1. (integer) 1
2. (integer) 1
3. (integer) 1
```

BITCOUNT 커맨드는 1로 설정된 비트의 수를 카운팅할 수 있다.

```
BITCOUNT mybitmap
```

### Hyperloglog

집합의 원소 개수인 카디널리티를 추정할 수 있는 자료구조다.

대량 데이터에서 중복되지 않는 고유한 값을 집계할 때 사용할 수 있다.

set은 모두 기억하지만, hyperLoglog는 데이터 그 자체보다 자체적인 방법으로 데이터를 변경해 처리한다.

저장되는 데이터 개수에 구애받지 않고 계속 일정한 메모리를 유지하며, 중복되지 않는 유일한 원소의 개수를 저장할 수 있다.

* 최대 12KB크기, 카디널리티 추정 오차범위 0.81개. 최대 2^64개의 아이템 저장 가능

PFADD 커맨드로 hyperloglog에 아이템을 저장할 수 있으며, PFCOUNT 커맨드로 저장 된 아이템의 개수, 즉 카디널리티를 추정할 수 있다.

```
PFADD members 123

PFCOUNT members
```

### Geospatial

경도, 위도 데이터 쌍의 집합으로 간편하게 지리 데이터를 저장될 수 있다.

내부적으로 sorted set으로 저장되며, 하나의 자료 구조 안에 키는 중복돼 저장되지 않는다.

```
GEOADD travel 14.399393 50.390234 seoul 
```

GEOPOS 커맨드를 이용하면 저장된 위치 데이터를 조회할 수 있으며, 

GEODIST 커맨드 를 사용하면 두 아이템 사이의 거리를 반환할 수 있다.

```
GEOPOS travel seoul
1. 14.39939...
2. 50.390234 ...

GEODIST travel seoul prague KM
8252.9957...
```

GEOSEARCH 커맨드를 이용하면 특정 위치를 기준으로 원하는 거리 내에 있는 아이템을 검색할 수 있다.

 BYRADIUS 옵션을 사용하면 반경 거리를 기준으로, BYBOX 옵션을 사용 하면 직사각형 거리를 기준으로 데이터를 조회할 수 있다

### stream

![image-20240502005845689](./images//image-20240502005845689.png)

stream은 레디스를 메시지 브로커로서 사용할 수 있게 하는 자료구조.

데이터를 계속해서 추가하는 방식(append only)으로 저장하므로 실시간 이벤트 또는 로그성 데이터의 저장을 위해 사용할 수 있다.

## 레디스에서 키를 관리하는 법
### 키의 자동 생성과 삭제
키의 생성과 삭제는 세가지 공통적 규칙을 따른다

1. 키가 존재하지 않을떄 아이템을 넣으면 아이템을 삽입하기 전 빈 자료구조를 생성한다.
   1. 이미 키에 다른 자료구조가 있을경우 아이템을 추가하면 에러를 반환한다.  
2. 모든 아이템을 삭제하면 키도 자동으로 삭제된다(stream은 예외)
3. 키가 없는 상태에서 키 삭제, 아이템 삭제, 등 읽기 전용 커맨드 수행시 에러를 반환하는 대신 키가 있으나 아이템이 없는것처럼 동작한다. 



### 키와 관련된 커맨드

**키의 조회  - EXISTS**

```
EXISTS key
```

**KEYS pattern**

레디스에 저장된 모든 키를 조회하는 커맨드. 매칭되는 패턴에 해당하는 모든 키의 list 반환

* 패턴은 glob 패턴 스타일로 동작

````
keys pattern
````

* 굉장히 위험한 커맨드. 모든 키를 반환한다. 

**SCAN** 

```
SCAN cursor [MATCH pattern] [COUNT count] [TYPE type]
```

KEYS를 대체해 사용할 수 있는 커맨드.

SCAN 커맨드는 커서 기반으로 특정 범위 키만 조회하기 떄문에 비교적 안전하다. 

**SORT**

```
SORT key [BY pattern] [LIMIT offset count] [GET pattern] [ASC | DESC] [ALPHA] [STORE destination]
```

list, set, sorted set에서만 사용할 수 있는 커맨드로, 키 내부의 아이템을 정렬해 반환한다. 

LIMIT 옵션을 사용하면 일부 데이터만 조회할 수 있으며, ASC/DESC 옵션을 사용하면 정렬 순서를 변경할 수 있다. 

정렬할 대상이 문자열일 경우 ALPHA 옵션을 사용 하면 데이터를 사전 순으로 정렬해 조회할 수 있다.



**OBJECT**

```
OBJECT <subcommand> [<arg> [value] [opt]]
```

키에대한 상세 정보 반환.

subcommand 옵션으로는 ENCODING, IDLETIME이 있으며 내부적으로 어떻게 저장됐는지, 호출되지 않은 시간 등 확인 가능



DEL | UNLINK

DEL은 동기적으로 키를 삭제

UNLINK는 키와 데이터를 삭제하지만, 백그라운드에서 처리하며 우선 키와 연결된 데이터를 끊어 조회되지 않게한다.

100만 개의 아이템이 저장돼 있는 sorted set 키를 DEL 커맨드로 삭제하는 것은 전체 키가 100만 개 있는 레디스에서 동기적인 방식으로 FLUSH ALL을 수행하는 것과 같고, 수행되는 시간 동안 다른 클라이언트는 아무런 커맨드를 사용할 수 없다. 

따라서 키에 저장된 아이템이 많은 경우 DEL이 아니라 UNLINK를 사용해 데이터를 삭제하는 것이 좋다

lazyfree-lazy-user-del 옵션이 yes일 경우 모든 DEL 커맨드는 UNLINK로 동작해

백그라운드로 키를 삭제한다. 버전 7 기준으로 해당 옵션의 기본값은 no이다.

# 4. 레디스 자료 구조 활용 사례
## sorted set을 이용한 실시간 리더보드
리더보드에는 두 가지 유형이 있다. 

절대적 리더 보드abosolute loaderborad는 서비스의 모든 유저를 정렬시켜 상위권의 목록만을 표시하는 반면 

상대적 리더보드는 사용자마다 다른 데이터를 보여준다. 즉 사용자의 스코어를 기반으로 다른 사용자와 비교해 순위를 결정하는 리더보드이다.

리더보드는 기본적으로 사용자의 스코어를 기반으로 데이터를 정렬하는 서비스이기 때문에 사용자의 증가에 따라 가공해야 할 데이터가 몇 배로 증가한다. 또한 리더보드는 실시간으로 반영돼야 하는 데이터다. 유저의 스코어가 100에서 110으로 변경되면 이 데이터는 실시간으로 계산돼 리더보드에서 자신의 순위가 상승한 것을 바로 확인 할 수 있어야 한다.



서비스에 일별 리더보드를 도입하기 위해 다음과 같이 daily-score:<날짜>를 이용해

sorted set 키를 만들고, 사용자의 스코어를 가중치로 사용해서 데이터를 입력해보자.

조회

```
ZRANGE daily-score:220817 0 -1 withscores
```

상위 스코어 3명만 출력하고 싶다면?

```
ZREVRANGE daily-score:220817 0 2 withscores
```

### 리더보드 데이터 업데이트

만약 player: 286이 게임을 해서 데이터를 업데이트해야 한다면 다음 커맨드로 쉽게변경이 가능하다.

```
ZADD daily-score:220817 200 player:286
```

같은 아이템을 저장하고자 할 때 스코어가 다르면 기존 데이터의 스코어만 신규 입력한 스코어로 업데이트된다.

직접 스코어의 값을 지정해서 변경하지 않고도 ZINCRBY 커맨드를 이용해서 sorted set 내의 스코어를 증감시킬 수 있다

* 원자적 연산

```
ZINCRBY daily-socre:220817 100 player:24
```

### 랭킹 합산

매주 월요일마다 리더보드가 초기화 된다면, 주간 누적 랭킹시 많은 연산을 해야한다

레디스에서는 **ZUNIONSTORE** 커맨드를 사용해 간단하게 구현할 수 있다.

ZUIONSTORE 커맨드는 지정한 키에 연결된 각 아이템의 스코어를 합산하는 커맨드다.

따라서 해당하는 일자의 키를 지정하기만 한다면 손쉽게 주간 리더보드 데이터를 얻 을 수 있다.

![image-20240502011308870](./images//image-20240502011308870.png)

22년 8월 15일부터 17일까지의 데이터를 합산하고 싶다면 다음과 같이 사용하자.

```
ZUNIONSTORE weekly-score:2208-3 3 daily-score:220815 daily-score: 220816 daily-score:220817
```

* <생성할 키 이름> <합산할 키 개수> <합산할 키>

ZUIONSTORE를 이용해 데이터를 합칠 때 스코어에 가중치를 줄 수도 있다. 

만약 8월16일에 스코어 두 배 이벤트가 있었다면 그림 4-6과 같이 8월 16일 데이터에만 가중치를 두 배로 늘려 계산할 수 있다.

```
> ZUNIONSTORE weekly-score:2208-03 3 daily-score:220815 daily-score: 220816 daily-score:220817 weights 1 2 1
(integer) 4
```

WEIGHTS 옵션을 이용해 가중치를 줄 수 있으며, 위의 예제에서는 15일, 16일, 17일에 각각1,2,1을 곱한 값으로 합산된 랭킹을 구할 수 있다.

## sorted set을 이용한 최근 검색 기록

쇼핑몰에서 사용자가 최근에 검색한 내역을 확인할 수 있는 기능을 추가하려고 한다.

* 유저별로 다른 키워드 노출

* 검색 내역은 중복 제거

*  가장 최근 검색한 5개의 키워드만 사용자에게 노출

sorted set은 set이기 때문에 저장될 때부터 중복을 허용하지 않으며, 스코어로 시간을 사용한다면 검색 기록으로 정렬될 수 있다.

<img src="./images//image-20240502011608239.png" width = 550>



## sorted set을 이용한 태그 기능

관계형 데 이터베이스에서 태그 기능을 사용하려면 적어도 2개의 테이블이 추가돼야 한다. 첫 번째로는 태그 테이블, 두 번째로는 태그-게시물 테이블이다.

레디스에서 set을 사용하면 굉장히 간단하게 게시물의 태그 기능을 사용할 수 있다.

```
SADD post:47:tags IT REDIS DataStore

SADD post:22:tags IT python
```

* 게시물:게시물번호:태그들 이라는 key값으로 저장



특정 게시물이 어떤 태그와 연관되었는지 알고싶다면

```
SADD tag:DataStore:posts 53

SADD tag:IT:posts 53
```





SMEMBERS 커맨드를 이용하면 특정 태그를 갖고 있는 포스트를 쉽게 확인할 수 있다

```
SMEMBER tag:IT:posts
```

SINTER 커맨드를 이용하면 특정 set의 교집합을 확인할 수 있다. 

만약 IT와 Datastore 태그를 모두 포함하는 게시물을 확인하고 싶으면 다음과 같이 SINTER 커맨드를 사용 할 수 있다.

```
SINTER tag:IT:posts tag:Datasoutre:posts
```

## 랜덤 데이터 추출

보통 관계형 데이터베이스에서 랜덤 데이터 추출을 사용할 때에는 ORDER BY RAND()

함수를 많이 사용한다. 이 함수는 쿼리의 결값을 랜덤하게 정렬하지만, 조건 절에 맞는 모든 행을 읽은 뒤, 임시 테이블에 넣어 정렬한 다음 랜덤으로 1imit에 해당할 때까지 데이터를 추출한다. 데이터가 1만 건 이상일 경우 이와 같은 쿼리는 성능이 나 빠지게 돼 굉장히 부하가 많이 가는 방법일 수 있다.

레디스를 사용하면 0(1)의 시간 복잡도를 이용해 랜덤한 데이터를 추출할 수 있다.



**RANDOMKEY** 커맨드

HRANDFIELD, SRANDMEMBER, ZRANDMEMBER는 각각 hash, set, sorted set에 저장된 아 이템 중 랜덤한 아이템을 추출할 수 있다.

HRANDFIELD 커맨드를 사용하면 지정한 hash 내에서 임의로 선택된 하나의 아이템을 추출할 수 있다. 이때 COUNT 옵션을 이용하면 원하는 개수만큼 랜덤 아이템이 반환되 며, WITHVALUES 옵션을 사용하면 필드에 연결된 값도 함께 반환할 수 있다.

이때 COUNT 옵션을 양수로 설정하면 중복되지 않는 랜덤 데이터가 반환되고, 음수로 설정하면 데이터가 중복해서 반환될 수 있다.

```
HRANDFILED user:hash 1 WITHVALUES
```

```
HRANDFIELD user:hash 2

HRANDFIELD user:hash -2
```

## 레디스에서의 다양한 카운팅 방법

### 좋아요 처리하기
하나의 유저는 같은 댓글에 한 번씩만 좋아요를 누를 수 있어야 하기 때문에 단순히 좋아요의 개수를 파악하는 것이 아닌, 어떤 유저가 어떤 댓글에 좋아요를 눌렀는지의 데이터 또한 처리할 수 있어야 한다.

댓글 id를 기준으로 set을 생성한 뒤, 좋아요를 누른 유저의 id를 set에 저장하면 중 복 없이 데이터를 저장할 수 있다

```
SADD comment-like:12554 967
```

각 댓글별로 좋아요를 누른 수는 SCARD 커맨드로 확인할 수 있다.

```
SCARD comment-like: 12554

(integer) 3
```

### 읽지 않은 메시지 수 카운팅하기

채팅 애플리케이션에서 사용자가 속한 채널별로 읽지 않은 메시지를 카운팅하고 관리 하려고 한다. 이전에 살펴본 좋아요 예제와 유사하게 채팅 메시지가 도착할 때마다 바 로 관계형 데이터베이스를 업데이트하는 대신 데이터를 레디스와 같은 인메모리 데이 터베이스에 일시적으로 저장한 뒤 필요한 시점에 한꺼번에 업데이트하는 방식을 사용 해서 관계형 데이터베이스의 부하를 최소화하고 성능을 향상시키고자 한다.

사용자의 ID를 키로 사용하고, 채널의 ID를 아이템의 키로 활용해 숫자 형태의 메시지 카운트 를 관리하는 방법을 고려할 수 있다

<img src="./images//image-20240502012448991.png" width = 550>

ID가 234인 사용자가 4234 채널에서 새로운 메시지를 수신했다면 다음과 같은 명령어를 사용할 수 있다.

```
HINCRBY user:234 channel:4234 1
```

메시지를 삭제했다면?

```
HINCRBY user:123 channel:3135 -1
```

### DAU 구하기

레디스의 비트맵을 이용하면 메모리를 효율적으로 줄이면서도 실시간으로 서비스의 DAU를 확인할 수 있다.

사용자 Id는 0이상의 정수값이여야 한다.

사용자 ID는 String 자료구조에서 하나의 비트로 표현될 수 있으며, 1천만 사용자는 1천만개의 비트로 나타낼 수 있꼬 1.2MB크기에 해당한다.

![image-20240502012708350](./images//image-20240502012708350.png)

id가 14인 유저가 접근했을때에는 오프셋 14를 1로 설정해준다

```
SETBIT uv:20221106 14 1
```

해당 일자에 접근한 유저 수를 확인할 때에는 BITCOUNT 커맨드를 사용할 수 있다.

```
\> BITCOUNT uv: 20221106
```

게임에서 출석 이벤트를 진행하기 위해 특정 기간 동안 매일 방문한 사용자를 구하고 싶을 수 있다.

 11월 1일부터 3일까지 매일 출석한 유저에게 보상을 지급하기 위해 일주일 동안 매일 출석한 유저를 구하는 방법을 알아보자.

![image-20240502012841930](./images//image-20240502012841930.png)

```
BITOP AND event:202211 uv:20221101 uv:20221102 uv:20221103
```

같이 BITOP AND 커맨드를 이용하면 3일 동안 연속 출석한 유저의 정보 를 새로운 비트맵 자료 구조인 event: 202211로 얻을 수 있다. 비트맵 데이터는 응용쪽 애플리케이션에서 list로 변환해 사용할 수 있다. 

위 이벤트의 결과 데이터인 event:202211을 확인해보자.

```
\> GET event: 202211

"x01\x02"
```

해당 결과로 나온 문자열을 리스트로 변환하면 다음과 같다

```
fun main() {
    // 이진 데이터 \x01과 \x02를 포함하는 문자열 생성
    val result = String(charArrayOf(1.toChar(), 2.toChar()))
    val bitsList = mutableListOf<Int>()

    for (char in result) {
        val bits = (7 downTo 0).map { i -> 
            (char.code shr i) and 1 
        }
        bitsList += bits
    }

    println(bitsList)
}
// [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]
```

* 7번 인덱스와 14번 인덱스가 1이므로, id가 7번, 14번인 유저가 매일 출석한 것이다.



## hyperloglog를 이용한 애플리케이션 미터링

미터링은,사용자가 자원을 얼마나 사용했는지 여부이다.

미터링은 사용자의 서비스 사용 내역을 이용해서 측정하기 때문에 초당 수천건 이상의 작업이 발생할 수 있고, 높은 처리량과 낮은 지연시간을 가져야 한다.

1초에 로그가 100개씩 쌓이면 한시간에는 36만개, 한달에 2억 6천개의 로그가 쌓인다.

다음 조건을 만족한다면 레디스의 hyperloglog를 사용하는것을 고려할 수 있다.

* 집합 내의 유일한 데이터 수를 카운팅
* 1% 미만의 오차는 허용 가능
* 카운팅할 때 사용한 정확한 데이터를 다시 확인하지 않아도 된다. 

유저의 월별 API 호출 횟수를 계산할 수 있다.

각 유저 구분 ID를 키로 사용하고, API 호출할때마다 저장되는 로그의 식별자를 hyperloglog에 저장할 수 있다.

* 예를 들어 2022년 11월에 ID 245 유저의 호출 횟수 계산

```
PFADD 2011:user:245 49483
```

* 49483은 로그의 식별자

SET과 비슷하지만 용량은 12KB로 고정이기 때문에 매우 효율적이다.

PFMERGE 커맨드를 이용하면 여러개의 hyperloglogs를 합칠 수 있어 분기별 또는 연도별 합산 데이터를 계싼할 수 있따.

```
PFMERGE 2022:user:245 202211:user:245 202212:user:245

PFCOUNT 2022:user:245
> (integer) 7
```

1. **PFMERGE** 명령:
   - `PFMERGE 2022:user:245 202211:user:245 202212:user:245`
   - 이 명령은 `202211:user:245` 및 `202212:user:245` 두 HyperLogLog 키의 데이터를 병합하여 새로운 HyperLogLog 키 `2022:user:245`에 저장합니다. 결과적으로 `2022:user:245`는 두 키의 데이터를 포함하게 됩니다.
2. **PFCOUNT** 명령:
   - `PFCOUNT 2022:user:245`
   - 이 명령은 `2022:user:245` HyperLogLog 키의 고유 요소의 추정 수를 반환합니다. 반환된 값 `(integer) 7`은 `2022:user:245` 키가 추정하는 고유 요소의 수가 7개라는 것을 의미합니다.

### Geospatial Index를 이용한 위치 기반 애플리케이션 개발

### 레디스에서의 위치 데이터

위치데이터는 주로 경도와 위도(x, y)좌표 쌍으로 표현된다.

레디스를 활용하면 데이터 저장뿐만 아니라 실시간 위치 연산을 직접 수행할 수 있다.

* 예를들어 geo set과 pub/sub 기능을 함께 사용해서 근처의 사용자에게 실시간 알림을 보낼 수 있다.

### geo set

각 위치 데이터는 경도와 위도 쌍으로 저장되며, 내부적으로 sorted set 구조로 저장된다

```
GEOADD user 50.07432 14.32413 142
```

ID가 142인 사용자의 위치 정보를 GEOADD 커맨드를 사용해서 추가할 수 있다.

저장된 데이터는 GEOPOS 커맨드로 조회할 수 있따.

```
GEOPOS restaurant ukalendu // 레스토랑 키의 ukaliendu 값의 위경도 출력
```

다음과 같이 1키로 이내 데이터도 찾을 수 있다.

```
GEOSEARCH restaurant fromlonlat 50.134234 14.21342341 byradius 1 km
```

* 예제에서는 FROMLONLAT 옵션을 이용해 직접 경도와 위도를 지정한 뒤, 해당 위치 근 처 1km 내의 데이터를 검색했다

* BYRADIUS 옵션은 사용자가 지정한 반지름 값을 기준으로 그 반지름 만큼 떨어진 범위 내의 데이터를 검색한다.

* BYBOX 옵션은 width와 height값을 지정하여 특정 위치 중심으로 한 직사각형 영역 내의 장소들을 검색한다.

```
GEOSEARCH key FROMMEMBER member BYBOX 4 2 KM
```

* 좌우로 width만큼, 상하로 height만큼 직사각형 결정 

![image-20240502214250495](./images//image-20240502214250495.png)

* 기준점 중심으로 양옆으로 2KM 위아래로는 1KM 내 데이터 검색 

# 5. 레디스를 캐시로 사용하기

## 레디스와 캐시
캐시 도입시 고려사항

* 데이터 저장소에서 데이터 검색시 오래걸리는 경우
* 캐시에 저장된 데이터가 자주 변하지 않고 자주 검색되는 경우

관계형 DB는 디스크에 접근해 데이터를 검색해오지만 레디스는 인메모리 이기때문에 굉장히 빠르다

평균 읽기 및 쓰기 작업 속도가 1ms 미만이며 초당 수백만건 작업 가능

### 캐싱 전략

#### 읽기 전략 - look aside

<img src="./images//image-20240503230659716.png" width =550>

데이터베이스보다 캐시에 있는지 확인하고 캐시에서 반환 - 캐시 히트

데이터가 없으면 캐시 미스라고 하며 데이터베이스에 접근하게 된다.

장점

* 레디스 장애 생겨도 DB 조회 가능 

단점

* 레디스의 커넥션이 모두 디비로 가서 부하를 발생시킬 수 있음 

레디스에 아무 데이터가 없다면 캐시 미스가 발생하여 성능이 느려질 수 있으므로 미리 데이터베이스에서 캐시로 밀어넣는 작업을 하기도 한다.

이를 **캐시 워밍업** 이라고 한다. 

### 쓰기전략과 캐시의 일관성

캐시는 단순히 DB의 데이터를 복사해온 값이므로 원본 데이터와 동일한 값을 갖도록 유지하는것이 필수이다.

DB만 업데이트 되서 캐시에는 값이 반영되지 않는다면 캐시 불일치가 발생한다. 

때문에 다음의 캐시 쓰기 전략들을 고려한다. 

#### write thorugh

DB업데이트마다 캐시도 데이터를 업데이트 한다. 

이방식의 경우 다시 사용되지 않을 데이터가 게속 저장되어있을 수 있으므로 만료 시간(TTL)을 사용할것을 권장한다

#### cache invalidation 

DB에 업데이트할때마다 캐시에서는 데이터를 삭제하는 전략이다. 

저장소에서 특정 데이터를 삭제하는것이 새로운 데이터를 저장하는것보다 리소스를 적게 먹기 때문에 write through 단점을 보완한 방식이다.

#### write behind(write back)

쓰기가 빈번하게 발생하는 서비스라면 캐시에 먼저 대량으로 저장하고, 건수나 특정 시간 간격마다 비동기적으로 DB에 업데이트 한다. 

데이터가 실시간 정확성이 필요하지 않는 경우 유용하다

* 유튜브 동영상 좋아요 등 

## 캐시에서의 데이터 흐름

레디스에 데이터 저장시 적절한 TTL을 지정하는것이 좋다 

### 만료 시간

레디스 TTL는 초단위로 표현. EXPIRE 커맨드로 만료시간을 지정할 수 있다.

TTL key 명령어로 만료시간을 확인 가능하다

* -2인경우 키가 없음
* -1인경우 만료시간이 없음

PTTL과 PEXPIRE 커맨드는 밀리세컨드로 동작한다.

```
ex) TTL 지정
EXPIRE a 60
```

기존 키에 새로운 값을 덮어 쓸 경우 이전에 설정한 만료시간은 유지되지 않고 사라진다. 

레디스에서 키가 만료됐따고 바로 삭제되지 않는다

passive방식과 active 방식 두가지로 삭제된다

* passive: 사용자가 키에 접근시 키가 만료됐다면 메모리에서 수동으로 삭제. 접근할떄에만 삭제하기떄문에 패시브라고 함. 단점은 접근하지 않으면 삭제 안됌
* active : TTL값이 있는 키중 20개를 랜덤하게 뽑아낸 뒤 만료된 키를 모두 메모리에서 삭제한다. 약 25%이상의 키가 삭제됐따면 다시 20개를 랜덤하게 뽑은뒤 확인. 아니라면 뽑아놓은 20개 키 집합에서 확인하며, 1초에 10번씩 수행한다

### 메모리 관리와 maxmemory-policy 설정

레디스에서는 데이터의 최대 저장 용량을 설정하는 maxmemory 설정과 이 용량을 초 과할 때의 처리 방식을 결정하는 maxmemory-policy 설정값을 사용해 메모리를 관리 한다. maxmemory-policy의 다양한 설정값과 동작 방식에 대해 알아보자.

**Noeviction**

디폴트 값. 레디스에 가득 차더라도 임의로 데이터를 삭제하지 않는다. 더이상 저장할 수 없다는 에러를 반환한다.

관리자가 직접 레디스 데이터를 지워야 하기 때문에 권장하지 않는 설정값이다.

데이터 관리를 캐시 대신 애플리케이션에 관리를 맡긴다는 것을 의미한다.

**LRU Eviction**

가장 최근에 사용되지 않은 데이터부터 삭제하는 정책.

레디스는 LRU 알고리즘을 이용한 두가지 설정 값을 가지고 있다.

1. volatile-lru : 만료시간이 설정돼 있는 키에 한해서 LRU로 삭제. 임의적인 방식으로 삭제되면 안되는 값이 있다면 volatile-lru 사용
   * 그러나 장애 상황을 유발할 수 있다. 모든 키가 만료시간이 없으면 삭제되지 않기 떄문에 noeviction과 동일하다
2. allkeys-LRU : 모든 키에 대해 LRU를 이용해 데이터를 삭제하기 떄문에 메모리 풀 장애 상황은 방지할 수 있따. 

**LFU Eviction**

가장 자주 사용되지 않은 데이터부터 삭제하는 정책.

LRU와 유사하지만, 우선순위가 유동적으로 바뀌므로 LRU보다 효율적일 수 있다.

LFU 또한 두가지 설정값을 가지고 있따.

1. volatile-lfu : 만료시간이 있는 키에 한해서만 LFU로 삭제. 마찬가지로 장애 가능
2. allkeys-lfu : 모든 키에 대해 LFU 적용

**RANDOM eviction**

랜덤으로 키중 하나를 골라 삭제한다. 알고리즘을 이용하여 삭제될 키값을 정하기 않기 때문에 부하를 줄일 수 있는 방법이다.

레디스는 근사 알고리듬을 사용하기 때문에 LFU, LRU 에 큰 리소스를 사용하지 않는다. 따라서 굳이 레디스의 부하를 줄이기 위한다는 이유로 random eviction을 사용하는 것은 권장하지 않는다.

random eviction 또한 다음 두 가지 설정값을 갖고 있다.

- ﻿﻿volatile-random: 만료 시간이 설정돼 있는 키에 한해 랜덤하게 키를 삭제한다.
- ﻿﻿allkeys-random: 모든 키에 대해 랜덤하게 키를 삭제한다.

**volatile-ttl**

만료시간이 가장 작은 키를 삭제한다. 즉 어차피 삭제될 키를 미리 삭제하는 옵션

### 캐시 스탬피드 현상

대규모 트래픽 환경에서 만료시간을 어떻게 설정하느냐에 따라 캐시 스탬피드와 같은 문제가 발생할 수 있다.

캐시 스템피드 현상은 여러 요청이 동시에 캐시된 데이터를 갱신하려고 할 때 발생하는 문제이다(중복 읽기, 중복 쓰기)

<img src="./images//image-20240503232906226.png" width = 750>

레디스에서 특정 키가 만료될 때, 여러 서버는 한번에 DB에서 데이터를 읽는 과정을 거친다. 이를 중복 읽기라고 한다.

이후 각 애플리케이션에 레디스에 데이터를 쓰게되는데 이또한 여러번 반복되서 중복 쓰기가 발생한다.

#### 적절한 만료시간(TTL) 설정

반복적으로 사용되는 데이터라면. 만료시간을 너무 짧지 않게 설정한다.

### 선 계산

랜덤한 확률로 만료시간이 남아있어도 갱신하는 방법이다.

단순히 데이터를 가져오는것보다 더 많은 리소스를 사용한다고 볼 수도 있지만, 상황에 따라 캐시 스템피드 현상을 방지할 수 있기 때문에 전체적인 성능을 향상시킬 수도 있다.

#### PER 알고리즘

캐시값이 만료되기 전 언제 DB에 접근해서 값을 읽어오면 되는지 최적으로 계산하는 알고리즘. 

PER 알고리듬을 소개한 논문에는 수많은 수학 이론이 있지만, 간단하게 다음과 같이 요악할 수 있다.

```
currentTime - ( timeToCompute * beta * log(rand()) ) > expiry
```

- ﻿﻿currentTime: 현재 남은 만료 시간
- ﻿﻿timeToCompute: 캐시된 값을 다시 계산하는 데 걸리는 시간
- ﻿﻿beta: 기본적으로 1. 0보다 큰 값으로 설정 가능
- ﻿﻿rand(): 0과 1 사이의 랜덤 값을 반환하는 함수
- ﻿﻿expiry: 키를 재설정할 때 새로 넣어줄 만료 시간

**timeToCompute * beta * log(rand())** 는 무작위성을 가진 값이며, 캐시의 만료 여부에 영향을 미친다.

만료시간이 가까워질수록 currentTime과 expire의 차이가 작아지면서 조건이 true가 될 확률이 높아진다.

위 조건에서 true가 반환이 되면 DB에서 읽어 갱신하게 된다

이 알고리즘은 만료시간에 가까워질수록 true가 될 확률이 증가하므로, 불필요한 재계산을 효과적으로 방지하는 효율적인 방법일 수 있다.

**백그라운드 작업 사용**:

 캐시된 데이터를 비동기적으로 갱신하는 백그라운드 작업을 사용하여 캐시 갱신 작업의 부하를 분산.

## 세션 스토어로서의 레디스

### 세션이란?

클라이언트의 상태 정보. 

유저가 로그인해있는동안 세션 데이터를 끊임없이 읽고 쓰면서 사용자가 서비스를 이용하면서 행동을 분석해 비즈니스 개선에 사용할 수 있다. 

### 세션 스토어가 필요한 이유

웹 서버별로 세션 스토어를 따로 관리하면, 유저는 세션정보를 갖고있는 웹 서버에 종속될수밖에없다.

특정 웹서버에 유저가 몰리게 되어 트래픽을 분산시킬수없는 상황이 될 수가 있는데 이를 sticky session 이라 한다.

all-to-all이라고 모든 웹서버에 세션 정보를 복수할 수 있지만, 불필요한 저장공간을 차지하게 된다. 

그렇다고 DB에 두면 응답속도가 느려질 수 있어 장애를 유발할 수 있다.

레디스를 세션 스토어로 사용하여 여러 서버에서 중앙집중식으로 보게 한다면 앞선 모든 이슈를 해결할 수 있다. 



특히나 레디스의 hash 자료구조는 세션 정보를 저장하기 아주 유용하다. 

### 캐시와 세션의 차이

세션을 레디스에 사용할때 흐름은 다음과 같다.

![image-20240504002821251](./images//image-20240504002821251.png)

세션이 활성화돼있는 동안에는 애플리케이션은 유저의 데이터를 세션 스토어에만 저장한다.

로그아웃할때 세션은 종료되며, 데이터 종류에 따라 DB에 업데이트 되어 영구저장된다.

세션스토어에 장애가 발생하면 데이터가 손실될 가능성이 있으므로 레디스를 세션 스토어로 활용할 때에는 레디스를 캐시로 사용할때보다 신중하게 운영해야 한다. 



# 6. 레디스를 메시지 브로커로 사용하기
## 메시징 큐와 이벤트 스트림

메시지 브로커는 크게 메시징 큐와 이벤트 스트림이라는 두 가지 형태로 나눌 수 있다. 

이 둘은 크게 두가지 차이점을 갖고있다.

1. 방향성 : 메시지 큐의 퍼블리셔는 컨슈머의 큐로 데이터를 직접 푸시한다.

2개의 서비스에 같은 메시지를 보내야 한다면 퍼블리셔는 2개의 각각 다른 메시지 큐에 데이터를  푸시해야한다.

반면 스트림은 특정 저장소에 하나의 메시지를 보내고, 소비자들은 같은 메시지를 스트림에서 pull해갈 수 있어 메시지를 복제하여 저장할 필요가 없다.

2. 영속성

메시지 큐는 소비자가 데이터를 읽어갈떄 큐에서 데이터를 삭제한다.

이벤트 스트림은 구독자가 읽어간 데이터는 바로 삭제되지 않고, 저장소 설정에 따라 특정 기간동안 저장될 수 있다. 



메시지 큐는 1:1 상황에서 한 서비스가 다른 서비스에게 지정할때 유용하게 사용되고,

스트림은 n:n (다대다)상황에서 유리하게 사용할 수 있다. 



### 레디스를 메시지 브로커로 사용하기

레디스의 **pub/sub은** 모든 데이터는 한번 채널에 전파된 뒤 삭제되는 일회성이며, 잘 전달됐는지 정보는 보장하지 않는다.

완벽하게 메시지가 전달돼야 하는 상황에서는 적합하지 않지만 fire-and-forget패턴이 필요한 알림 서비스에서는 유용하게 사용될 수 있다.

* 이 패턴은 주로 성능 향상이나 비동기 작 업올 수행할 때 사용되며, 작업의 완료나 결과에 대한 처리가 필요하지 않을 때 유용하게 사용된다
* fire-and-forget 패턴을 사용할 때는 결과 확인이나 오류 처리를 고려하지 않고 작업을 진행하므로, 신뢰성이 필요한 경우에는 사용하지 않아야 한다.

레디스의 **list** 자료 구조는 메시지 큐로 사용하기에 알맞다.

푸시와 팝이 가능하며, 데이터가 있는지 매번 확인할 필요 없이, 새로운 데이터가 들어오면 읽어갈 수 있는 블로킹 기능도 가능하다.



레디스의 stream은 카프카에서 영감을 받아 만들어진 자료구조로, 데이터는 계속해서 추가되는 방식으로 저장된다.(append-only)

소비자와 소비자 그룹을 이용하면 카프카와 비슷하게 처리할 수 있다.

stream에 저장되는 메시지를 실시간으로 리스닝하며 소비할수도있으며, 저장돼있는 데이터를 시간대별로 검색하는것도 가능하다 

## 레디스의 pub/sub
메시지를 채널로 보내기만 할뿐, 어떤 구독자가 읽어가는지, 정상적으로 전달됐는지, 어떤 발행자에 의해 생성됐는지 메타데이터는 알 수 없다. 

### 메시지 publish하기

```
PUBLISH hello world
```

* hello라는 채널을 수신하는 모든 서버들에 world라는 메시지를 전파한다.
* 전파한 후에는 수신한 구독자의 수가 반환된다 

### 메시지 구독하기

```
SUBSCRIBE event1 event2
```

* event1, event2채널을 동시에 구독한다.
* 클라이언트가 구독자로 동작하면 새로운 채널을 구독할 수 있찌만, 다른 커맨드를 수행할 수는 없다.

구독자가 수행할 수 있는 커맨드는

SUbSCRIBE, SSUBSCRIBE, SUNSUBCRIBE, PSUBCRIBE, UNSUBCRIBE, PUNSUBSCRIBE, PING, RESET ,QUIT 이다. 

1. **SUBSCRIBE (채널명)**:
   - 특정 채널에 구독합니다. 이 커맨드를 사용하면 클라이언트는 지정된 채널에서 발생하는 메시지를 수신할 수 있습니다.
2. **SSUBSCRIBE (패턴)**:
   - 지정된 패턴과 일치하는 모든 채널에 대해 구독합니다. 와일드카드를 사용하여 여러 채널을 동시에 구독할 수 있습니다.
3. **SUNSUBSCRIBE (패턴)**:
   - 지정된 패턴과 일치하는 모든 채널에 대한 구독을 해제합니다.
4. **PSUBCRIBE (패턴)**:
   - 지정된 패턴과 일치하는 모든 채널을 구독합니다. 즉, 특정 패턴으로 시작하는 모든 채널을 구독합니다.
   - PSUBSCRIBE mail-* 라는 커맨드 사용시 앞부분이 mail-로 시작하는 모든 채널에 전파된 메시지 수신 가능. 
   - 이때 메시지는 pmessage 타입으로 전달되며, SUBSCRIBE 커맨드를 이용해 구독하는 방식과 구분된다.

<img src="./images//image-20240504160111212.png" width = 650>

만약 구독자가 main-1과 psubscribe mail-*를 동시에 구독하면

2개의 메시지를 받게된다 



5. **UNSUBSCRIBE (채널명)**: 특정 채널의 구독을 해제

6. **PUNSUBSCRIBE (패턴)**: 지정된 패턴과 일치하는 모든 채널에 대한 구독을 해제합

7. **PING**: 서버에 대한 핑을 보낸다. 주로 연결이 유효한지 확인하기 위해 사용

8. **RESET**: :클라이언트의 상태를 재설정. 주로 테스트나 디버깅 목적으로 사용.

9. **QUIT**: 현재 연결을 종료하고 Redis 서버와의 연결을 끊는다.



### 클러스터 구조에서의 pub/sub

레디스 클러스터 사용하게 되면 클러스트에 속한 모든 노드에 자동으로 전달된다.

따라서 레디스 클러스터의 아무 노드애 연결해 SUBSCRIBE 사용하면 데이터를 수신할 수 있다. 

굉장히 간단하고 명료하지만, 클러스터의 목적을 고려한다면 비효율적인 방식으로 여겨질 수 있다.

클러스터는 분산 환경에서 데이터를 분산해서 저장하기 위함인데, 모든 노드에 복제되는것은 불필요한 리소스 사용과 네트워크 부하가 발생할 수 있다. 

### sharded pub/sub

클러스터 구조의 pub/sub을 방지하기 위해 도입됐다.

* SPUBLISH, SSUBSCRIBE 명령어

shaded pub/sub은 각 채널은 슬롯에 매핑된다. 클러스터에서 키가 슬롯에 할당되는 것과 동일한 방식으로 채널이 할당되며,

같은 슬롯을 가진 노드간에만 메시지를 전파한다. 

<img src="./images//image-20240504160525675.png" width =650>

SPUBLISH 커맨드로 발행된 메시지는 모든 노드에 전파되지 않으며, 노드의 복제본에만 전달된다

```
SPUBLISH apple a
-> Redirected to slot [7092] located at 10.0.0.2:6379
```

SSUBSCRIBE도 마찬가지로 특정한 서버에서만 수행될 수 있다.

```
SSUBSCRIBE apple
```

apple 채널은 apple 키 값을 할당받을 수 있는 슬롯을 포함한 마스터 노드에 연결될 수 있도록 리다이렉트된다.

이렇게되면 모든 노드로 전파되지 않기때문에 불필요한 복제를 줄여 자원을 절약할 수 있다는 장점이 있다. 

## 레디스의 list를 메시징 큐로 사용하기
큐의 head와 tail에서 데이터를 넣고 뺄수있는 LPUSH, LPOP, RPUSH, RPOP 커맨드가 존재하기 때문에 애플리케이션에서 직접 구현할 수 있다. 

### list의 EX 기능

> 트위터는 각 유저의 타임라인 캐시 데이터를 레디스에서 list 자료구조로 관리한다

타임라인 캐시에 데이터를 저장할떄 RPUSH가 아닌 RPUSHX를 사용하는데, RPUSHX는 list가 이미 존재할때만 아이템을 추가하는 커맨드다.

이 커맨드를 이용하면 이미 캐시된(키가 존재하는)타임라인에만 데이터를 추가할 수 있다. 자주 들어오지 않는 유저에 대해 굳이 캐시를 관리해야 할 필요가 없기 때문.

```
RPUSHX Timelinecache:userB data3 
```

장점 : 사용자 캐시가 존재하는지 유무를 애플리케이션에서 확인할 필요가 없어서 성능 향상 가능

### list의 블로킹 기능

event-driven구조에서 시스템은 이벤트 루프를 돌며 신규로 처리할 이벤트가 있는지 체크한다.

이벤트 루프는 이벤트 큐에 새 이벤트가 있는지 체크하며, 새로운 이벤트가 없는경우 polling interval동안 대기한뒤 다시 큐를 확인하는 과정을 반복한다.

list의 블로킹 기능을 사용하면 이와 같은 불필요함을 줄일 수 있다.

**BRPOP, BLPOP은 각각 RPOP, LPOP에 블로킹을 추가한 커맨드다.**

클라이언트가 BLPOP을 이용해 데이터를 요청했을 때 리스트에 데이터가 있으면 즉시 반환하며 없을때에는 데이터가 들어올 때까지 기다린 후 들어온 값을 반환하거나, 클라이언트가 설정한 타임아웃 시간만큼 대기한 후에 nil값을 반환한다.

```
BRPOP queue:a 5
```

* queue:a에 타임아웃 5초동안 대기하고 5초가 경과하면 nil을 반환한다.
* 타임아웃 값이 0이면 제한없이 무제한으로 기다린다.

또한 BRPOP은 RPOP과 다르게 2개의 데이터를 반환한다.

첫번째는 팝된 리스트의 키 값을 반환하고, 두번째에 반환 데이터의 값을 반환한다.

* 이렇게 설계된 이유는 동시에 여러 리스트에서 대기할 수 있게 하기 위해서이다.

아래 커맨드는 1000초동안 a, b, c 큐중 어느하나라도 데이터가 들어올때까지 기다린 뒤 그중하나의 리스트에 데이터가 들어오면 해당 값을 읽어온다

```
BRPOP queue:a queue:b queue:c timeout 1000
1) "queue:b"
2) "DATA"
```

### list를 이용한 원형 큐

만약 특정 아이템을 계속해서 반복 접근해야하는 클라이언트, 혹은 여러 클라이언트가 병렬적으로 같은 아이템에 접근해야 하는 경우 원형 큐를 이용할 수 있다.

RPOPLPUSH 커맨드를 사용하면 원형 큐를 사용할 수 있다. 

* POP하고 다시 마지막에 PUSH한다. 

<img src="./images//image-20240504161513704.png" width = 650>

## Stream
### 레디스의 Stream과 아파치 카프카

stream은 두가지 방식으로 활용될 수 있따.

1. stream을 대량의 데이터를 효율적으로 처리하는 플랫폼으로 사용 가능
2. 데이터 엔지니어가 여러 생산자가 생성한 데이터를 다양한 소비자가 처리할 수 있께 지원하는 데이터 저장소 및 중간 큐잉 시스템으로 사용 가능



### 스트림이란?

연속적인 데이터의 흐름, 일정한 데이터 조각의 연속

![image-20240504161712793](./images//image-20240504161712793.png)

파일 하나는 유한하지만 이를 읽어올때 애플리케이션은 데이터를 잘개 쪼개서 처리한다. 

애플리케이션 내부에서 서버간 데이터의 이동이 필요하다면? 

* 웹 서버에서 받아온 결제 데이터를 분석 서버로 전달
* 사용자의 결제 데이터를 이메일 서버로 넘기기 등

<img src="./images//image-20240504161817419.png" width = 650>

### 데이터의 저장

메시지의 저장과 식별

<img src="./images//image-20240504161859117.png" width =650>

카프카는 토픽이라는 개념에 저장. 

레디스에서는 하나의 stream 자료구조가 하나의 stream을 의미한다.

레디스 stream에서는 각 메시지는 시간과 관련된 유니크한 ID를 가지며 이 값은 중복되지 않는다

```
<millisecondsTime>-<sequenceNumber>
```

* 2개의 파트로 나뉜다.
* 밀리세컨드 : 레디스 노드 로컬 시간. 
* 시퀀스 파트는 밀리세컨드에 저장된 데이터의 순서. 64bit로 어마어마하게 큰 수

이 유니크한 ID값이 곧 시간을 의미하기 때문에 시간을 이용해 특정 데이터를 검색할 수 있다.

#### 스트림 생성과 데이터 입력

레디스에서는 XADD를 이용해 새로운 이름의 stream에 데이터를 저장하면 저장과 동시에 stream 자료구조가 생성된다

```
XADD Email * subject "forst" body "hello?"
"1659114481311-0" // 반환되는 id값
```

* Email이라는 이름의 스트림 생성. 존재하지 않는경우 스트림 생성, 존재하면 메시지만 추가

* `*` 필드는 저장되는 데이터의 ID. `*`로 입력할 경우 레디스에서 자동으로 생성되는 타임스탬프 ID를 사용 

메시지는 키 값 쌍으로 저장된다. (first, hello)

TTL도 지정 가능하다

```
XADD Push * userid 1000 ttl 3 body Hey
```

만약 기존에 사용하던 ID를 이용해 메시지를 구분하고 싶다면?

```
XADD mystream 0-1 "hello" "world"
```

* 이경우 0-1보다 작은 id값은 저장할 수 없다

#### 스트림 데이터 조회

레디스 stream에서 데이터를 2가지 방식으로 읽을 수 있다.

1. 실시간으로 처리되는 데이터 리스닝
2. ID를 이용해 필요한 데이터 검색

```
// 실시간 리스닝
XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID...]
```

ex

```
XREAD BLOCK 0 STREAMS Email 0
```

* BLOCK 0는 더이상 스트림에 데이터가 없더라도 연결을 끊지말고 계속 리스닝하라는 의미
* BLOCK 1000이면 1000MS까지만 연결 유지하며 대기
* STREAMS Email 0는 Email 스트림 저장된 데이터중 0보다 큰 값을 읽어오라는 의미. 즉 처음부터 저장된 모든 데이터를 읽어오라는것

커맨드를 실행한 이후의 메시지만을 가져오고 싶다면? 0대신 $를 입력

* $는 저장된 최대 ID

ID를 지정해서 가져오고 싶다면? 0대신 ID를 입력

```
XREAD BLOCK 0 STREAMS Email 0 16591151808983
```



**특정한 데이터 조회** 

```
XRRANGE key start end [COUNT count]
XREVRANGE key end start [COUNT count]
```

XRANGE 커맨드를 이용하면 ID를 이용해 원하는 시간대의 데이터를 조회할 수 있다.

stream에 저장된 ID 중 가장 작은 ID 값을 지정하고 싶을 때에는 **-**, 제일 마지막 ID 값을 지정하고 싶을 때에는 **+** 기호를 사용하자. XREVRANGE 는 XRANGE의 역순으로 데 이터를 조회하고 싶을 때 사용한다.

예를 들어 Email stream에 저장된 모든 데이터를 가져오고 싶다면 다음과 같은 커맨드를 사용하면 된다.

```
XRANGE Email - +
```

XRANGE 커맨드는 커맨드 수행하는 시점에 stream에 저장된 모든 데이터를 반환하고 종료하고, 이후 데이터는 반환하지 않는다.

입력한 타임스탬프를 포함한 데이터를 조회할수도 있다.

만약 입력한 데이터를 포함하지 않고, 그 다음 데이터부터 조회하고 싶을 때에는 입력한 타임스탬프 값에 ( 문자를 사용할 수 있다.

```
XRANGE Email 1659114481311-0 +
또는

XRANGE Email (1659114481311-0 +
```

LIMIT 옵션을 이용해서 조회할 데이터의 개수를 제한하는 것도 가능하다.

### 소비자와 소비자 그룹

레디스 stream에서도 XREAD 커맨드를 여러 소비자가 수행한다면 팬아웃이 가능하다.

<img src="./images//image-20240504162915108.png" width = 700>

만약 같은 데이터를 여러 소비자가 나눠서 가져가기 위해서는 어떻게 해야 할까? 같은 역할을 하는 여러 개의 소비자를 이용해 메시지를 병렬 처리함으로써 서비스의 처리 성능을 높일 수 있다.

이때 처리되는 메시지의 순서가 보장돼야 하는 경우와 그렇지 않은 경우에 대해 처리할 수 있다.

레디스 stream에서는 데이터가 저장될 때마다 고유한 ID를 부여받아 순서대로 저장 된다. 따라서 소비자에게 데이터가 전달될 때, 그 순서는 항상 보장된다.

반면 카프카에서 유니크 키는 파티션 내에서만 보장되기 때문에 소비자가 여러 파티션에서 토픽을 읽어갈 때에는 데이터의 순서를 보장할 수 없다.

레디스 스트림에서는 카프카와 달리 메시지가 전달되는 순서를 신경쓰지 않아도 된다. 

<img src="./images//image-20240504163201100.png" width = 700>

* 레디스 스트림에서는 소비자 그룹 내의 한 소비자는 다른 소비자가 아직 읽지 않은 데이터만을 가져간다..

소비자 그룹에 속한 이메일 서버 (2)가 129-0이라는 ID의 메시지를 읽어갔다면, 

그다음 이메일 서버 (1)이 데이터를 읽어갈 때에는 133-0을 읽어갈 수 있다. 

각 요청 시마다 소비자는 stream에서 차례대로 데이터를 가져오게 된다.

레디스 stream에서 소비자 그룹을 생성하려면 XGROUP 커맨드를 사용한다.

```
XGROUP CREATE Email EmailServiceGroup $
```

* $는 현재시점 이후의 데이터부터 리스닝하겠따는것을 의미한다.

소비자 그룹을 이용해 데이터를 읽어오고 싶다면 XREADGROUP 커맨드를 사용하면 된다. 

XREADGROUP 은 XREAD와 같은 형태로 데이터를 응답하지만, 지정한 소비자 그룹을 통해서 데이터를 읽길 원한다는 것을 뜻한다.

```
XREADGROUP GROUP EmailServiceGroup emailService1 COUNT 1 STREAMS Email >
```

* EmailServiceGroup에 속한 emailService1라는 소비자가 Email stream에 있는 1개의 메시지를 읽어오고자 할 때 사용하는 커맨드.
* 그룹 내에서 소비자를 고유하게 식별할 수 있는 이름을 지정해야 한다.
* `>` 는 전달되지 않았던 새로운 메시지를 전달하라는 의미 .

만약 다른 소비자에게 읽히지 않는 데이터가 있다면, 데이터를 1개 가져오고, 읽힌 데이터 뿐이라면 nil을 반환한다.

* 각 소비자는 COUNT 커맨드를 이용해 소비할 메시지를 직접 가능 

만약 `>` 대신 0 또는 다른 숫자 ID 입력시 입력한 ID보다 큰 ID 중 대기 list에 속하던 메시지를 반환한다.

XREADGROUP을 사용해 stream 데이터를 읽어올 때, 읽어오는 동작 자체가 소비자 그 룹에 영향을 미치기 대문에 이를 일종의 쓰기 커맨드로 생각해야 한다. 그렇기 때문에 **이 커맨드는 마스터에서만 호출할 수 있다.**

stream과 소비자 그룹은 독립적으로 동작할 수 있다. 

즉, Email이라는 stream 메시지를 읽어가기 위한 소비자 그룹은 **다수 존재할 수 있으며**, **각각 독립적으로 동작한다**.

 소비자 그룹 1의 소비자가 a라는 메시지를 읽었다면 같은 그룹에서는 그 메시지를 다시 읽을 수 없지만, <u>소비자 그룹 2 혹은 일반적인 다른 소비자에서는 해당 메시지를 읽을 수 있다</u>. **하나의 소비자 그룹에서 여러 개의 stream을 리스닝하는 것도 가능하다.**

```
XGROUP CREATE Email bigroup 0
XGROUP Create Push bigroup 0

XREADGROUP GROUP BIGroup BI1 COUNT2 STREAMS Email Push > >
```

* XGROUP 커맨드를 이용해 각 stream에 BIGroup이라는 이름을 가진 소비자 그룹을 먼저 생성한 뒤, XREADGROUP 커맨드를 이용해서 데이터를 읽으면 BIGroup은 Email과 push 2개의 stream을 리스닝할 수 있게 된다

### ACK와 보류 리스트(pending list)

메시지 브로커를 여러 서비스가 이용할때, 예상치못한 장애로 인해 이를 인지하고 재처리할 수 있는 기능이 필요하다.

레디스 Stream에서는 소비자 그룹에 속한 소비자가 메시지를 읽어가면 각 소비자별로 읽어간 메시지에 대한 리스트를 새로 생성하며,

마지막으로 읽어간 데이터의 ID로 last_delivered_id값을 업데이트 한다.

* last_delivered_id값은 해당 소비자 그룹에 마지막으로 전달한 ID를 파악해 중복으로 동일한 메시지를 전달하지 않기 위해 사용된다.

 ![image-20240504225303708](./images//image-20240504225303708.png)

* 이메일 서비스 1소비자가 2개의 메시지를 가져갔고, 서비스가 1개의 메시지를 가져갔다. 
* 즉 남은 1개 메시지는 보류 stream에 대기

레디스 stream은 소비자별로 pendling list를 만들고, 어떤 소비자가 어떤 데이터를 읽어갔는지 인지하고 있다. 

![image-20240504225603304](./images//image-20240504225603304.png)

만약 이메일 서비스 2가 데이터가 처리됐다는 ACK를 보내게 되면 레디스 stream은 이메일 서비스2의 pending list에서 ACK를 받은 메시지를 삭제한다. 

즉 pending list를 이용해 어떤 소비자가 어떤 데이터를 처리했는지, 처리못했는지를 파악할 수 있다.

예를들어 **이메일 서비스에 문제가 발생한 경우 stream의 pending list에 데이터가 남아있는경우 다시 해당 데이터를 불러와서 처리하고 ACK를 보내서 데이터 유실을 막을 수 있다.** 

 또한, 1번 서버에 장애가 발생해 해당 서버를 사용 못하지만, 작업중이고 ACK하지 않은 메시지가 있을 경우 다른 서버에서 처리해야할 수 있다. 이경우 1번서버의 pending 리스트에 남아있는 메시지를 확인하여 처리할 수 있다.

따라서 **XREADGROUP**를 이용해 소비자 그룹 형태로 데이터 를 읽었을 때, 데이터 처리가 완료된 후에 애플리케이션에서 **XACK**를 주기적으로 전송 하는 작업이 필요하다.



현재 소비자 그룹에서 보류중인 리스트 확인하는 커맨드

```
XPENDING <key> <groupname> [<start-id> <end-id> <count> [<consumer-name>]]

XPENDING Email EmailServiceGroup
1) (integer) 9
2) "1659114481311-0"
3) "1659170735630-9"
4) 1) 1) "es1"
		  2) "1"
   2) 1) "es2"
      2) "1"
   3) 1) "es3"
      2） "7"
```

* 첫번째 값은 ACK를 받지 못해 보류중인 메시지 개수
* 두번째, 세번째 값은 각각 보류중인 메시지 ID 최솟값, 최댓값

* 그 뒤로는 소비자별로 보류중인 리스트가 몇개있는지 알 수 있다.

XACK를 이용하여 데이터 처리 ACK를 보낼 수 있다.

```
XACK key <groupname> ID

XACK Email EmailServiceGroup 16591144-0
```



### Redis Stream에서의 at most once vs. at least once vs. exactly once

* at most once : 최대 한번. 소비자는 메시지를 받자마자 처리하기전에 ACK를 보낸다. 
  * 속도는 향상되지만, 소비자에 문제가 생긴 경우 처리하지 못한 데이터를 잃음. 메시지가 손실되더라도 빠른 응답이 필요한 경우 사용
* at least once : 최소 한번. 소비자는 받은 메시지를 모두 처리한뒤 ACK를 보냄. 
  * ACK 전송이 지연돼, 메시지는 처리됐지만 ACK를 못보내는 현상이 생길 수 있음.
  * 중복문제가 발생할 수 있다. 
* exactly once : 정확히 한번. 무조건 한번씩은 전송되는것을 보장
  * 레디스 stream을 이용하면 set등의 추가 자료구조를 이용해 이미 처리된 메시지인지 아닌지를 확인하는 과정이 필요하다

### 메시지의 재할당

레디스는 소비자에게 장애가 날경우 대비해 소비자별 pending list를 유지한다.

만약 특정 소비자 서버에 장애가 발생한다면 다른 소비자가 대신 처리해야 한다.

XCLAIM 커맨드를 이용하면 메시지의 소유권을 다른 소비자에게 할당할 수 있다.

```
XCLAIM <key> <group> consumer <min-idle-time> <ID-1> <ID-2> ... <ID-N>
```

* **key**: 스트림의 이름
* **group**: 소비자 그룹의 이름
* **consumer**: 메시지를 할당받을 소비자의 이름
* **min-idle-time**: 메시지가 소비되지 않고 대기한 최소 시간(밀리초 단위).
* **id**: 재할당할 메시지 ID
* min-idle-time :  메시지가 보류상태로 최소 대기시간을 초과한 경우에만 소유권을 변경할 수 있도록 해서 같은 메시지가 2개의 다른 소비자에게 중복으로 할당되는 것을 방지한다.

 Emailservice3라는 소비자에 문제가 생겨, 

이 소비자가 처리하던 메시지를 다른 소비자인 Emailservice 1, 2가 가져가기 위해 XCLAIM 커맨드를 실행하는 상황을 가정

```
ExmailService 1: XCLAIM Email EMailServiceGroup EmailService3 3600000 16265694-0
ExmailService 2: XCLAIM Email EMailServiceGroup EmailService3 3600000 16265694-0
```

* 위 예제처럼, 먼저 실행되는 커맨드가 실행되면 보류시간이 즉시 0으로 재설정 되어서, EmailService2의 XCLAIM 커맨드에서의 최소 대기시간(3600000)보다 메시지의 보류시간이 짧기때문에 이 커맨드는 무시되며, 중복 메시지 할당을 방지할 수 있다.

> XCLAIM 커맨드는 메시지가 지정된 `min-idle-time` 동안 소비되지 않았을 때만 메시지를 다른 소비자로 이전할 수 있습니다. 따라서, 메시지의 현재 `idle time`이 `min-idle-time`보다 작다면, 해당 메시지는 다른 소비자로 이전되지 않습니다.

### 메시지의 자동 재할당

XCLAIM을 사용해 보류중인 메시지를 확인하고 특정 소비자에게 직접 소유권을 재할당하는 작업이 번거로울 수 있다.

소비자가 직접 보류했던 메시지 중 하나를 자동으로 가져와서 처리할 수 있도록 하는 **XAUTOCLAIM** 커맨드는 할당 대기중인 다음 메시지의 ID를 반환하는 방식으로 동작하기 떄문에 반복적 호출을 가능하게 한다.

```
XAUTOCLAIM <key> <group> <consumer> <min-idle-time> <start> [COUNT count] [JUSTID]
```

다음과 같이 지정한 소비자 그룹에서 최소 대기 시간을 만족하는 보류 중인 메시지가 있다면 지정한 소비자에 소유권을 재할당하는 방식으로 동작한다.

```
XAUTOCLAIM Email EmailServiceGroup es1 360000 0-0 count 1
```

# 7. 레디스 데이터 백업 방법

백업과 복제는 목적부터 다르다. 복제하더라도 백업은 필요하다. 

만약 실수로 데이터를 삭제하는 커맨드가 실행되면 바로 복제본에 전달되므로, 복제 구조만으로는 데이터를 안전하게 유지할 수 없다.

데이터를 안전하게 저장하기 위해 RDB , AOF 두가지 백업방식을 지원한다. 

* AOF : 모든 쓰기 작업을 차례대로 기록하며, 복원시 파일 다시 읽어가며 데이터세트 구성
  * RESP(레디스 프로토콜) 형태로 저장 
* RDB : 일정시점에 메모리에 저장된 전체 데이터를 저장(snapshot)
  * 바이너리 형태로 저장. 

<img src="./images//image-20240505011931487.png" width = 450>

RDB의 경우 시점 단위로 여러 백업본을 저장하고 AOF 보다 복원이 빠르지만, 특정 시점으로는 복구 불가능

AOF는 RDB파일보다 크고 주기적으로 압축해 재작성하지만, 원하는 시점으로 복구 가능. 

두 옵션 동시 사용가능하며, 가능하면 두가지 백업 방식을 동시에 사용하는게 권장된다.

두 옵션 사용시 레디스는 AOF를 우선적으로 복원시 사용한다.

* AOF가 내구성이 더 보장된다고 판단한다. 



레디스 서버는 재시작 될때만 데이터를 복원하며, AOF파일이나 RDB파일이 존재하는지 확인한 뒤 파일을 로드한다. 

## 레디스에서 데이터를 영구 저장하기

## RDB 방식의 데이터 백업
원하는 시점마다 RDB 파일이 생성 가능하다.

원격 저장소로 파일을 옮겨 2차 백업을 수행할 수도 있다. (데이터 센터 장애등 방지 가능 )

장애 발생시 손실 가능성을 최소화 해야한다면 RDB만을 이용한 백업은 적절하지 않다.

저장 시점부터 장애가 발생한 직전까지의 데이터는 손실될 수 있기 때문이다. 

RDB 파일 생성방법은 아래 크게 3가지다 

### 1. 특정 조건에 자동으로 RDB 파일 생성

```
save <기간(초)> <기간 내 변경된 키의 개수>
dbfilename <RDB파일명>
dir <RDB파일이 저장될 경로>
```

* 기본값은 dump.rdb

```
save 900 1

save 300 10

save 60 10000
```

redis. conf에 위와 같은 조건으로 save 옵션을 설정한다면 인스턴스는 다음과 같은 상황에서 RDB 파일을 생성한다.

- ﻿﻿900초(15분) 동안 1개 이상의 키가 변경된 경우
- ﻿﻿300초(5분) 동안 10개 이상의 키가 변경된 경우
- ﻿﻿60초(1분) 동안 10,000개 이상의 키가 변경된 경우

만약 RDB 파일을 저장하고 싶지 않다면 save ""와 같이 빈 문자열로 설정해서 옵션 을 비활성화할 수 있다

```
# 현재 적용된 save 옵션 확인
CONFIG GET save

# save 옵션 초기화
CONFIG SET save ""

# redis.conf 파일 재작성
CONFIG REWRITE
```

* 실행중인 레디스 인스턴스에서 파라미터 수정시 직접 CONFIG SET 명령어로 수정하고 redis.conf 파일 재작성을 해줘야 영구 저장된다.  

### 2. 수동으로 RDB 파일 생성

SAVE, BGSAVE 커맨드로 원하는 시점에 가능하다.



SAVE는 동기방식으로 파일을 저장하며, 완료될떄까지 모든 클라이언트의 명령을 차단한다.

때문에 일반적인 운영환경에서는 SAVE커맨드를 되도록 사용하지 않는것이 좋다



BGSAVE는 fork를 호출해 자식 프로세스를 생성하며, 생성된 자식프로세스가 백그라운드에서 RDB파일을 생성한 뒤 종료된다

* 만약 이미 백그라운드로 데이터가 저장되고있을떄 BGSAVE를 수행하면 에러를 반환한다.

RDB파일이 정상적으로 저장되었는지 LASTSAVE 커맨드로 확인할 수 있다.

### 3. 복제를 사용할 경우 자동으로 RDB 파일 생성

REPLICAOF 커맨드를 이용해 복제를 요청하면 마스터 노드에서는 RDB 파일을 새로 생성해 복제본에 저장한다.

* 복제가 끊어졌다 복제 재연결 하더라도 마스터 노드는 복제본으로 RDB 파일을 전송한다. 

## AOF 방식의 데이터 백업
실수로 FLUSHALL 커맨드로 모두 날렸다 해도, AOF 파일을 직접 열어 FLUSHALL 커맨드만 삭제한 뒤 레디스 재시작 하면 커맨드를 실행하기 직전까지 데이터를 복구할 수 있다.



설정 파일에서 appendonly 옵션을 yes로 설정하면 AOF파일에 주기적으로 저장된다. 

AOF 파일은 appenddirname에서 지정한 경로와 appendfilename 옵션 에 설정한 이름으로 생성된다.

```
appendonly yes 
appendfilename "appendonly.aof" 
appenddirname "appendonlydir"
```

* 디폴트 이름은 appendonly.aof 파일.
* 버전 7.0부터 AOF파일을 여러 개로 저장되며 appenddirname에서 지정된 디렉터리 하위에 저장된다.

AOF파일에는 데이터가 변경되는 커맨드만 기록하기 떄문에 DEL 같은 작업은 기록되지 않는다. 

list에서 블로킹 기능을 지원하는 BRPOP커맨드는 AOF에는 저장될떄 RPOP으로 기록된다. (굳이 블로킹을 명시할 필요가 없기 때문)

기존 string 값에 사용자가 입력한 부동소수점 값을 더해주는 INCRBYFLOAT 커맨드도 AOF 파일에는 그대로 기록되지 않는다.

* 아키텍처에 따라 부동소수점 처리 방식이 다르기 때문에 AOF파일에는 증분 후 값을 직접 SET하는 커맨드로 변경됌 

### AOF 파일을 재구성하는 방법

왜 필요한가? -> 파일이 점점 커지므로 주기적으로 압축 재구성 하는 작업이 필요하다.

RDB처럼 특정 조건에 자동으로 재구성 또는 수동으로도 재구성 할 수 있다. 



**재구성 과정**

기존 AOF파일을 사용하지 않고 레디스 메모리에 있는 데이터를 읽어와서 새로운 파일로 저장하는 형태로 동작한다.

AOF 파일 재구성시에도 fork로 자식 프로세스를 생성하여 동작한다. 

**버전 7 이전까지의 재구성 과정**

<img src="./images//image-20240505013214807.png" width = 650>

1. ﻿﻿﻿﻿레디스는 fork를 이용해 자식 프로세스를 생성한다. 생성된 자식 프로세스는 레디스 데이터를 읽어와 신규로 생성한 임시 파일에 저장한다.
2. ﻿﻿﻿﻿백그라운드로 (1)의 과정이 진행되는 동안 레디스 데이터가 변경된 내역은 기존의 AOF 파일과 인메모리 버퍼에 동시에 저장된다.
3. ﻿﻿﻿﻿(1)의 AOF 재구성 과정이 끝나면 인메모리 버퍼에 저장된 내용을 (1)의 임시 파일 마지막에 추가한다.
4. ﻿﻿﻿﻿생성된 임시 파일로 기존 AOF 파일을 덮어 씌운다.

단점 : (2)과정에서 RDB파일이 저장되는 동안 데이터가 변경된 동일한 로그가 AOF파일과 인메모리 버퍼에 이중으로 저장되어서 수동으로 AOF 파일을 처리할 때 관리가 복잡할 수 있다.

**버전 7 이후 AOF 파일의 저장 구조**

![image-20240505013342843](./images//image-20240505013342843.png)

기본이 되는 바이너리 형태의 RDB파일, 증가하는 RESP의 텍스트 형태의 AOF 파일로 나눠서 데이터를 관리한다.

* 레디스가 바라보고 있는 파일이 어떤것인지 기록하는 매니페스트 파일

AOF 재구성될때마다 AOF를 구성하고 있는 각 RDB와 AOF의 파일명의 번호 그리고 매니페스트 파일 내부의 seq 값도 1씩 증가

**버전 7 이후 AOF 재구성 과정**

![image-20240505013539563](./images//image-20240505013539563.png)

1. ﻿﻿﻿﻿레디스는 forK를 이용해 자식 프로세스를 생성하고 자식 프로세스는 레디스 데이터를 읽어와 신규로 생성한 임시 파일에 저장한다.
2. ﻿﻿﻿﻿백그라운드로 (1)의 과정이 진행되는 동안 레디스 메모리의 데이터가 변경된내역은 신규 AOF 파일에 저장된다.
3. ﻿﻿﻿﻿(1)의 AOF 재구성 과정이 끝나면 임시 매니페스트 파일을 생성한 뒤, 변경된 버전으로 매니페스트 파일 내용을 업데이트한다.
4. ﻿﻿﻿﻿생성된 임시 매니페스트 파일로 기존 매니페스트 파일을 덮어 씌운 뒤, 이전 버 전의 AOF, RDB 파일들을 삭제한다.

> 기존 버전의 (2), (3) 단계의 비효율을 줄일 수 있다. 

레디스 AOF 파일 재구성 과정은 모두 순차 입출력(sequential i/o)를 사용하기 때문에 모든 과정이 굉장히 효율적이다.

* 파일 내에서 직접 데이터를 검색할 필요가 없기 떄문에 랜덤 I/O가 없어 매우 효율적

### 자동 AOF 재구성

```
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

auto-aof-rewrite-percentage는 AOF 파일을 다시 쓰기 위한 시점을 정하기 위 한 옵션이다. 

마지막으로 재구성됐던 AOF 파일의 크기와 비교해, 현재의 AOF 파일이 **지정된 퍼센트만큼 커졌을 때 재구성을 시도한다.** 

마지막으로 저장된 AOF 파일의 크기는 레디스에서 INFO Persistence 커맨드로 확인할 수 있는 aof_base_size 값 이다.

```
INFO Persistence

aof_current_size:186830
aof_base_size:145802
```

* auto-aof-rewrite-percentage가 100이면, aof_current_size가 aof_base_size의 100%인 291604가 되면 자동으로 재구성을 시도한다.



### 수동 AOF 재구성

BGREWRIEOF 커맨드를 이용하여 원하는 시점에 AOF를 재구성할 수 있다.



### AOF 타임스탬프

```
aof-timestamp-enabled no
```

설정 파일에서 aoftimestamp-enabled 옵션을 활성화시키면 AOF 파일에 데이터가 저장될 때 타임스탬프도 함께 저장된다.

```
#TS:1669532434
...명령어
...명령어2
```

이를 이용해서 특정 시간에서의 복원이 가능하다. 

레디스에서 제공하는 redis-check-aof 프로그램을 사용해 FLUSHALL이 실행되 기 전까지로 데이터를 복구할 수 있다. 

예제에서는 리눅스 타임스탬프를 1669532845로 돌려봤다.

```
src/redis-check-aof --truncate-to-timestamp 1669532845 appendonlydir/appendonly.aof.manifest
```

* 돌린 타임스탬프까지의 데이터만 AOF 파일에 남게된다

이 옵션은 레디스 버전 7부터 지원하며, 이옵션을 켜서 AOF 파일에 #TS가 저장되면 이전버전의 레디스와 호환되지 않는다



### AOF 파일 복원

redis-check-aof 프로그램 사용시 --fix 옵션을 사용하여 해결할 수 있다.

```
src/redis-check-aof --fix appendonlydir/appendonly.aof.manifest
```

* 단 이방식도 원본 파일을 변경하므로 원본 파일을 옮겨두고 하는것이 좋다 

### AOF 파일의 안전성
AOF는 RDB보다 얼마나 안전하다고 할 수 있을까?

레디스가 파일에 저장시 WRITE라는 시스템콜 사용시 FSYNC를 사용하면 좋다

* WRITE는 바로 내려쓰지 않고, 커널이 여유있꺼나 최대 지연시간인 30초에 도달하면 그때서야 쓴다
* FSYNC는 OS버퍼에 저장된 내용을 실제로 디스크에 강제로 내리도록 하는 시스템 콜. 부하가 있더라도 무조건 디스크에 플러시함

AOF 파일 저장시 APPENDFSYNC 옵션을 이용하면 강제로 내구성을 제어할 수 있다.

다음과 같은 옵션이 있따.

- ﻿﻿APPENDFSYNC no: AOF 데이터를 저장할 때 WRITE 시스템 콜을 호출한다. 데이터는 커널 영역에 데이터가 잘 저장되는지만 확인하기 때문에 **쓰기 성능이 가장 빠르다.**
- ﻿﻿APPENDFSYNC always: AOF 데이터를 저장할 때 항상 WRITE와 FSYNC 시스템 콜을 함께 호출한다. 즉, 매번 쓰고자 하는 데이터가 파일에 정확하게 저장되는 것을 기다리기 때문에 **쓰기 성능은 가장 느리다.**
- ﻿﻿APPENDFSYNC everysec: 데이터를 저장할 때 WRITE를 호출하며, 1초에 한 번씩 FSYNC 시스템 콜을 호출한다. **성능은 no 옵션을 사용했을 때와 거의 비슷하다.**

일반적인 경우 everysec 옵션을 사용하는것이 좋다 



## 백업을 사용할 때 주의할 점

인스턴스 maxmemory값은 실제 서버 메모리보다 여유를 갖는게 좋다

* Redis의 `maxmemory` 설정은 Redis 인스턴스가 사용할 수 있는 최대 메모리 양을 지정하는 구성 옵션

왜냐하면 fork()로 자식 프로세스를 생성하는데 이때 부모 프로세스만큼 메모리를 그대로 잡아먹기 때문이다.

이때 레디스는 Copy-On-WriteCow 방식을 이용해 메모리상의 데이터를 하나 더 복사하는 방법을 이용해 백업을 진행하면서도 클라이언트의 요청 사항을 받아 메모리의 데이터를 읽고 수정하는 작업을 진행할 수 있다.

![image-20240505014710640](./images//image-20240505014710640.png)

최악의 경우 기존 메모리 용량의 2배를 사용하게 될 수 있으며, maxmemory값이 너무 커진 경우 copy-on-write 동작으로 인해 서버가 OOM으로 다운될 수도 있다. 

따라서 레디스의 maxmemory 옵션은 실제 메모리보다 여유를 갖고 설정하는 것이 안 정적이다. 

예를 들어 다음 표와 같이 서버의 메모리 유형에 따라 적절한 maxmemory 값 을 지정하는 것이 좋다.

| RAM  | Maxmemory | 비율 |
| ---- | --------- | ---- |
| 2GB  | 638MB     | 33%  |
| 4GB  | 2048MB    | 50%  |
| 8GB  | 4779MB    | 58%  |
| 16GB | 10240MB   | 63%  |
| 32GB | 21163MB   | 65%  |
| 64GB | 43008MB   | 66%  |



# 8. 복제

가용성 : 서비스 안정성을 측정하는 데 사용되는 지표.

Availability= Available for Use Time / Total Time

- **분자 (Numerator)**: **Available for Use Time**은 시스템이 실제로 사용 가능한 시간을 나타냅니다. 즉, 시스템이 작동하고 사용자가 정상적으로 사용할 수 있는 시간을 의미합니다.
- **분모 (Denominator)**: **Total Time**은 관찰 기간 동안의 전체 시간을 의미하며, 이는 시스템이 작동해야 하는 전체 시간을 포함합니다. 이 시간에는 정상 작동 시간뿐만 아니라, 정지 시간(계획된 유지보수나 예기치 않은 다운타임 포함)도 포함됩니다.

레디스의 고가용성 확보를 위해 두가지 기능이 필요하다.

* 복제 : 마스터 노드를 복제 노드로 복사하는 기능
* 자동 페일오버 : 마스터 노드 장애시 클라이언트 연결을 자동으로 복제본 노드로 리디렉션 기능. 



## 레디스에서의 복제 구조

복제 노드가 필요한 이유.

* 마스터가 다운됐을 떄 대신 사용 가능한 노드
* 복제본은 트래픽을 분산시켜 감소시키는 역할.
* 백업을 복제본으로 수행시 백업 작업이 서비스에 영향을 최소한으로 미치게 함.

레디스는 멀티 마스터 복제를 제공하지 않는다(클러스터 말고 복제 구조)

모든 입력은 마스터 노드에서 이뤄지고 복제본은 그대로 받는다. 



### 복제 구조 구성하기

```
REPLICAOF <master-ip> <master-port>

masterauth your_master_password // config 파일에서 작성하는것.  복제본에서 지정해야함. 

// 아래는 config파일이 아닌 커맨드로 지정하는것
CONFIG SET masterauth password

CONFIG REWRITE
```

<img src="./images//image-20240505015236223.png" width = 450>

## 복제 메커니즘
버전 7 이전에서는 repl-diskless-sync 옵션의 기본값은 no이며, 기본적으로 그림 8-5와 같은 방식으로 복제 연결이 이뤄졌다.

<img src="./images//image-20240505015432628.png" width = 550>

1. ﻿﻿﻿﻿REPLICAOF 커맨드로 복제 연결을 시도한다.
2. ﻿﻿﻿﻿마스터 노드에서는 fork로 자식 프로세스를 새로 만든 뒤 RDB 스냅숏을 생성 한다.
3. ﻿﻿﻿﻿(2)번 과정 동안 마스터 노드에서 수행된 모든 데이터셋 변경 작업은 레디스 프로토콜RESP 형태로 마스터의 복제 버퍼에 저장된다.
4. ﻿﻿﻿﻿RDB 파일이 생성 완료되면 파일은 복제본 노드로 복사된다.
5. ﻿﻿﻿﻿복제본에 저장됐던 모든 내용을 모두 삭제한 뒤 RDB 파일을 이용해 데이터를로딩한다.
6. ﻿﻿﻿﻿복제 과정 동안 버퍼링됐던 복제 버퍼의 데이터를 복제본으로 전달해 수행시킨다.

이와 같은 복제 과정에서 복제 속도는 디스크 IO 처리량에 영향을 받는다. 마스터에 서 RDB 파일을 저장하는 시간, 복제본에서 RDB 파일을 읽어오는 과정 모두 디스크 1/O 속도에 영향을 받기 때문이다. 만약 로컬 디스크에 RDB 파일을 쓰는 것이 아니 라 NAS와 같은 원격 디스크를 사용한다면 디스크 I/0 속도는 더욱 느려질 수 있다.



버전 7 이후에서는 디스크를 사용하지 않고 복사해서 성능을 향상시켰다

* repl-diskless-sync 옵션 default가 yes

<img src="./images//image-20240505015556233.png" width = 550>

1. ﻿﻿﻿﻿REPLICAOF 커맨드로 복제 연결을 시도한다.
2. ﻿﻿﻿﻿마스터 노드는 소켓 통신을 이용해 복제본 노드에 바로 연결하며, RDB 파일은 생성됨과 동시에 점진적으로 복제본의 소켓에 전송된다.
3. ﻿﻿﻿﻿(2)의 과정 동안 마스터 노드에서 수행된 모든 데이터셋 변경 작업은 레디스 프로토콜RESP 형태로 마스터의 복제 버퍼에 저장된다.
4. ﻿﻿﻿﻿소켓에서 읽어온 RDB 파일을 복제본의 디스크에 저장한다.
5. ﻿﻿﻿﻿복제본에 저장된 모든 데이터를 모두 삭제한 뒤 RDB 파일 내용을 메모리에 로딩한다.
6. ﻿﻿﻿﻿복제 버퍼의 데이터를 복제본으로 전달해 수행시킨다.

소켓에서 읽어온 RDB 데이터를 바로 메모리에 로드하지 않고, 디스크에 먼저 저장한다. 이후 RDB 파일을 로드한다.

디스크의 I/0가 느리고 네트워크가 빠른 경우 디스크를 사용하지 않는 복제 방식을 사용하는 것이 더 빠르게 복제 연결을 완료할 수 있는 방법이다.

하지만 디스크를 사용하지 않는 방식에서 이미 하나의 복제본으로 복제 연결이 시작된 경우에는 **복제 과정이 끝나기 전까지 다른 복제본과의 연결은 수행될 수 없으며**, 다른 복제본들은 하나의 복제 연결이 끝날때까지 큐에서 대기해야 한다. 

이를 방지하기 위해 repl-diskless-sync-delay 옵션을 사용할 수 있다.

* 새로운 복제 연결이 들어오면 기본 5초(기본값)를 기다린 뒤 복제 연결을 시작한다. 
* 이 기간 내에 또다른 복제 연결이 들어오면 마스터는 여러 복제본으로 소켓을 연결해 한번에 여러개의 복제본에 RDB 파일을 전송할 수 있다.
* 이 옵션은 활성화하는것이 좋다 

### 비동기 방식으로 동작하는 복제 연결

정상적으로 복제 연결이 된 상태에서 마스터에서 복제본으로의 데이터 전달은 비동기방식asymchronous 으로 동작한다.

클라이언트는 데이터 입력시마다 복제본에 데이터가 제대로 전달되었는지 확인하지 않기 때문에 복제 구조를 사용하더라도 짧은 지연시간과 높은 성능을 갖는다.

### 복제 ID

모든 레디스 인스턴스는 replication id를 갖고 있다. 

레디스 내부 데이터가 수정되는 모든 커맨드 수행할 때마다 오프셋이 증가한다. 

INFO REPLICATION 커맨드를 사용하면 복제 연결 상태를 확인할 수 있다.

마스터와 레플리카의 offset이 같으면 복제가 정확하게 된것이고, 아니면 아직 진행중 또는 불일치 일 수 있다. 





### 부분 재동기화

복제 연결이 끊길 때마다 마스터에서 RDB 파일을 새로 내려 복제본에 전달하는 과정을 거친다면 네트워크가 불안정한 상황에서 복제 기능을 사용하는 레디스의 성능은 급격하게 나빠질 것이다. 

이를 방지하기 위해 레디스는 부분 재동기 호출(partial resynchronization) 기능을 사용해 안정적으로 복제 연결을 유지한다.

![image-20240505020250874](./images//image-20240505020250874.png)

마스터는 커넥션 유실을 대비해 백로그 버퍼라는 메모리 공간에 복제본에 전달한 커맨드 데이터를 저장해둔다.

복제본은 PSYNC 커맨드를 호출해 자신의 replication id와 오프셋을 마스터에 전달한 후 백로그에 저장된 내용을 복제본에 전달해 RDB  파일을 새로 저장하지 않고 백로그 내용을 보내 부분 재동기화를 수행한다. 

* 그러나 백로그 버퍼에 원하는 데이터가 없거나, replication id가 마스터와 일치하지 않는다면 전체 재동기화 (full resync)를 시도한다. 

### Secondary 복제 ID
한개의 복제본 그룹 내의 모든 레디스 노드는 동일한 replication_id를 갖는다 

레디스는 2개의 복제 ID를 갖는다. 왜? -> 마스터로 승격되는 복제본 때문. 페일오버 이후 새로운 마스터에 연결된 복제본이 전체 재동기화 대신 부분 재동기화로 성능 향상을 얻기 때문 

### 읽기 전용 모드로 동작하는 복제본 노드

복제 노드는 기본으로 read only 모드로 동작한다. replica-read-only 옵션을 이용해 해제할 수 있는데, 이 경우 복제본 노드의 데이터가 변경되더라도 복제본이 재시작되거나 마스터와 전체 재동기화 수행시 데이터가 유실되므로 주의해야 한다. 

또한 복제 로컬에서만 데이터가 유지되기 때문에 다른 노드로는 전파되지 않으며 일치하지 않는 문제가 발생한다.  

### 유효하지 않는 복제본 데이터

복제본의 데이터와 마스터의 데이터가 정확하게 일치하지 않는 경우의 데이터를 의미한다.

* 복제본이 마스터와 끊어졌거나, 복제가 완벽히 완료되지 않았을 경우

복제본의 데이터가 유효하지 않다고 판단될 때에도 클라이언트로부터 들어오는 모든 읽기 요청에 데이터를 반환하며,

replica-serve-stale-data 파라미터를 이용해 no로 설정하면 일부 커맨드를 제외한 모든 커맨드에 대해 에러를 반환하게 할 수 있다. 



### 백업을 사용하지 않는 경우에서의 데이터 복제

레디스에서 복제를 사용하는 경우 마스터와 복제본에서 백업 기능을 사용하는 것이 좋다.

 만약 이 기능을 사용하지 않으려면 재부팅 후 레디스가 자동으로 재시작되지 않도록 설정할 것을 권장한다.



마스터가 장애로 인해 모든 데이터가 유실되었고, 복제본 노드에 원본 데이터가 있어도 마스터에서 복제본으로 빈 RDB를 보내기 떄문에 모든 데이터가 유실될 수 있으므로 백업기능은 무조건 사용하는것이 좋다. 

# 9. 센티널
센티널 없이 복제만 사용하면 다음과 같은 문제점이 있다.

마스터 장애 발생시 데이터는 복제본에 존재할 수 있는데, 이를 복구하려면

1. 복제본 노드에 직접 접속한 뒤 REPLICA OF NO ONE을 입력해 읽기 전용 해제
2. 애플리케이션 코드에서 레디스 마스터 엔드포인트를 복제본으로 변경
3. 재배포

이런 불편함이 있다. 

센티넬을 사용하면 자동 페일오버를 이용하여 복제본을 마스터로 승격시켜 다운타임을 최소화 할 수 있다. 

## 센티널이란?
### 센티널 기능
* 모니터링 : 마스터 복제본 인스턴스 상태 실시간 확인
* 자동 페일오버 : 마스터가 장애면 복제본 중 하나를 마스터로 승격. 기존 마스터에 연결된 복제본은 새로 마스터가 된 인스턴스에 연결
* 인스턴스 구정정보 안내 : 현재 구성에서의 마스터정보를 클라이언트에게 알려주므로 페일오버 발생시 레디스 엔드포인트 정보를 변경할 필요가 없음. -> 클라이언트는 센티널을 통해 마스터 정보를 받아오기 떄문 

### 분산 시스템으로 동작하는 센티널

센티널은 최소 3대이상일때 동작가능하다

* 하나의 센티널 이상 생기더라도 다른 센티널이 계쏙해서 역할 수행 가능.

잘못된 탐지를 줄이기 위해 쿼럼 이라는 개념을 이용한다.

* 쿼럼 : 마스터가 비정상 동작을 한다는것에 동의해야 하는 센티널의 수. 쿼럼을 만족해야 페일오버를 시작한다
* 센티널 3개시 쿼럼은 2. 센티널 2대가 쿼럼에 동의해야 페일오버를 시작 
* 과반수 선출을 위해 홀수로 구성하는 것이 좋으며. 더 견고하고 싶다면 5대로 구성 



### 센티널 인스턴스 배치 방법

센티널 인스턴스는 물리적으로 서로 영향받지 않는 서버에서 실행하는것이 좋음. 

1. 2개의 복제본이 있는 구성

<img src="./images//image-20240505021600735.png" width = 450>

* 마스터, 복제본 한개 인스턴스마다 둔다. 

2. 1개의 복제본이 있는 구성의 센티널

<img src="./images//image-20240505021710102.png" width = 450>

* 이때 server c는 센티널 한대만 두고, 클라이언트의 요청을 받지 않으므로 매우 적은 사양의 인스턴스도 괜찮다. 

## 센티널 인스턴스 실행하기
### 센티널 프로세스 실행

센티널을 띄우기 위해서 sentinel.conf라는 별도 구성 파일이 필요하다

```
port 26379
sentinel monitor master-test 192.168.0.11 6379 2
```

* sentinel monitor : 모니터링할 마스터 이름 지정. 쿼럼 값도 지정 

센티널 실행

```
# redis-sentinel을 이용하는 방법
redis-sentinel /path/to/sentinel.conf

# redis-server를 이용하는 방법
redis-server /path/to/sentinel.conf --sentinel
```

* 지정된 위치에 sentinel. conf 파일이 없거나 해당 경로에 데이터를 쓸 수 없는 경우 인스턴스는 시작되지 않는다.

SENTINEL master 커맨드를 이용하면 원하는 마스터의 IP, 포트, 연결된 복제본의 개 수 등 다양한 정보를 확인할 수 있다.

``````
sentinel> SENTINEL master master-test
``````

### 페일오버 테스트

커맨드를 이용한 수동 페일오버 발생

```
SENTINEL FAILOVER <master name>
```

* 다른 센티넬 동의 없이 바로 페일오버 가능. 마스터와 복제본간 롤 체인지가 발생한다. 

**마스터 동작 중지시켜 자동 페일오버 발생**

```
# 레디스 셧다운
redis-cli -h <master-host> -p <master-port> shutdown
```

## 센티널 운영하기
### 패스워드 인증

장애 상황에 센티널이 자동으로 페일오버를 시키기 때문에 복제 구성 내의 모 든 레디스 노드는 마스터 노드가 될 가능성이 있다고 볼 수 있다. **따라서 하나의 복제 그룹에서 requirepass 와 masterauth 값은 모든 노드에서 동일하게 설정해야 한다.**

패스워드가 걸려 있는 레디스를 모니터링할 경우에는 sentinel. conf에 다음과 같이 패스워드를 지정해야 한다.

```
sentinel auth-pass ‹master-name> <password>
```

### 복제본 우선순위

모든 레디스 인스턴스는 replica-priority라는 파라미터를 가지고 있다. 

센티널은 페일오버를 진행할 때 각 복제본 노드의 replica-priority라는 우선순위 노드를 확 인하며, 해당 값이 가장 작은 노드를 마스터로 선출한다.

기본값은 100이며, 이 값이 0인 복제본은 절대 마스터로 선출되지 않는다.

### 운영 중 센티널 구성 정보 변경

센티널은 실행 도중 모니터링할 마스터를 추가, 제거, 변경할 수 있다. 

이때 마스터를 모니터링하는 센티널이 여러 대라면 **각각의 센티널에 모두 설정을 적용해야 하며, 설정을 변경했다고 해서 그 정보들이 다른 센티널로 전파되진 않는다.**

```
SENTINEL MONITOR <master name> <ip> <port> <quorum>
```

```
SENTINEL REMOVE <master name>
SENTINEL REMOVE 커맨드는 더 이상 지정하는 마스터를 모니터링하지 않도록 지시 한다.
```

SENTINEL SET 커맨드는 특정 마스터에 대해 지정한 파라미터를 변경할 수 있다. 

예를 들어 마스터가 다운됐다는 것을 판단하는 시간인 **down-after-milliseconds** 값을 변 경하고 싶다면 다음과 같은 커맨드를 입력하면 된다.

``````
sentinel> SENTINEL SET mymaster down-after-milliseconds 1000
``````

쿼럼 값도 간단하게 변경할 수 있다.

``````
sentinel> SENTINEL SET mymaster quorum 1
``````

### 센티널 초기화

센티널은 비정상적이라 판단한 복제본 노드에 대해서도 임의로 모니터링을 멈추지 않 는다. 예를 들어 페일오버된 뒤 계속 접근할 수 없는 기존 마스터 노드, 혹은 장애가 발생해 접근할 수 없는 복제본 노드 등에 대해서도 계속 모니터링을 시도한다.

특정 서버를 더 이상 사용할 수 없어 해당 인스턴스에 대한 모니터링을 중단하려면 SENTINEL RESET 커맨드를 사용해 센티널 인스턴스의 상태 정보를 초기화해야 한다.

```
SENTINEL RESET <master name>
```



### 센티널 노드의 추가/제거

현재 구성에 새로운 센티널 노드를 추가하는 것은 아주 간단하다. 마스터를 모니터링 하도록 설정한 센티널 인스턴스를 실행시키면 자동 검색 메커니즘에 의해 자동으로 기존에 실행 중이던 다른 센티널의 known-list에 추가된다.

### 센티널의 자동 페일오버 과정

센티널은 down-after-mi11iseconds 파라미터에 지정된 값 이상 동안 마스터에 보낸 PING에 대해 유효한 응답을 받지 못하면 마스터가 다운됐다고 판단한다.

 PING에 대한 유효한 응답은 +PONG, - LOADING, -MASTERDONN이며, 다른 응답이나 응답을 아예 받지 못할 경우는 모두 유효하지 않다고 판단한다.

만약 down-after-milliseconds 값이 30이고, 마스터는 29초마다 응답한다면 센티 널은 해당 마스터를 정상적이라고 인지한다.



2. 하나의 센티널 노드가 마스터 인스턴스가 장애라도 판단하면 우선 해당 센티넬이 sdown으로 플래깅한다(주관적 다운 상태)
3. 다른 센티널 노드들에게  **SENTINEL is-master-down-by-addr <master-ip> <master-port> <current-epoch> <*>**라는 커맨드를 보내 다른 센티널에게 장애 사실을 전파한다.

4. 커맨드를 받은 센티널들이 마스터 장애 인지 여부를 응답한다. 
5. 쿼럼 값 이상의 센티널 노드에서 장애를 인지한다면 센티널 노드는 마스터 상태를 sdown -> odown으로 (객관적 다운)으로 변경한다.
6. 처음으로 마스터 노드를 odown으로 인지한 센티널이 페일오버를 실시하며 시작하기 전   epoch 값을 하나 증가시킨다. 
   * 에포크는 증가하는 숫자갑으로 각 마스터에서 발생한 페일오버의 버전을 관리 
   * 새로운 페일오버 발생시 에포크 값은 하나씩 증가. 동일한 에포크 값으로 모든 센티널 노드가 같은 작업을 실시 중이라는것을 보증
7. 에포크 증가시킨 센티널이 다른 센티널에게 센티널 리더를 선출하기 위한 투표 메시지 보내고, 리더가 페일오버 실시 
   * odown으로 변경하려면 쿼럼 값 이상의 동의가 필요하다. 그러나 센티널 리더 선출시 쿼럼값이 아닌 과반 수 이상이 동의해야 리더가 선출된다.
   * 쿼럼 값보다 큰 센티널이 동의를 했을 경우에도 그 수가 과반수보다 적다면 페일오버는 발생하지 않는다
   * 센티널이 5개, 쿼럼 2 sdown-> odown은 가능하나, 2개의 센티널만 동의시 리더를 선출할 수 없어 페일오버 할 수 없다
8. 센티널 리더가 마스터 될 수 있는 복제본을 선택한다. 복제본 선출 순서는 다음과 같다.
   1. redis.conf에 명시된 replica-priority가 낮은 복제본
   2. 마스터로부터 더 많은 데이터를 수신한 복제본
   3. runID가 사전순으로 작은 복제본 
9. 선정한 복제본에 slaveof no one 명령어 수행해 복제 제거.
10. 복제본마다 replicaof new-ip new-port 커맨드 수행하여 선정된 복제본에 연결. 모든 센티널 노드들도 다 구성정보 변경 

### 스플릿 브레인 현상

스플릿 브레인split brain이란 네트워크 파티션 이슈로 인해 분산 환경의 데이터 저장소 가 끊어지고, 끊긴 두 부분이 각각을 정상적인 서비스라고 인식하는 현상을 의미한다.

네트워크 단절이 길어지면, 센티널들이 장애로 판단하여 마스터가 새로 선출될 수 있다. 

만약 마스터 인스턴스에는 장애가 발생 하지 않았으며, 단지 노드 간 네트워크 단절이 일어난 경우라면 하나의 복제본에 2개 의 마스터가 생기는 스플릿 브레인 현상이 일어난다.

기존 마스터 인스턴스에 데이터를 입력하고, 새 클라이언트가 다른 센티널에 마스터 주소를 물어보면 새로운 마스터 주소를 반환해서 새로운 마스터에 데이터를 쓰게된다.

네트워크 단절 복구시 기존 마스터는 센티널에 의해 새로운 마스터의 복제본으로 연결되며, 기존 마스터 인스턴스에 입력되었떤 데이터들을 유실되는 문제가 발생한다.



# 10. 클러스터
## 레디스 클러스터와 확장성
### 레디스에서의 확장성

레디스의 처리량을 증가시키기 위해 스케일 업만으로는 한계가 있다. 단일 스레드로 동작하기 때문에 CPU를 추가해도 동시에 활용할 수 없다. 때문에 서버 대수를 늘리는 스케일 아웃을 이용하는것이 좋다. 

### 레디스 클러스터의 기능

데이터 샤딩 : 저장소를 수평확장하며 여러 서버간에 데이터를 분할해서 저장하는 아키텍처 패턴 

레디스에서는 클러스터 사용시 최대 마스터를 1000개까지 확장시킬 수 있다.

샤딩 기능은 레디스 내부적으로 관리되며 추가적인 프록시 서버 등의 아키텍처는 필요하지 않다. 

하나의 키는 하나의 마스터 노드에 매핑되며, 클러스터의 모든 노드는 키가 저장돼야할 노드와 어디에 있는지 알기 때문에 키가 할당된 마스터 노드로 리디렉션 한다. 

매번 레디스에 키를 저장할 노드를 질의하지 않기 위해 클라이언트에서 클러스터 내 어떤 마스터에 있는지 캐싱할 수 있으며 이를 이용해 키를 찾아오는 시간을 단축시킬 수 있다. 

**고가용성**

<img src="./images//image-20240505133352835.png" width = 550>

클러스터는 최소 3대 마스터, 복제본 노드를 갖도록 구성하는 것이 일반적이며, 클러스터의 각 노드는 서로를 모니터링한다.

마스터 노드에 장애 발생시, 이를 인지한 다른 노드들이 마스터에 연결된 복제본을 마스터로 자동으로 페일오버시킨다.

클러스터 내 노드들은 클러스터 버스라는 독립적인 TCP 통신을 이용하며, 추가 포트를 열어야 한다.

* config file에서 cluster_bus_port값을 정의하지 않으면 디폴트로 일반포트 + 10000을 더한 동작으로 설정. (6379 -> 16379

구성은 풀 메쉬 토폴로지 형태이며, ping-pong으로 서로 통신하며 감시한다. 

오버헤드는 걱정하지 않아도 된다. 가십 프로토콜과 구성 업데이트 메커니즘을 이용해 클러스터가 정상이면 노드간 너무 많은 메시지를 교환하지 않는다 

## 레디스 클러스터 동작 방법
### 해시슬롯을 이용한 데이터 샤딩
클러스터 구조에서 모든 데이터는 해시 슬롯에 저장된다. 레디스는 총 16,384의 (2^14) 해시 슬롯을 갖는다. 

3대의 마스터 노드로 클러스터 구성시 해시 슬롯은 다음과같이 분배된다.

<img src="./images//image-20240505133727758.png" width = 450>

모든 키는 하나의 해시슬롯에 매핑되며, 이용하는 해시함수는 다음과 같다.

```
HASH_SLOT = CRC16(key) mod 16384
```

이 알고리즘을 이용해 특정 해시슬롯 값을 알아내고, 해당 해시슬롯을 갖고있는 마스터에 데이터를 저장하거나 가져온다.

![image-20240505134409939](./images//image-20240505134409939.png)

해시슬롯은 마스터 노드 내에서 자유롭게 옮겨질 수 있으며, 옮겨지는중에도 접근 가능하므로 클러스터 내에서 마스터 노드의 추가 삭제는 간단히 처리될 수 있다.

### 해시태그

클러스터 사용시 다중 키 커맨드를 서로 다른 해시슬롯에 속한 키에서는 사용할 수 없다. 

```
MGET user1:name user2:name // 사용 불가 
```

- **MSETNX**, **BLPOP**, **BRPOP** 등의 명령어는 클러스터 모드에서 지원되지 않는다.
- **MSET**, **MGET** 등은 모든 키가 같은 노드에 있을 경우에만 사용할 수 있다.

클러스터는 키를 이용해 커맨드를 처리할 마스터로 리디렉션 하기 때문에 2개 이상의 키에 접근해야 하는 커맨드는 처리할 수 없다. 

이때, 해시태그 라는 기능을 사용하면 이 문제를 해결할 수 있다.

키에 대괄호를 사용하면 전체 키가 아닌 대괄호 사이에 있는 값을 이용해 해시되어 사용할 수 있다.

```
user:{123}:profile
user:{123}:account
```

예를들어 위 두 키는 대괄호 사이 123이라는 동일한 값을 갖고있기 때문에 같은 해시슬롯(같은 마스터)에 저장되는것이 보장된다.

만약 대괄호 사이 아무런 문자열이 없다면 다른 키들과 동일하게 전체 키의 문자열로 해싱되며, 여러 개의 {}문자가 포함된 경우 가장 처음의 {부터 가장 처음의}사이의 값들이 해싱된다.

| 입력 키                | 해시 태그된 부분 |
| ---------------------- | ---------------- |
| `{user1000].followers` | user1000         |
| `user{}id`             | user{}id         |
| `user{{name}}id`       | `{name`          |
| `user{name}{id}`       | `name`           |

1. 괄호안의 user1000값으로 해싱
2. {}에 아무것도 없기 때문에 키 전체를 이용해 해싱
3. {부터 첫번쨰 }안에 있는값인 {name으로 해싱
4. name으로 해싱

``````
MGET {user}1:name {user}2:name
``````

* 여기서 `{user}1:name`과 `{user}2:name`은 해시 태그 `user`를 공유합니다. 이는 두 키가 같은 해시 슬롯에 위치하도록 보장하여, 한 번의 커맨드로 두 키의 값을 효율적으로 조회할 수 있습니다.

따라서 클러스터 구조에서 다중 키 커맨드를 사용하고 싶다면 위의 예제와 같이 해시 태그 기능을 사용하면 된다. 하지만 너무 많은 키가 같은 해시태그를 갖고 있다면 하 나의 해시슬롯에 데이터가 몰리는 현상이 발생할 수 있기 때문에 키의 분배에 대한 모니터링이 필요할 수 있다.

### 자동 재구성

특정 마스터 장애 발생시, 해당 마스터의 복제본은 다른 마스터 노드들에게 페일오버 시도해도 될지 투표를 요청하며,

다른 마스터 노드들이 정상 상태가 아니라고 판단할 경우 복제본에게 투표하여 과반수 이상이 투표를 받으면 복제본이 마스터로 승격된다 

만약 새로 마스터가 된 복제본이 다시 장애가 발생하면 어떻게 될까?

**cluster-require-full-coverage** 라는 설정이 yes로 되어있으면 전체 클러스터를 사용할 수 없게 된다.

* 데이터 정합성 위해 일부 해시슬롯 사용 못하게 되면 전체 사용 불가. 조작도 실패

만약 가용성이 중요한 서비스에서 클러스터 노드의 다운타임을 줄이고 싶다면 자동 복제본 마이그레이션이 가능하도록 아무 마스터 노드에 **복제본을 하나 더 추가하는 것을 고려하는 것이 좋다.**

### 복제본 마이그레이션

<img src = "./images//image-20240505140822353.png" width = 450>

만약 특정 마스터가 복제본이 2개이상 있고, 복제본이 1개있는 마스터가 장애가 발생하여 복제본이 마스터가 되면

해당 새로운 마스터의 복제본은 존재하지 않는다. 이때, 레디스 클러스터는 복제본 노드의 불균형을 파악해서 다른 마스터의 2개이상 있는 복제본 중 하나를 새로운 마스터의 복제본으로 옮겨 불균형을 해소시킨다. 이를 복제본 마이그레이션이라 한다.

아무 복제본이나 마이그레이션 되는것이 아닌, 가장 많은 수의 복제본이 연결된 마스터의 복제본 중 하나가 옮겨지게 된다.

또한 FAiL 상태가 아닌 복제본 중 노드 ID가 가장 작은 복제본이 이동될 노드로 선택된다

```
cluster-allow-replica-migration yes
cluster-migration-barrier 1
```

* cluster-allow-replica-migration가 yes일때 동작. 기본값 yes
* cluster-migration-barrier는 복제본 마이그레이션 하기 전 마스터가 가지고 있어야 할 최소 복제본 수 
  * 예를들어 이값이 2라면, 복제본이 없는 마스터 노드가 있고, 복제본이 2개잇는 마스터 노드가 있어도 마이그레이션 되지 않는다. 

## 레디스 클러스터 실행하기
최소 3개 마스터 노드가 필요하며 각각 복제본을 추가해 6개 노드로 운영하는것이 일반적이다. 

### 클러스터 초기화

redis.conf파일에 cluster-enabled 설정을 yes로 설정한다

```
cluster-enabled yes
```

각기 다른 서버 6대에 레디스를 실행한다

```
redis-cli -cluster create [host:port] --cluster-replicas 1
```

* --cluster create 옵션을 이용해 클러스터 생성 명시하고, 클러스터에 추가할 레디스의 ip:port쌍을 쭉 나열한다
* --cluster-replicas 1은 마스터마다 1개의 복제본을 추가할것임을 의미 

입력한 순서대로 3개는 마스터 나머지는 복제본이 구성된다

```
redis-cli --cluster create 111.1.1.1:6379 111.1.1.2:6379 111.1.1.3:6379 111.1.1.4:6379
... --cluster-replicas 1 -a password
```

정상적인 초기화가 완료되면 앞에서와 같이 [OK] ALL 16384 slots covered. 커맨 드가 떨어지며 생성이 종료된다.

해시슬롯은 마스터에게만 할당되며 복제본에는 할당되지 않는다 .



### 클러스터 상태 확인하기

CLUSTER NODES 커맨드를 이용해 클러스터의 상태를 확인할 수 있다.

CLUSTER NODES 커맨드는 랜덤으로 클러스터 내의 노드들을 순서 없이 출력하며, 출력되는 라인은 각각 다음과 같은 필드를 갖고 있다.

```
<id> <ip:port@cport> «flags> ‹master› ‹ping-sent> ‹pong-recv> «config-epoch> ‹link-state› «slot› ‹slot› ... ‹slot>
```

| 필드명             | 설명                                                         |
| ------------------ | ------------------------------------------------------------ |
| **id**             | 노드가 생성될 때 자동으로 만들어지는 랜덤 스트링의 클러스터 ID 값이다. 노드에 한 번 할당된 ID는 바뀌지 않는다. |
| **ip: port@cport** | 노드가 실행되는 ip와 port 그리고 클러스터 버스 포트 값이다. 클러스터 포트 주소는 레디스 포트에 10000을 더한 값으로 자동으로 설정된다. |
| **flags**          | 노드의 상태를 나타낸다. 플래그는 다음과 같은 상태를 포함할 수 있다: mysell, master, slave, tal?, tall, handshake, nofailover, noaddr, noflags. |
| **master**         | 복제본 노드일 경우 마스터 노드의 ID, 마스터 노드일 경우 '-' 문자가 표시된다. |
| **ping-sent**      | 보류 중인 PING이 없다면 0, 있다면 마지막 PING이 전송된 유닉스 타임을 표시한다. |
| **pong-sent**      | 마지막 PONG이 수신된 유닉스 타임을 표시한다.                 |
| **config-epoch**   | 현재 노드의 구성 에포크. 페일오버가 발생할 때마다 에포크는 증가하며, 구성 충돌이 있을 때 에포크가 높은 노드의 구성으로 변경된다. |
| **link-state**     | 클러스터 버스에 사용되는 링크의 상태를 의미한다 (connected/disconnected). |
| **slot**           | 노드가 갖고 있는 해시슬롯의 범위를 표시한다.                 |

### redis-cli를 이용해 클러스터 접근하기와 리디렉션

특정 마스터 노드에 연결해서 키를 입력하더라도 해시슬롯이 다르면 해당 해시슬롯 마스터 노드에 저장을 해야한다.

즉, 일반적인 클라이언트를 이용해 데이터를 넣을 때에는 데이터가 저장될 수 있는 노드가 정해져 있고 해당 노드에만 키 에 대한 커맨드를 수행시킬 수 있음을 의미한다.

이러한 불편함을 줄이기 위해 Jedis, Redisson 등의 레디스 클라이언트들은 클러스터 모드 기능을 제공한다.

redis-cli를 사용한다면 -c 옵션을 추가해 클러스터 모드 로 사용할 수 있고, 이 경우에 리디렉션 기능이 제공된다.

```
$ redis-cli -c
127.0.0.1:6379> set user:1 true
-> Redirected to slot [10778] located at 192.168.0.22:6379
ОК
192.168.0.22:6379>
```

대부분 레디스 클라이언트는 리디렉션한 정보를 캐싱해 Map을 생성해서 캐싱된 노드로 바로 커맨드를 보낼 수 있게 한다.

Map은 마스터 노드가 추가 삭제되거나 페일오버 등 구조가 변경되면 리프레시 된다.

### 페일오버 테스트

수동 페일오버

페일오버 발생시킬 복제본 노드에서 cluster failover 커맨드를 실행하여 발생시킬 수 있다. 

## 레디스 클러스터 운영하기
### 클러스터 리샤딩

마스터 노드가 가지고 있는 해시슬롯 중 일부를 다른 마스터로 이동하는 것을 리샤딩 이라 한다. 

리샤딩은 redis-cli에서 cluster reshard 옵션을 이용해 수행할 수 있다.

이때 클러스터에 속한 여러 노드 중 하나의 노드를 지정하면 해당 노드가 속한 클러스 터 구조를 파악한 뒤 연결된 다른 노드의 정보를 찾아와 다음과 같이 보여준다. 이때 마스터 노드뿐만 아니라 레플리카 노드 중 하나를 지정하더라도 리샤딩 동작은 동일 하게 수행된다.

첫 번째로, 이동시킬 슬롯의 개수를 정해야 한다. 100개의 키를 이동시켜보자.

```
How many slots do you want to move (from 1 to 16384? 100

What is the receiving node ID?
```

모든 작업이 끝난 뒤 **cluster check** 커맨드를 이용해 클러스터 정보를 자세히 확인 할 수 있다. cluster check 커맨드는 cluster nodes 보다 조금 더 자세한 구성을 확 인할 수 있다.

### 클러스터 확장-신규 노드 추가

마스터 및 복제본 추가 할 경우 추가하고자 하는 노드에 데이터가 저장되있으면 안됀다.

또한 마찬가지로 config 파일에 cluster-enabled yes가 추가되어있어야한다



**마스터로 추가하기**

```
redis-cli --clister add-node <추가할 노드 IP:PORT> <기존 노드 IP:PORT>
```

* 기존 노드는 기존 클러스터에 속한 노드중 1개의 노드 

**복제본으로 추가하기**

```
redis-cli --clister add-node <추가할 노드 IP:PORT> <기존 노드 IP:PORT> --cluster-slave [--cluster-master-ip <기존 마스터 ID>]
```

- ﻿-cluster-master-id 옵션을 이용해 복제본의 마스터가 될 노드를 지정해주면 신 규로 추가하는 노드는 지정한 마스터에 복제본으로 연결된다. 만약 해당 옵션 없이

- ﻿-cluster-slave 옵션을 이용해 노드를 추가할 때는 추가되는 노드가 임의의마스터 의 복제본으로 연결된다.

### 노드 제거하기
```
redis-cli --cluster del-node <기존 노드 IP:PORT> <삭제할 노드 ID>
```

마스터 노드의 경우 제거하기전 노드에 저장된 데이터가 없는 상태여야 한다.

즉 할당된 해시슬롯이 하나도 없도록 해시슬롯을 모두 다른 노드로 **리샤딩** 하고 제거한다

* 혹은 수동으로 페일오버 진행하고 노드를 복제본으로 만든 뒤 클러스터에서 제거할 수도 있다.

```
redlis-cli --cluster reshard <host>:<port> --cluster-from <node-id>
--cluster-to <node-id> --cluster-slots <number of slots> --cluster yes
```

예시

```
redlis-cli --cluster del-node 192.168.0.11:6379 <node-id>

>>> SENDING CLUSTER FORGET message to the cluster...
>>> SENDING CLUSTER RESET SOFT to the deleted node
```

**CLUSTER FORGET**

클러스터 제거시 클러스터 구성 데이터 지우기 및 다른 노드들에게도 해당 노드를 지우라는 커맨드를 함께 보내 주소나 아이디 등을 제거한다

`CLUSTER FORGET <node-id>` 커맨드를 수신한 노드는 노드 테이블에서 제거할 노드의 정보를 지운 뒤 60초동안 이 노드 아이디와 신규로 연결되지 않는다.   따라서 60초 동안 제거한 노 드의 ID가 다시 추가되는 것을 차단하지 않으면 다른 노드에 의해 제거된 노드를 다 시 클러스터에 추가할 가능성이 존재한다.

**CLUSTER RESET**

제거될 노드에서 수행되는 명령어다 SOFT/HARD가 있다. 기본값은 SOFT다 

CLUSTER RESET은 다음과 같은 과정으로 진행된다. 

HARD RESET을 진행할 때에는 1에 서 5번 과정이 모두 수행되며, SOFT RESET에서는 1에서 3번까지의 과정만 수행된다.

1. ﻿﻿﻿클러스터 구성에서 복제본 역할을 했었다면 노드는 마스터로 전환되고, 노드가 가지고 있던 모든 데이터셋은 삭제된다. 노드가 마스터이고 저장된 키가 있다면 리셋 작업이 중단된다.
2. ﻿﻿﻿노드가 해시슬롯을 가지고 있었다면 모든 슬롯이 해제되며, 만약 페일오버가 진 행되는 과정이었다면 페일오버에 대한 진행 상태도 초기화된다.
3. ﻿﻿﻿클러스터 구성 내의 다른 노드 데이터가 초기화된다. 기존에 클러스터 버스를 통해 연결됐던 노드를 더 이상 인식할 수 없다.
4. ﻿﻿﻿currentEpoch, configepoch, LastVoteepoch 값이 0으로 초기화된다.
5. ﻿﻿﻿노드의 ID가 새로운 임의 ID로 변경된다.

### 레디스 클러스터로의 데이터 마이그레이션

리플리케이션 혹은 싱글 혹은 센티널 구성을 클러스터로 마이그레이션 하고싶다면 간단하게 할 수 있다.

* . 기존 애플리케 이션에서 다중 키 커맨드를 사용하지 않았을 경우에는 커넥션 변경 이외의 데이터 저 장 로직은 문제가 되지 않으며, 사용했을 경우라면 해시태그를 사용하도록 애플리케 이션 로직을 일부 수정해야 한다.

운영 중인 레디스의 데이터를 마이그레이션할 때에는 소스 레디스에 **연결된 클라이언트를 모두 중단시키는 것이 좋다**. 마이그레이션 도중 원본 레디스 노드에서 변경되 거나 추가된 데이터는 마이그레이션되는 클러스터에 반영되지 않기 때문이며, 경우에 따라 서비스에 점검을 건 상태에서 진행해야 할 수도 있다.

다음 커맨드를 이용하면 데이터를 마이그레이션할 수 있다.

```
redis-cli --cluster import 192.168.0.11:6379 --cluster-from 192.168.0.88:6379 --cluster copy
```

### 복제본을 이용한 읽기 성능 향상

마스터에 데이터를 읽어가는 부하가 집중되는 경우 데이 터를 쓰는 커넥션은 마스터에, 읽기는 복제본에서 수행할 수 있도록 커넥션을 분배시 킨다면 읽기 성능을 향상시킬 수 있다.

이런 경우 다음과 같이 복제본으로 맺어지는 커넥션을 READONLY 모드로 변경해 클라이언트가 복제본 노드에 있는 데이터를 직접 읽을 수 있게 할 수 있다.

접속해서 그냥 readonly 명령어 치면된다

```
192.168.0.55:6379> readonly
OK
```





## 레디스 클러스터 동작 방법
### 하트비트 패킷

클러스터 노드들은 지속적으로 서로 상태 확인을 위해 ping, pong 패킷을 주고받는다. 이 두 패킷을 묶어서 하트비트 패킷이라고 한다.

```
노드 ID
현재 에포크
구성 에포크
핑크
비트맵
TCP 포트
클러스터 포트
클러스터 상태
[마스터 노드 ID]

--------- 가십 섹션
노드 ID
IP/포트 쌍
노드 핑크

노드 ID
IP/포트 쌍
노드 핑크
--------- 가십 섹션

```

- ﻿﻿노드 ID
- ﻿﻿현재 에포크/구성 에포크: 분산 환경에서 일관성을 유지하기 위한 정보
- ﻿﻿노드 플래그: 노드가 마스터인지 혹은 복제본인지 등의 노드 정보

*  비트맵: 마스터가 제공하는 해시슬롯의 비트맵 정보, 복제본인 경우 마스터의 정보

- ﻿﻿TCP 포트: 발신 노드의 TCP 포트
- ﻿﻿클러스터 포트: 발신 노드의 노드 간 커뮤니케이션을 위한 포트
- ﻿﻿클러스터 상태: 발신 노드 관점에서 봤을 때의 클러스터 상태(down/ok)
- ﻿﻿마스터 노드 ID: 복제본 노드인 경우 마스터의 노드 ID

클러스터가 주고받는 유형의 패킷에 가십 섹션이 추카된 형태를 뛴다 



> 중요한것은 에포크 값.
>
> 수신받은 패킷의 에포크값이 로컬 노드 에포크값보다 크다면 현재 수신받은 패킷의 에포크값으로 에포크 값으로 업데이트 한다.
>
> 모든 노드는 가장 큰 에포크 값으로 통일되어야 한다. 



### 해시슬롯 구성이 전파되는 방법

레디스 클러스터에서 가장 중요한 기능 중 하나는 커맨드에서 사용한 키의 해시슬롯이 어디에 있는지 파악해 정확한 해시슬롯의 위치를 알려주는 것이다.

클러스터에서 해시슬롯의 구성은 두 가지 방법으로 전파된다.

- ﻿﻿하트비트 패킷: 마스터 노드가 PING, PONG의 패킷을 보낼 때 항상 자기가 갖고 있는 해시슬롯을 패킷 데이터에 추가
- ﻿﻿업데이트 메시지: 하트비트 패킷에는 발신하는 노드의 구성 에포크 값이 포함돼 있으며, 패킷을 보낸 노드의 에포크 값이 오래됐다면 해당 패킷을 받은 노드는 신규 에포크의 구성 정보를 포함한 업데이트 메시지를 노드에 보내 하트비트 패 킷을 보낸 노드의 해시슬롯 구성을 업데이트

만약 페일오버가 발생된 뒤 현재의 구성 에포크인 3보다 더 큰 4라는 구성 에포크를 가진 패킷을 수신했다고 해보자. 해당 패킷에서 노드 B가 해시슬롯 1, 2를 갖고 있다고 주장하면, 하트비트 패킷을 수신한 노드는 해시슬롯 테이블을 다음과 같이 업데이트 한다

```
0 -> NULL
1 -> B [4]
2 -> B [4]
```

해시슬롯 구성의 변경은 폐일오버와 리샤딩 중에만 발생한다. 페일오버와 리샤딩하는 작업 모두 에포크가 증가하는 작업이기 때문에 작업 이후 변경 사항을 클러스터 전체 에 전파시킨다. 클러스터의 모든 노드는 가장 큰 구성 에포크 값을 가진 노드에 동의 하기 때문에 클러스터 내의 모든 노드 값을 업데이트시킬 수 있다.



### 노드 핸드셰이크

한 노드가 클러스터에 합류하기 위해 CLUSTER MEET 커맨드를 다른 노드에 보낸다. 

해당 커맨드를 수신한 노드는 자신이 아는 다른 노드들에게 전파하고, 서로 모르는 상태면 해당 노드와 CLUSTER MEET를 통해 신규 연결을 맺는다

이와 같은 방식으로 클러스터 내 모든 노드들은 풀 메쉬 연결을 하게된다.

이미 알고있는 노드들(클러스터내의 노드들) 이외에는 CLUSTER MEET를 수행하지 않기 때문에 외부의 다른 클러스터와 우연히 연결되는것을 막을 수 있다.



### 클러스터 라이브 재구성

- ﻿﻿클러스터에 새로운 노드를 추가하려면 빈 노드를 클러스터에 추가한 뒤, 일부 해 시슬롯을 기존 마스터에서 신규 노드로 옮긴다.
- ﻿﻿클러스터에서 노드를 제거하려면 해당 노드를 빈 노드로 만들기 위해, 갖고 있던 해시슬롯을 다른 노드로 보낸다.

해시슬롯 또한 결국 논리적인 키의 집합이기 때문에 레디스 클러스터가 실 제로 하는 일은 하나의 마스터 노드에서 다른 마스터 노드로 데이터를 옮기는 것을 의미한다.

A가 갖고 있던 해시슬롯 8을 B로 옮기고 싶다면 각 노드에서 다음과 같은 커맨드가 수행된다.

- ﻿﻿A에게: CLUSTER SETSLOT 8 MIGRATING B
- ﻿﻿B에게: CLUSTER SETSLOT 8 IMPORTING A

또한 레디스는 해시슬롯 8에 속한 키를 A에서 B로 마이그레이션한다. 이는 다음 커맨 드를 사용해 수행된다.

```
CLUSTER GETKEVINSLOT slot count
```

* 이 커맨드는 지정한 해시슬롯이 가지고 있는 키를 반환하며, 반환된 모든 키에 대해 노드 A에 MIGRATE 커맨드를 전송한다.

다음 커맨드는 키를 원자적으로 A에서 B로 마이그레이션한다. 

2개의 인스턴스 모두 키를 마이그레이션하는 동안 **락이 걸리며, 이로 인한 경쟁 상황은 발생하지 않는다.**

```
MIGRATE target-host target-port key target-database id timeout
```

* MIGRATE는 대상 인스턴스에 연결해서 키를 전송하고 OK 코드를 받으면 기존 데이터를 삭제한다.

마이그레이션이 완료되면 두 노드에게 모두` SET SLOT <slot> NODE<node-id>` 커맨드를 전송하고 전파된다.

### 리디렉션
클러스터의 리디렉션에게는 MOVED 리디렉션과 ASK 두종류가 있다.

* MOVED: 요청하는 해시슬롯이 저 노드에 있으니 앞으로 이 키에 대한 요청은 저 노드로 보내
* ASK : 지금 요청한 이 쿼리는 저 노드에서 수행해, 하지만 다음 요청의 노드는 다시 나한테 보내

왜 리디렉션을 구분했을까?

* 다른 노드에 커넥션을 맺는 과정이 많아졌을 떄 속도차이가 발생하므로 구분하여 구분했다.



**MOVE 리디렉션**

커맨드를 받은 노드가 해당 해시슬롯을 가진 경우 원하는 데이터를 해시슬롯에서 찾아 바로 반환.

아니라면 어떤 노드가 어떤 해시슬롯을 갖고있는지 해시슬롯 맵을 확인한 후 MOVED 에러로 클라이언트에 응답한다. 

```
ex)
GET x
-MOVED 2345 192.168.0.22:6379 
```

* 2345는 키의 해시슬롯. IP port는 해당 해시슬롯을 갖고있는 마스터 노드 

해당 클라이언트는 이 응답을 갖고 맵에 저장한 뒤 다음부터는 올바른 마스터 노드로 바로 데이터를 조회하여 리디렉션을 생략함으로써 성능 향상 가능.

**ASK 리디렉션**

ASK 리디렉션은 해시슬롯이 이동되는 과정에서만 발생한다.

이 리디렉션을 받은 클라이언트는 다음과 같이 동작한다.

- ﻿﻿리디렉션 오류가 반환한 노드 정보로 쿼리를 재전송하지만, 이후에 같은 키에 대 한 쿼리가 들어오면 기존에 전송한 노드에 다시 보낸다.
- ﻿﻿리디렉션을 받은 값으로 클라이언트의 해시슬롯 맵을 업데이트하지 않는다.(MOVED와 다름. )

즉 A노드와 B노드가 있을 때, 해시슬롯을 B로 이전하고 있지만, 질의하는 해시슬롯이 A에 있는 경우에 ASK 리디렉션이 발생한다.

클라이언트가 B노드에 질의하지만, 해당 해시슬롯이 아직 A에서 이전중이므로, **지금 요청한 이 쿼리는 저 노드(A노드)에서 수행해, 하지만 다음 요청의 노드는 다시 나한테(B) 보내** 라고 하는것이다. 

만약 클라이언트가 A노드에 질의하는 경우 + 마이그레이션이 완료된 경우 MOVED 리디렉션이 오게된다. 

### 장애 감지와 페일오버

레디스 클러스터에서 장애감지에 사용되는 플래그가 있다.

PFAIL과 FAIL이 있다.

**PFAIL 플래그**

Possible failure. 일부 노드에서는 접근할 수 없지만 확실하지 않은 장애 상태

NODE_TIMEOUT 시간 이상 도달할 수 없는 경우 PFAIL로 표시한다. 



**FAIL 플래그**

실제 페일오버를 트리거하려면 PFAIL이아닌 FAIL상태여야한다. 

만약 A노드가 B노드를 PFAIL 상태로 플래깅 했다면, 이후 클러스터 내의 다른 노드가 보낸 하트비트 패킷에서 B의 상태에 대해 듣고, 

일정 시간 내에 다른 노드에서 B에 대한 PFAIL 또는 FAIL 알림을 받으면 이 노드를 FAIL이라 플래깅하고 페일오버가 트리거 된다.

### 복제본 선출

다음과 같은 조건에서 복제본은 페일오버를 직접 시도한다.

- ﻿﻿마스터가 FAIL 상태다.
- ﻿﻿마스터는 1개 이상의 해시슬롯을 갖고 있다.
- ﻿﻿마스터와의 복제가 끊어진 지 오래다(파라미터로 조절 가능).

위 조건을 모두 만족하면 복제본은 자신의 에포크 값을 1 증가시키고 마스터 인스턴스에 투표를 요청한다. 

복제본은 클러스터 내 모든 마스터 노드에 FAILOVER_AUTH_REQUEST 패킷을 보내 투표를 요청하고 투표에 동의함을 응답한다.

* 여기서 여러 복제본이 동시에 승격요청을 보내는것을 방지하기 위해 NODE_TIMEOUT * 2시간 동안은 같은 마스터로 승격되고자 하는 복제본에게는 투표할 수 없다. 

다수의 마스터로부터 ACK를 받은 복제본이 마스터 후보로 선출되며, NODE_TIMEOUT*2 시간 동안 과반수 이상의 마스터에서 ACK가 오지 않으면 페일오버는 중단된다. 이후 NODE_TIMEOUT*4만큼의 지연 후에 다시 새로운 투표를 시도할 수 있다.

마스터가 FAIL 상태가 된 이후 복제본은 다음과 같이 계산된 짧은 딜레이를 가진 뒤투표를 시작한다.

```
DELAY = 500 ms + 랜덤 지연 시간 (0 ~500ㅡㄴ) + SLAVE_RANK * 1000 ms
```

# 11. 보안
## 커넥션 제어
### bind
레디스 인스턴스가 실행중인 서버는 여러 네트워크 인터페이스를 가질 수 있따 ( 여러 아이피를 가질 수 있음)

bind 설정은 서버의 여러 ip중 어떤 ip를 통해 들어오는 연결을 받을것인지 지정한다.

bind의 기본 설정값은 127.0.0.1이며, 이는 서버에 대한 루프백 IP 주소를 나타 낸다. 

기본값을 변경하지 않으면 레디스는 오직 동일한 서버 내에서의 연결만을 허용한다. 

레디스가 설치된 서버 외부에서 직접 레디스에 접근해야 하는 경우, 이 값을 서 버를 바라보는 다른 유효한 IP 주소로 변경해야 한다.

* 0.0.0.0 또는 *로 설정하면 모든 연결을 허용한다 

그러나 레디스 인스턴스가 외부 인터넷 에 노출되고 운영 목적으로 사용된다면, bind 설정값을 특정한 IP로 설정해서 의도하 지 않은 연결을 방지하는 **보안적인 설정을 권장한다.**

### 패스워드

레디스 패스워드 지정방법

```
CONFIG SET requirepass password

CONFIG REWRITE
```

### Protected mode

protected mode가 yes일 때 레디스 인스턴스에 패스워드를 설정하지 않았다면 레디 스는 127.0.0.1 IP를 이용해 로컬에서 들어오는 연결만을 허용한다

* 운영중이라면 반드시 설정하는것을 권장.

## 커맨드 제어
### 커맨드 이름 변경

rename-command는 특정 커맨드를 다른 이름으로 변경하거나, 커맨드를 비활성화할 수 있는 설정이다.

rename-command 설정은 redis.conf 파일에서 변경할 수 있으며 **실행중에는 동적으로 변경 불가능**



ex) CONFIG를 CONFIG_NEW로 변경

```
# in redis.conf 파일 
rename-command CONFIG CONFIG_NEW
```

만약 CONFIG 명령어를 사용하지 못하게 하려면?
```
rename-command CONFIG ""
```

만약 센티널 사용시에는 sentinel.conf에서도 redis.conf와 똑같이 변경 처리해줘야 한다.

* 센티널이 전송하는 커맨드를 레디스가 수행할 수 없어 페일오버 불가능할 수 있다.  

```
rename-command CONFIG "my_config" 
rename-command SHUTDOWN "my_shutdown"

sentinel. conf에서도 마찬가지로 커맨드 이름을 같이 변경해야 한다.
sentinel rename-command mymaster CONFIG my_config 
sentinel rename-command mymaster SHUTDOWN my_shutdown
```

### 커맨드 실행 환경 제어

레디스가 실행 중일 때 변경하면 위험할 수 있는 커맨드는 기본적으로 변경할 수 없도록 차단됐으며, 사용자는 이러한 커맨드의 변경을 아예 차단 또는 허용 하거나, 로컬 연결에서만 변경이 가능할 수 있도록 선택할 수 있다.

``````
enable-protected-configs no 
enable-debug-command no 
enable-modulle-command no
``````

이 세 가지 설정 파일은 일반적으로 레디스를 운영 목적으로 사용할 때에는 잘 사용되 지 않는 커맨드이기 때문에, 레디스가 악성 공격에 노출될 가능성을 줄이기 위해 도입 됐다. 세 가지 설정은 아래와 같은 값으로 변경할 수 있다.

- ﻿﻿no: 모든 연결에 대해서 명령어의 수행이 차단된다.
- ﻿﻿yes: 모든 연결에 대해서 명령어의 수행이 허용된다.
- ﻿﻿local: 로컬 연결(127.0.0.1)에 대해서만 명령어의 수행이 허용된다.



보안 강화를 위해 protected-mode를 yes로 설정하고, 패스워드를 설정해 사용하는 것을 권장한다. 

그러나 패스워드를 사용하지 않고 레디스 인스턴스를 사용하 려는 경우, 

enable-protected-configs 옵션을 local 또는 no로 설정해 외부에서 레디스의 중요한 설정 파일을 변경할 수 없도록 하는 것이 좋다.



## ACL
레디스 6부터 유저라는 개념을 도입해 유저별로 실행 가능한 커맨드와 접근 가능한 키를 제한하는 기능.

유저 생성 방법

```
ACL SET USER 이름 활성상태 >비밀번호 ~접근가능한 키 접근가능한pub/sub채널 실행 가능한 커맨드


ACL SETUSER ysk on >ysk123 ~cached:* &* +@all -@dangerous
```

### 유저의 생성과 삭제

특정 유저 확인하고 싶은 경우

```
ACL GETUSER ysk
```

ACL DELUSER를 이용하면 생성한 유저를 삭제할 수 있다.

```
ACL DELUSER ysk
```

ACL LIST 커맨드를 보면 모든 유저 확인 가능

기본 유저는 다음과 같은 권한과 특징을 가지고 있다.

- ﻿﻿유저 이름: default
- ﻿﻿유저 상태: On(활성 상태)
- ﻿﻿유저 패스워드: nopass(패스워드 없음)
- ﻿﻿유저가 접근할 수 있는 키: ~*(전체 키)
- ﻿﻿유저가 접근할 수 있는 채널: &*(전체 채널)
- ﻿﻿유저가 접근할 수 있는 커맨드: +@all(전체 커맨드)

### 유저 상태 제어

유저 활성 상태는 on / off 로 제어가능하며, on이라는 구문이 없으면 off소 생성되고 해당 유저는 접근할 수 없다.

* 생성시 on을 사용하여 생성해야 한다

### 패스워드
`>패스워드` 키워드로 패스워드를 지정할 수 있으며 삭제도 가능하다.

nopass 권한 부여시 패스워드 없이도 접근가능하다. 



### 패스워드 저장 방식

ACL를 이용해 패스워드를 저장하면 내부적으로 SHA256 방식으로 암호화돼 저장되기 때문에 유저의 정보를 확인하고자 해도 바로 조회할 수 없다.

아래 이용해서 패스워드 재정의가 가능하다.

**Redis CLI 사용**: Redis의 커맨드 라인 인터페이스를 사용하여 관리자가 직접 새로운 패스워드를 설정할 수 있습니다. 이를 위해서는 다음 명령어를 사용합니다:

```
ACL SETUSER username resetpass>newpassword
```

### 커맨드 권한 제어

개별 커맨드, 서브 커맨드, 모든 그룹화된 커맨드 조절이 가능하다.

* +@all 혹은 allcommands 키워드는 모든 커맨드의 수행 권한을 부여한다는 것을 의미
* -@all 혹은 nocommands는 아무런 커맨드를 수행할 수 없다는 것을 뜻한다. 
* 커 맨드 권한에 대한 언급 없이 유저를 만들면 -@all 권한의 유저가 생성된다.

* 특정 카테고리의 권한을 추가하려면 `+@<category>`,
*  제외하려면 `-@<category>`
* 개별 커맨드의 권한을 추가, 제외하려면 @ 없이 바로 `+<command>`나 `-<command>`를 사용하면 된다.

다양한 커맨드를 보고싶으면 레디스 공식 홈페이지나 책 346~ 348페이지를 보자 

### 유저 초기화

reset 커맨드로 이용 

### ACL 규칙 파일로 관리하기

만약 /etc/redis/users.ac1 파일로 ACL 파일을 관리하고 싶다면 redis.conf에 다음 커맨드를 추가하면 된다. 

```
aclfile /etc/redis/users.acl
```

ACI 데이터가 redis. conf에 저장되든, 다른 ACL 파일 에 저장되든 저장되는 형태는 동일하며, 다만 저장되는 위치가 달라질 뿐이다.

ACI 파일을 사용하지 않을 때에는 CONFIG RENRITE 커맨드를 이용해 레디스의 모든

설정값과 ACI 룰을 한 번에 redis. conf에 저장할 수 있다.

## SSL/TLS


### 레디스에서 SSL/TLS 사용하기
기본적으로 비활성화 되어있어 레디스 빌드시 다음과 같이 정의해ㅔ야 한다

```
make BUILD_TLS=yes
```

레디스에서 SSI/TIS 프로토콜을 사용할 때에는 레디스 인스턴스와 클라이 언트 간 동일한 인증서를 사용한다. 따라서 다음 설정에서 정의한 key, cert, ca-cert 파일은 레디스를 실행할 클라이언트에 동일하게 복사해둬야 한다



redis.conf 파일에서 tls-port값을 추가하면 SSL/TLS 연결을 사용할것을 의미한다

```
tls-port <포트 번호>
tis-cert-file/path/to/redis.crt 
tls-key-file /path/to/redis.key 
tls-ca-cert-file /path/to/ca.crt
```

일반 포트, tls-포트 두 운용이 가능하다.

인증서 없이는 레디스 인스턴스로의 접근을 할 수 없도록  port 0을 명시해 기본 포트를 비활성화도 가능하다. 

redis-cli를 이용해 SSL/TLS 프로토콜을 활성화한 인스턴스에 접속할 때에는 연결 시 다음과 같이 인증서를 입력해야 한다

```
redis-cli --tls \
--cert /path/to/redis.crt \
--key /path/to/redis.key \
--cacert /path/to/ca.crt
```

### SSL/TLS를 사용한 HA 구성

SSL/TLS를 사용하는 마스터와 TIS 연결을 이용한 복제를 하기 위해서는 복제본도

마스터와 동일하게 다음 설정을 추가해야 한다.

```
tls-port <포트 번호>

tls-replication yes

tis-cert-file/path/to/redis.crt 
tls-key-file /path/to/redis.key 
tls-ca-cert-file /path/to/ca.crt
```

센티널에서도 SSL/TIS 연결을 사용해 레디스에 접속할 수 있다. 복제 연결을 할 때와 마찬가지로 센티널 구성 파일인 sentinel.conf에 다음 내용을 추가해야 한다.

```
tls-port <포트 번호>

tls-replication yes

tis-cert-file/path/to/redis.crt 
tls-key-file /path/to/redis.key 
tls-ca-cert-file /path/to/ca.crt
```

클러스터 구성에서 SSL/TLS 연결을 사용하려면 다음과 같이 tIs-cluster yes 구문을 추가하자.

```
tls-port <포트 번호>

tls-replication yes

tls-cluster yes

tis-cert-file/path/to/redis.crt 
tls-key-file /path/to/redis.key 
tls-ca-cert-file /path/to/ca.crt
```



# 12. 클라이언트 관리
## 클라이언트 핸들링
### 클라이언트 버퍼 제한

레디스는 각 클라이언트마다 출력 버퍼를 생성해, 반환할 데이터를 임시 저장합니다. 클라이언트 수가 많거나 데이터 처리 속도가 느릴 경우, 출력 버퍼가 커져서 메모리 사용량이 증가할 수 있습니다. 이를 방지하기 위해 레디스는 출력 버퍼의 크기에 대해 하드 제한과 소프트 제한을 설정하여, 버퍼 크기가 너무 커지면 클라이언트 연결을 종료합니다.

- **일반 클라이언트**: 기본적으로 출력 버퍼 크기 제한이 없습니다.
- **Pub/Sub 클라이언트**: 하드 제한은 32MB, 소프트 제한은 60초 동안 8MB를 유지할 경우 연결 종료.
  - 빠르게 처리되는 메시지들을 처리하기 위해 더 많은 메모리 공간이 필요하기 때문 
- **복제본 클라이언트**: 하드 제한은 256MB, 소프트 제한은 60초 동안 64MB를 유지할 경우 연결 종료.
  - 복제본이 마스터로부터 대량의 데이터를 받는 경우가 많아 큰 출력 버퍼가 필요 

이를 변경하기 위해서는 설정값을 변경하거나 CONFIG SET으로 변경할 수 있는데, 이 때 다음과 같은 커맨드를 수행한다.

```
CONFIG SET client-output-buffer-limit <class> <hard-limit> <soft-limit> <soft-limit-duration>
```

* class는 normal(일반 레디스 클라이언트) , slave(replica), pubsub중 하나다 

예를 들어 복제 클라이언트의 1imit 값을 모두 제거하려면 다음과 같이 입력하면된다.

```
CONFIG SET client-output-buffer-limit "slave 0 0 0"
```

레디스는 클라이언트 쿼리 버퍼라는 내부 버퍼도 운용하는데ㅡ 클라이언트에서 전송한 커맨드를 잠시 저장하는 역할을 합니다. 클라이언트가 커맨드를 보내면 레디스는 이를 쿼리 버퍼에 저장 후 처리한다. 기본적으로 쿼리 버퍼의 크기는 1GB로 설정되어 있으며, 이는 클라이언트에서 발생할 수 있는 버그로 인해 쿼리 버퍼가 과도하게 커지는 것을 방지하기 위함.

필요한 경우, `client-query-buffer-limit` 설정을 변경하여 쿼리 버퍼의 크기를 조정할 수 있다. 이를 통해 특별한 상황에 맞게 쿼리 버퍼의 크기를 원하는 대로 설정할 수 있다.

### 클라이언트 이빅션

클라이언트 연결도 메모리를 사용해서 클라이언트 연결 수가 많아지면 메모리를 과다 사용해 OOM이나 데이터 eviction을 유도할 수도 있다.

레디스는 클라이언트 연결에 의해 증가하는 메모리 사용량을 관리하기 위해, Redis 7.0 버전부터 `maxmemory-clients` 이 설정을 통해 모든 클라이언트 연결(일반 및 pub/sub 포함)이 사용하는 메모리의 총량을 제한할 수 있다.



클라이언트 이빅션은 **메모리 사용량이 설정된 임계치에 도달하면 메모리를 확보하기 위해 서버에서 클라이언트 연결을 자동으로 해제하는 기능이다.**

서버는 메모리 사용량이 가장 높은 클라이언트부터 연결을 끊어 필요한 최소한의 클라이언트만 해제하여 `maxmemory-clients` 설정 값을 초과하지 않도록 한다.

- **설정 파일**: `redis.conf`에서 `maxmemory-clients` 값을 설정하거나, `CONFIG SET` 커맨드를 이용해 동적으로 변경할 수 있다.
- **비활성화**: 이 값을 `0`으로 설정하면 클라이언트 이빅션 기능이 비활성화된다. 디폴트로 비활성화 되어있다. 
- **퍼센티지 설정**: 예를 들어, `maxmemory-clients 5%`라고 설정하면, 이는 Redis 서버의 전체 `maxmemory` 설정의 5%만큼만 클라이언트 연결에 할당되도록 한다 .

```
maxmemory-clients 1G
maxmemory-clients 5%
```

대규모 트래픽 환경에서는 5%나 10%같은 값이 권장된다.

특정 클라이언트 연결을 클라이언트 이션 기능에서 제외시킬 수도 있다. 예를 들어 레디스 서버를 주기적으로 모니터링하고 알림을 보내는 애플리케이션의 경우, 해당 클라이언트 연결은 이빅션의 영향을 받지 않도록 설정하는 것이 좋다.

```
\> CLIENT NO-EVICT on

OK
```

* 이 설정을 해제하고 싶다면 `CLIENT NO-EVICT off` 커맨드를 실행

### Timeout과 TCP Keepalive

클라이언트가 연결되면 커맨드를 수행하지 않더라도 연결은 계속 유지된다.

특정 시점에 활동이 없는 클라이언트를 정리하려면 타임아웃 설정을 사용해 해제할 수 있다.

redis.conf 또는 다음 설정으로 처리할 수 있다.

```
CONFIG SET timeout 600
```

이 설정은 pub/sub클라이언트에는 영향을 주지 않는다.

`tcp-keepalive` 설정은 연결된 클라이언트에게 주기적으로 TCP ACK를 보내고, 클라이언트로부터 응답이 없으면 연결을 끊는다.

기본값으로 300초이며 연결된 클라에게 5분마다 한번씩 TCP ACK를 보낸다. 

## 파이프라이닝
레디스 파이프라이닝은 클라이언트가 연속적으로 여러개의 커맨드를 보내는 기능이다. 

한번에 여러 커맨드를 일괄 처리하여 보내면 응답속도를 줄이고 처리량을 늘릴 수 있다.

사용법은 줄바꿈을 이용해 동시에 실행할 여러 커맨드를 보내면 된다. 

코틀린 렛튜스 예제

```kotlin
fun main() {
    // Redis 클라이언트 생성
    val redisClient = RedisClient.create("redis://localhost:6379")

    // 커넥션 열기
    val connection: StatefulRedisConnection<String, String> = redisClient.connect()
    
    try {
        // 명령어 동기화를 위한 API 가져오기
        val commands: RedisCommands<String, String> = connection.sync()

        // 파이프라이닝 시작
        commands.multi()  // 트랜잭션 시작

        // 여러 명령어를 한 번에 보내기
        commands.set("key1", "value1")
        commands.set("key2", "value2")
        commands.get("key1")
        commands.get("key2")

        // 파이프라이닝 실행 및 응답 받기
        val results = commands.exec()  // 트랜잭션 실행

        // 결과 출력
        println("Results: $results")
    } finally {
        // 자원 정리
        connection.close()
        redisClient.shutdown()
    }
}
```



성능향상에 도움이 되지만 주의할점이있다.

1. 한번에 너무 많은 쿼리를 보내면 네트워크 대역폭 한계로 인해 속도 저하 가능 및 쿼리 버퍼 제한에 걸릴 수 있다.

때문에 쪼개서 배치로 보내는게 낫다.

## 클라이언트 사이드 캐싱

매번 레디스 리모트 캐시보단 로컬에서도 캐시를 이용할 수 있다. 

로컬 캐싱을 이용하면 네트워크 를 이용하지 않고 데이터를 반환하기 때문에 응답 시간을 크게 단축할 수 있다. 또한 레디스에 접근하지 않고도 데이터를 반환하기 때문에 레디스 서버의 부하도 줄일 수 있다.

그러나 정합성을 고려해야하는데, 정합성을 위해 2가지 모드의 클라이언트 사이드 캐싱을 지원한다.

1. Default Mode
2. Broadcasting Mode

디폴트 모드에서는 레디스 서버가 클라이언트가 액세스한 키를 기억해서 동일한 키가 수정될 때 무효 메시지를 전송한다.

* 레디스 서버가 이를 기억해야해서 메모리 비용이 들지만, 정확히 무효 메시지를 보낼 수 있다는 장점

브로드캐스팅 모드에서는 레디스가 모든 키에 대한 액세스를 기억하지 않고 특정 프리픽스에 대해 접근한 클라이언트만 기억해서 메모리가 적게 사용된다.

프리픽스와 일치하는 키가 변경될 때마다 변경 메시지를 수신하는 단점이 존재하며, 이로 인해 레디스 서버는 CPU 자원을 소비할 수 있다.

# 13. 레디스 운영하기

## 레디스 모니터링 구축하기
### 프로메테우스와 그라파나를 이용한 레디스 모니터링
레디스 서버에 레디스 익스포터와 노드 익스포터를 띄워 모니터링 한다

* 레디스 익스포터는 레디스 인스턴스의 정보 수집
* 노드 익스포터는 레디스가 실행되는 서버의 하드웨어와 OS 메트릭을 수집

### 레디스 플러그인을 이용한 그라파나 대시보드

그라파나에서 레디스 플러그인을 설치하면 RedisGrafana에서 제공하는 대시보드를 이용해 실시간으로 레디스의 상태 를 확인할 수 있다. 앞선 방법에서와 같이 레디스 익스포터를 설치할 필요가 없다.

* http://dashboard/connections/datasources/redis-datasource

## 레디스 버전 업그레이드
운영중인 레디스 버전 업그레이드 방법은 2가지다

1. 업그레이드할 버전의 레디스 인스턴스를 새로운 서버에 설치하고 기존 버전의 레디스를 복제. 
2. 실행중 레디스 인스턴스 중지한 다음 신규 버전의 레디스를 재실행하는 방식. 





### 센티널 구성의 레디스 버전 업그레이드

```
1. 신규 버전의 레디스 바이너리 파일 다운로드

2. 3대의 센티널 인스턴스 모두 중단
$ /home/centos/redis/src/redis-cli -p 26379 shutdown

3. 신규 버전 폴더에 기존의 sentinel.conf 복사
$ cp /home/centos/redis-old/sentinel.conf /home/centos/redis/sentinel.conf

4. 신규 바이너리 파일을 이용해 3대의 센티널 인스턴스 시작
$ /home/centos/redis/src/redis-sentinel/home/centos/redis/sentinel.conf

5. 복제본 인스턴스 중단
$ /home/centos/redis/src/redis-cli config rewrite 
$ /home/centos/redis/src/redis-cli shutdown

6. 신규 버전 폴더에 기존의 redis. conf 복사
$ cp /home/centos/redis-old/redis.conf /home/centos/redis/redis.conf

7. 신규 바이너리 파일을 이용해 복제본 인스턴스 시작
$ /home/centos/redis/src/redis-server/home/centos/redis/redis.conf

8. 센티널에서 수동 페일오버 수행
127.0.0.1:26379> sentinel failover mymaster
9. 기존 마스터 인스턴스 중단

10. 신규 버전 폴더에 기존의 redis. conf 복사

11. 신규 바이너리 파일을 이용해 기존 마스터 인스턴스 시작

12. 센티널에서 수동 페일오버 수행(페일백)
```



### 클러스터 구성의 레디스 버전 업그레이드

클러스터의 각 레디스 인스턴스를 A, B, C, D, E, F라 하고, 

A, B, C 인스턴스가 마스터 

그리고 D, E, F 노드가 각각 A, B, C 노드의 복제본일 때 다음과 같은 순서로 업그레이드할 수 있다.

1. ﻿﻿﻿D, E, F 노드 각각 버전 업그레이드
2. ﻿﻿﻿D 노드에서 페일오버
3. ﻿﻿﻿A 노드 업그레이드
4. ﻿﻿﻿E 노드에서 페일오버
5. ﻿﻿﻿B 노드 업그레이드
6. ﻿﻿﻿F 노드에서 페일오버
7. ﻿﻿﻿C 노드 업그레이드

## 레디스 운영 가이드
### 장애 또는 성능 저하를 유발할 수 있는 레디스의 설정 항목

**maxmemory-policy**

maxmemory-policy는 레디스가 메모리 한계에 도달했을 때 어떤 키를 제거할지를 결정하는 설정값이다. 기

본값은 noeviction으로 설정돼 있으며, 레디스에 데이터가 가 득 차더라도 임의로 데이터를 삭제하지 않고, 레디스에 데이터를 더 저장할 수 없다는 에러를 반환한다.

로직에 따라 애플리케이션 장애로 이어질 수 있다. 

따라서 만약 레디스의 일부 데 이터가 임으로 삭제되더라도 계속해서 새로운 입력을 받고 싶다면 이 값을 allkeys-Iru로 설정할 것을 권장한다.

**stop-writes-on-bgsave-error**

이 설정은 RDB 스냅숏이 정상적으로 저장되지 않았을 때 레디스로의 모든 쓰기 작업을 중지하는 역할을 한다. 

이로써 최신 백업이 실패한 것을 인지하고 서버에 문제 가 있음을 알려줘 더 큰 장애를 방지할 수 있다

* 다른 모니터링기능을 활성화하여 대비할 수 있어 끄고 싶다면 이 설정을 비활성화하는것 이 좋다.

**자동 백업 옵션(RDB, AOF)**

백업 작업은 의도한 시간에 의도한 레디스 인스턴스에서 실행될 수 있도록설정하는 것이 좋다.

save 옵션은 일정한 기간 동안 변경된 키 수의 개수가 조건에 맞을 때 자동으로 RDB파일을 생성한다. save 옵션의 기본값은 다음과 같이 설정돼 있다.

```
CONFIG GET SAVE
1) "save"
2) 3600 1 300 100 60 10000
```

대규모 트래픽에서 이렇게 유지하면 RDB 파일이 문제가 생길 수 있으므로 기본 설정값을 사용하지 않는것이 좋다.

appendonly 옵션을 yes로 설정해서 AOF 형식의 백업을 수행하는 경우에도 주의하 는 것이 좋다. 

기본적으로, AOF 파일 크기가 기존의 AOF 파일보다 100% 증가하면 자동 재작성이 발생한다.

이것도 비활성화는

```
CONFIG SET auto-aof-rewrite-percentage 0
```

### 레디스 운영 및 성능 최적화

커맨드 유형별 O(N) 이상 걸리는 커맨드를 주의하자.

* KEYS ((모든 키 반환 ))
* FLUSHALL ( 모든 키 삭제) : ASYNC와 같이 쓰는것이 좋다 
* FLUSHDB (모든 디비 삭제)  : ASYNC와 같이 써 백그라운드에서 작업하게 두는것이 좋다. 

### LAZY FREEING

레디스에서는 기본적으로 키를 삭제할 때 `DEL` 커맨드를 사용하는데, 이 방식은 동기적으로 작동하여 작은 자료구조나 아이템 수가 적은 경우에는 매우 빠르게 처리됩니다. 하지만, 수백만 개의 아이템을 가진 큰 키를 삭제할 경우 시간이 오래 걸릴 수 있습니다. 이를 해결하기 위해 레디스는 `UNLINK` 커맨드 같은 비동기적 메모리 해제 방식을 제공합니다.

레디스에서는 기본적으로 키를 동기적으로 삭제하지만, 설정을 변경하여 기본적으로 비동기적으로 삭제하도록 구성할 수 있습니다. 이와 관련된 설정 옵션은 다음과 같습니다:

- **lazyfree-lazy-eviction**: 메모리 제한을 위한 데이터 삭제 시 동기적 삭제 여부 설정
- **lazyfree-lazy-expire**: 만료된 키를 동기적으로 삭제할지 여부 설정
- **lazyfree-lazy-server-del**: 서버 동기화나 다른 명령의 사이드 이펙트로 인한 키 삭제 시 동기적 삭제 여부 설정
- **replica-lazy-flush**: 복제 동기화 시 데이터베이스 내용을 동기적으로 삭제할지 설정
- **lazyfree-lazy-user-del**: 사용자 코드에서 `DEL` 호출을 `UNLINK` 호출과 동일하게 처리

이 설정들의 기본값은 모두 `no`이며, `yes`로 변경할 때는 충분한 모니터링이 필요합니다. 설정을 `yes`로 변경하면 키와 값의 연결은 해제되지만, 해당 데이터가 메모리에서 바로 삭제되지 않고 일시적으로 남아 있게 됩니다. 이로 인해 메모리 사용량이 예상보다 증가할 수 있으므로, 활성화할 때 주의가 필요하며 메모리 사용량과 성능을 신중하게 모니터링해야 합니다.

### DEL 



DEL - list, set, sorted set, hash같은 자료구조 삭제시 아이템 수에 따라 선형적으로 시간이 증가한다.

때문에  UNLINK를 이용하는것이 좋다 (비동기로 삭제 )

```
UNLINK key1
```



### SORT / SORT/RO

list, set, sorted set에서만 사용한 커맨드. 키 내부의 아이템을 정렬해서 반환한다.

SORT의 시간복잡도는 O (N + Mlog(M))

* N은 아이템 수, M은 반환되는 아이템 수 

LIMIT 옵션 사용시 반환 아이템 수가 M으로 정의된다.

자료 구조 내에 너무 많은 아이템이 존재할 경우, SORT 커맨드를 이용한 정렬 작업에 많은 시간이 소요될 수 있으므로 이를 피하는 것이 좋다. 꼭 레디스 내에서 SORT 커맨 드를 이용해 정렬이 필요한 경우라면 자료 구조 내의 아이템 수를 적정하게 관리하는 것이 좋다.

### SET 관련 커맨드

| 커맨드      | 설명                     | 시간 복잡도 |
| ----------- | ------------------------ | ----------- |
| SDIFF       | 차집합 수행              | O(N)        |
| SDIFFSTORE  | 차집합 결과 저장         | O(N)        |
| SUNION      | 합집합 수행              | O(N)        |
| SUNIONSTORE | 합집합 결과 저장         | O(N)        |
| SINTER      | 교집합 수행              | O(NM)       |
| SINTERSTORE | 교집합 결과 저장         | O(NM)       |
| SINTERCARD  | 교집합의 카디널리티 계산 | O(NM)       |

### LIST 관련 커맨드

| 커맨드  | 설명                        | 시간 복잡도 |
| ------- | --------------------------- | ----------- |
| LINDEX  | 특정 인덱스 아이템 반환     | O(N)        |
| LINSERT | 피봇값 기준으로 아이템 삽입 | O(N)        |
| LSET    | 특정 인덱스 아이템 변경     | O(N)        |

### HASH 관련 커맨드

| 커맨드  | 설명               | 시간 복잡도 |
| ------- | ------------------ | ----------- |
| HGETALL | 모든 키-값 쌍 반환 | O(N)        |
| HKEYS   | 모든 키 반환       | O(N)        |
| HVALS   | 모든 값 반환       | O(N)        |

### SORTED SET 관련 커맨드

| 커맨드         | 설명                     | 시간 복잡도       |
| -------------- | ------------------------ | ----------------- |
| 기본 삽입/삭제 | 데이터 자동 정렬         | O(log(N))         |
| ZDIFF          | 차집합 수행              | O(L+(N-K)log(N))  |
| ZDIFFSTORE     | 차집합 결과 저장         | O(L+(N-K)log(N))  |
| ZUNION         | 합집합 수행              | O(N)+O(M*log(M))  |
| ZUNIONSOTRE    | 합집합 결과 저장         | O(N)+O(M*log(M))  |
| ZINTER         | 교집합 수행              | O(NX)+O(M*log(M)) |
| ZINTERSTORE    | 교집합 결과 저장         | O(NX)+O(M*log(M)) |
| ZINTERCARD     | 교집합의 카디널리티 계산 |                   |



## 레디스 트랜잭션 사용과 주의사항

레디스는 싱글 스레드로 동작하며 트랜잭션 사용시 주의해야 한다.

또한 두가지 방식으로 트랜잭션을 사용할 수 있다.

### MULTI /EXEC

MULTI는 트랜잭션을 시작하는 커맨드다. 이후 트랜잭션에서 실행하고자 하는 커맨드 를 MULTI 이후에 입력한 뒤, EXEC 커맨드를 사용하면 입력했던 커맨드를 원자적으로 실행하고, 트랜잭션이 성공하면 결과를 반환한다. 만약 트랜잭션 도중 오류가 발생하 면 트래잭션 내의 모든 커맨드를 롤백하고 트랜잭션을 종료한다.

잔고를 100 증가시키고, 거래 로그에 입금 내역을 추가하려면 MULTI와 EXEC 사이에 관련 명렁어를 입력할 수 있다.

```
\> MULTI

OK

(TX)> INCRBY account_balance 100

QUEUED

(TX)> RUSH transaction log " 100"

QUEUED

(TX) > EXEC

1. (integer) 100
2. (integer) 1
```

### 루아 스크립트

루아 스크립트는 레디스 내에서 원자적으로 실행되므로 여러 명령을 한 번에 실행하 고, 중간에 다른 클라이언트 요청을 수용하지 않아 데이터 일관성을 유지할 수 있다.

트랜잭션과 비슷한 원자성을 갖지만, 트랜잭션과 달리 일부 명령어가 실패하더라도 다음 명령어로 진행되며 롤백이 발생하지 않는 특징이 있다.

프로그래밍적 스크립트 코드

````lua
-- 키 이름과 인자를 받음
local key = KEYS[1]
local amount = tonumber(ARGV[1])

-- 인자값만큼 키의 값 증가시키고 새로운 잔고 계산
local newBalance = redis.call('INCRBY', key, amount)

-- 로그 메시지 생성 및 로그에 기록
local logMessage = '입금: ' .. amount
local logCount = redis.call('RPUSH', 'transaction_log', logMessage)

-- 결과 반환
return { newBalance, logCount }
````

레디스에서 스크립트를 로드하고 실행하려면 다음과 같이 SCRIPT LOAD 커맨드와

EVALSHA 스크립트를 사용할 수 있다.

```
> SCRIPT LOAD "local key = KEYS[1] local amount = tonumber(ARGV[1]) local newBalance = redis.call('INCRBY', key, amount) local logMessage = '입금: ' .. amount local logCount = redis.call('RPUSH', 'transaction_log', logMessage) return { newBalance, logCount }"
"1bb437215c104541ade5f5a9d889a2356f201361"
```

*  EVALSHA를 사용하면 스크립트를 다시 전송하지 않고도 스크립트를 반복해 실행할 수 있으므로 네트워크 대역폭을 절약할 수 있다.

### 트랜잭션과 루아 스크립트 사용할 때의 주의점

하지만 트랜잭션과 루아 스크립트를 사용하는 도중에 다른 클라이언트의 커맨드는 모두 대기하게 되므로, 트랜잭션의 길이가 길어지지 않도록 각별한 주의가 필요하다. 

레디스에서는 트랜잭션과 루아 스크립트 내부에 블로킹 커맨드(BLPOP, BRPOP)를 사용할 수 없도록 강제하고 있는데, 트랜잭션 내부에서 블로킹될 경우 레디스는 무한 대기 상 태에 빠질 수 있기 때문이다.

## has-get / has-del 패턴 사용 지양

레디스에서 데이터 조회 또는 삭제 시 EXISTS 커맨드를 사용해 데이터 존재 여부를 확인한 뒤 처리하는 has-get 및 has-del 패턴은 지양하는 것이 좋다. 이러한 패턴은 네트워크 부하를 늘리며, 불필요한 작업을 수행해 애플리케이션의 성능을 저하시킬 수 있는 좋지 않은 관행이다.



**그냥 직접 GET 해서 데이터를 가져오자**

레디스에서 GET과 같은 조회 커맨드는 키가 존재하지 않는 경우 nil 값을 반환하고, 

DEL 커맨드는 키가 없어도 에러를 반환하지 않으며 아무런 문제 없이 작동한다.



## 레디스 키스페이스 알림을 사용한 키 만료 모니터링

레디스에서 키스페이스 알림keyspace notfication 기능은 레디스 내부 키에 대한 변경 사항 을 모니터링하며 내부의 pub/sub 채널을 이용해 변경 사항에 대한 메시지를 구독할 수 있는 기능이다. 

예를 들어 키의 만료를 지속적으로 감시하다가 만료 이벤트가 발생 하면 신속하게 감지해 애플리케이션에서 필요한 추가 작업을 수행할 수 있다.

키스페이스 알림을 활성화하기 위해서는 notify-keyspace-events 설정 파일에 어 떤 알람을 수신할 것인지를 지정해야 한다. 

다음의 여러 문자를 조합해 구독하고자 하 는 데이터를 지정할 수 있다.

- ﻿﻿K: 키스페이스 이벤트. 이벤트가 발생한 데이터베이스에 대해 `keyspace@<db>` 접두사와 함께 발행
- ﻿﻿E: 키 이벤트./ 이벤트가 발생한 데이터베이스에 대해 `keyevent@<db>` 접두사와 함께 발행

- ﻿﻿g: 일반적인 명령 이벤트Generic commands. DEL, EXPIRE, RENAME 등과 같은 명령어 와 관련된 이벤트
- ﻿﻿$$: 문자열 명령어String commands와 관련된 이벤트
- ﻿l: 리스트 명령어list commands 와 관련된 이벤트
- ﻿﻿s: 집합 명령어Set commands 와 관련된 이벤트
- ﻿﻿h: hash 명령어Hash commands 와 관련된 이벤트
- ﻿﻿z: 정렬 집합 명령어 Sorted set commands와 관련된 이베트
- ﻿﻿t: stream 명령어stream commands 와 관련된 이베트
- ﻿﻿x: 만료된 키 이베 트Expired events
- ﻿﻿e: 삭제된 키 이벤트Evicted events
- ﻿﻿m: 누락된 키 이벤트Key missevens. 존재하지 않는 키에 접근할 때 발생
- ﻿﻿n: 새로운 키 이벤트New key events
- ﻿﻿A: g$Ishztxed”의 별칭으로, "m' 및 "n" 이벤트를 제외한 모든 이벤트를 포함

만료 이벤트를 수신하기 위해서는 다음과 같이 CONFIG SET 커맨드를 이용할 수 있다.

```
\> CONFIG SET notify-keyspace-events Ex
```

* keyevent@0__-:expired 채널을 구독하면 키가 만료될 때 아래와 같은 메시지를 수 신하게 된다.

```
\> SUBSCRIBE __keyevent@0__:expired

1. "message"
2. "__keyevent@0__:expired"
3. "my key"

```



### ## 레디스 모니터링

### 슬로우 로그

실행속도가 느린 커맨드를 기록하는 로그 

SLOWLOG GET 커맨드를 이용해서 확인 가능

```
SLOWLOG GET 
1) 1) (integer) 1923
   2) (integer) 1696344048
   3) (integer) 35233
   4) 1) "SCAN"
      2) "10179327"
      3) "COUNT"
      4) "50000"
```

각 레코드는 다음과 같은 정보를 나타낸다.

- ﻿﻿실행 시간Timestamp: 명령이 실행된 시간 정보
- ﻿﻿실행 시간ms: 명령이 실행되는 데 소요된 시간(밀리초 단위)
- ﻿﻿명령: 느리게 수행됐던 커맨드

설정 파일에서 슬로우 로그와 관련된 설정을 변경할 수 있다. 

슬로우 로그에 남는 기 준은 `slowlog-log-slower-than`설정값으로 변경 할 수 있으며, 기본은 10,000ms, 즉 10초다. 기본적으로 10초 이상 수행되는 커맨드는 슬로우 로그에 기록된다.