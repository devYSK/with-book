# 막힘없이 Postgresql

[toc]



# 1장 Postgresql 아키텍처

![image-20250228173416801](./images//image-20250228173416801.png)

* Postgresql 구성요소 : 프로세스, 파일(시스템운영에 필요한), 메모리

주요 프로세스 : postmaster, background, backend

메모리 : 개별 프로세스를 위한 로컬 메모리, 모든 프로세스 공유 메모리

메모리에서 처리된 데이터는 디스크 기록 전 모든 변경 사항을 WAL 로그에 기록하여 일관성을 보장한다.

## 주요 프로세스

Postmaster 프로세스와 Postmaster에서 포크된 여러 프로세스들로 구성되어 있다.

### Postmaster 프로세스

인스턴스 기동 시 가장 먼저 시작, 여러 Background, Backend 프로세스 생성.

클라이언트가 접속 시도시 별도의 Backend 프로세스가 생성되고 연결이 끊기기전까지 유지됌

### Backend 프로세스 (max_connections)

클라이언트 연결시 생성되며 클라이언트가 요청한 쿼리를 수행하고 결과를 전송하는 역할. 

backend 프로세스 수는 기본값이 100이며 max_connections 파라미터를 통해 변경 가능.

backend 프로세스에서 사용하는 로컬 메모리 영역을 정의하는 파라미터 정보

아래는 추가 정보 및 주의 사항을 포함하여 마크다운 표로 정리한 예시입니다.

| 이름                 | 설명                                                         | 추가 정보 및 주의 사항                                       |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| work_mem             | 정렬 작업(Order by, Group by, DISTINCT)와 조인 작업 시 사용하는 메모리 공간 | 복잡한 쿼리 시 성능 개선에 도움. 너무 낮으면 디스크 기반 정렬로 전환되어 성능 저하, 과도하게 높게 설정 시 동시 접속 시 총 메모리 사용량 급증 주의. 예: 집계 쿼리 성능 최적화 시 조정 필요. |
| maintenance_work_mem | Vacuum 작업 및 인덱스 생성 작업에 사용                       | 대규모 인덱스 재구성이나 Vacuum 작업 시 속도 개선 가능. 시스템 전체 메모리 상황과 작업 빈도를 고려하여 설정 필요. |
| temp_buffers         | 세션 단위로 임시 테이블에 접근하기 위해 사용하는 메모리 공간 | 임시 데이터를 많이 다루는 애플리케이션에 유리. 다수의 세션이 동시에 사용할 경우 총 메모리 사용량 증가에 주의. |
| catalog_cache        | 스키마 내부의 메타데이터를 이용할 때 사용하는 메모리 공간    | 메타데이터 조회 속도 향상에 도움. 캐시 효율성이 떨어지면 불필요한 I/O가 발생할 수 있으므로 데이터베이스 구조와 사용 패턴에 맞게 조정 필요. |

### Background 프로세스

Background 프로세스는 대부분 운영용이다.

background writer와 WAL writer는 필수 프로세스이고 나머지는 선택적이다.

| 이름                  | 설명                                                         | 추가 정보 및 주의 사항                                       |
| --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Background writer** | 주기적으로 shared buffer의 dirty 페이지를 디스크에 기록      | 지속적인 디스크 쓰기를 수행하므로 I/O 부하를 고려해야 합니다. 예: 과도한 쓰기 요청 시 성능 저하 가능. |
| Checkpointer          | 특정 간격으로 모든 dirty 페이지와 트랜잭션 로그를 디스크에 기록 | 데이터 안전성을 위해 중요한 역할을 합니다. 체크포인트 간격이 짧으면 디스크 부하가 증가할 수 있으니, 시스템 특성에 맞게 조정 필요. |
| Autovacuum launcher   | AutoVacuum이 필요한 시점에 수행하고 관리                     | 데이터베이스 유지보수를 자동으로 관리하지만, 상황에 따라 수동 개입이 필요할 수 있습니다. 예: 자주 변경되는 테이블 관리 시. |
| **WAL writer**        | WAL(writer-ahead log)을 디스크에 기록                        | 로그 기반 복구에 필수적입니다. WAL 기록 지연 시 복구 작업에 영향을 줄 수 있으므로 모니터링이 필요합니다. |
| Statistics collector  | 세션정보 및 테이블 통계정보와 같은 DB 사용 통계를 수집하여 pg_catalog에 반영 | 쿼리 최적화에 중요한 통계를 제공합니다. 통계 업데이트 주기를 조정하여 성능에 미치는 영향을 관리할 수 있습니다. |
| Archiver              | WAL 파일이 가득 차면 디스크에 기록                           | WAL 파일의 보관 및 백업을 위해 필요합니다. 아카이브 설정 미비 시 디스크 공간 부족 문제가 발생할 수 있습니다. |
| logger                | 오류 메시지를 로그 파일에 기록                               | 시스템 문제 추적에 유용합니다. 로그 파일 관리 및 주기적 로테이션 설정이 필요합니다. |

* 데이터베이스에서 특정 레코드를 업데이트하면 해당 페이지는 "dirty" 상태가 되는데, Background writer 같은 프로세스가 주기적으로 이러한 dirty 페이지들을 디스크에 기록함으로써, 나중에 장애가 발생해도 최신 데이터를 복구할 수 있도록 함.
* **왜 이렇게 하나?**
  - 매번 디스크에 쓰면 I/O 부하가 커지므로, Dirty 페이지를 모아서 효율적으로 기록
  - 장애 발생 시 데이터 유실을 방지하기 위해 일정 주기로 디스크에 기록 (Checkpoint 등)

## 메모리

PG 메모리는 크게 3가지로 나눌 수 있음

* 모든 프로세스들의 shared Memory
* Backend 프로세스에 해당하는 Local Memory
* OS 캐시 영역



Shared Memory는 다소 작게 설정되도록 설계되어 있다

```
shared_buffers = (Total RAM * 0.25)  # 일반적인 권장값 (물리 RAM의 25%)
```

나머지는 OS의 커널, 서비스, 캐시 등에서 사용 

* 25%만 사용하도록 권장하는 이유는, 공유 메모리와 OS 캐시를 함께 사용하여 데이터에 빠르게 접근하기 위해서

* 너무 크면 OS의 파일 캐시를 줄여 성능 저하 가능성 있음.

* `shared_buffers`가 너무 크면 **Checkpoint 시 대량의 데이터를 한꺼번에 기록**해야 하므로 I/O 부하 증가 가능.

* shared_buffers 최적 설정 찾는법

  * ```
    // 현재 설정 확인
    SHOW shared_buffers;
    
    // pg_buffercache 확장을 사용하여 버퍼 사용률 분석 가능
    // Dirty 페이지 비율이 너무 높다면 Checkpoint 설정과 함께 shared_buffers 조정 고려.
    SELECT count(*) FILTER (WHERE isdirty) * 100.0 / count(*) AS dirty_page_ratio
    FROM pg_buffercache;
    
    이후 pgbench 등을 사용해 성능 테스트 진행 후 최적값 조정.
    ```

  * 

<img src="./images//image-20250228194937975.png" width = 750>

이외에도 메모리라 불리는 캐시들의 공통점은 모두 디스크로의 물리 I/O를 줄여 속도를 향상시키는데 있다. 

### 공유 메모리 Shared Memory

Shared Buffers, WAL Buffers, CLog Buffers, Lock 스페이스 등으로 이루어 져있다

* Shared buffer : 일반적인 DB의 버퍼 캐시와 유사
  * 데이터의 변경 사항을 페이지 단위로 처리하며 물리 IO를 줄여 데이터에 빠르게 접근하기 위해 사용.
  * shared Buffer의 크기는 shared_buffers 파라미터로 설정. 
  * 기본값은 128MB이며, **IO 단위**는 block_size에 의해 정해지고 기본값은 8kb
* WAL 버퍼 : 데이터들의 변경 사항들이 임시로 저장되는 영역
  * 여기 저장된 내용은 시간이 지나면 영구 저장소인 WAL 세그먼트 파일에 기록. 
  * 복구가 필요할 때 데이터를 재구성하는 영역이며 wal_buffers 파라미터에 의해 크기가 정의됨 
* Clog(Commit log) 버퍼 : 트랜잭션의 커밋 아태를 기록하는 로그 파일 
  * in_progress, Committed, Aborted 같은 정보가 저장됨
  * 디비 엔진에 의해 자동 관리
* 락 스페이스 : Shared Buffer에서 락 관련 내용을 보관하는 영역으로 모든 유형의 락 정보를 저장
  * 이곳에 저장된 락 정보는 트랜잭션들의 순차성을 보장하며 데이터들의 일관성과 무결성을 유지한다
  * 메모리에서 저장할 수 있는 락 개수 
    * : max_locks_per_transaction * (max_connection + max_prepared_transactions)
* Other Buffers
  * 통계 정보, Two Phase commit, CheckPoint, Autovaccum 등 백그라운드 프로세스를 위한 메모리 영역 



### 2.2 로컬 메모리 

**Backend 프로세스가 쿼리를 위해 사용하는 영역**. 사용자가 요청한 쿼리를 실행 후 결과를 전송하는 임무를 수행.

로컬 메모리는 개별 세션에 대한 영역을 의미하며, 로컬 메모리의 전체 크기는 사용자 접속 수(커넥션 수)를 고려해서 설정해야 한다.

세션 단위, 트랜잭션 단위로 설정이 가능하다.

```
--- 세션 단위
SET work_mem = '16MB';

--- 트랜잭션 단위
SET LOCAL work_mem = '16MB';

-- 초기값으로
RESET work_mem;
```

주요 파라미터

* maintenace_work_mem : 기본값은 64MB work_mem 의 1.5배를 권장
  * vaccum, 인덱스 생성, 테이블 변경, 외래키 추가 등 같은 작업에 사용되는 공간 
* temp_buffers : TEmp 테이블 사용을 위한 공간이며 세션 단위로 할당. 기본값은 8MB
* work_mem : 쿼리 정렬 작업 / 해시 연산 수행시 사용되는 메모리 공간으로 기본값은 4MB
  * shared_buffers / max_connections 값으로 계산하는게 국룰
  * 이 영역이 크기가 모자르면 temp 파일인 디스크를 쓰게 됌. 
* Optimizer/Executor 수행한 쿼리들에 대한 최적의 실행계획 수립 및 실행시 사용 

## PostgreSQL 구조

### 3.1 Logical Structure

논리 구조와 물리 구조로 나눌 수 있다.

논리 구조

* 튜플 : 페이지 단위로 저장되며 하나의 페이지에 여러 튜플이 존재
* 오브젝트 : 페이지의 집합
* 스키마: 오브젝트의 집합
* 데이터베이스 : 스키마의 집합
* 클러스터 : 데이터베이스와 Role, 그리고 테이블 스페이스의 집합

![image-20250301212304813](./images//image-20250301212304813.png)

#### 클러스터 

클러스터는 논리적인 개념. 하나 이상의 데이터베이스와 Role, 테이블 스페이스의 집합.

<img src="./images//image-20250301212354263.png" width = 550>

하나의 인스턴스는 하나의 클러스터만을 관리하며, 한번에 여러 데이터베이스에 서비스 제공 가능. 

#### 데이터베이스

클러스터는 여러 데이터베이스로 구성할 수 있다.

최초 initdb() 수행시, Template0, Template1, Postgres 3개의 데이터베이스가 생성된다.

* Template : db 생성시 템플릿을 제공하기 위해 만들어진 DB.
  * 사용자가 Template1에 객체 추가 후 새 DB 생성마다 여기서 복제되어 동일하게 사용 가능
  * Template 0은 아예 초기상태이고, Template1에다 커스텀해서 사용한다

#### 스키마

스키마는 다양한 오브젝트들의 집합. 한 데이터베이스의 다수 스키마를 소유할 수 있다.

테이블 생성시 기본 스키마는 Public이다. 

pg_catalog.pg_namespace를 조회하면 현재 DBdㅔ 존재하는 스키마 확인 가능. 

#### 오브젝트(Object)

데이터를 저장하거나 참조하는데 사용되는 구조이며, 테이블, 인덱스, 뷰, 시퀀스, 프로시저 등

| 오브젝트                | 설명                                                         |
| ----------------------- | ------------------------------------------------------------ |
| **테이블(Table)**       | 데이터를 저장하는 기본 단위. 열(column)과 행(row)로 구성된다.<br>각 열은 특정 유형의 데이터를 저장하고, 각 행은 테이블의 한 레코드(튜플)를 나타낸다. |
| **뷰(View)**            | 하나 이상의 테이블에서 데이터를 선택적으로 보여주는 가상 테이블이다.<br>뷰는 데이터베이스 내의 데이터를 요약하거나, 복잡한 쿼리를 단순화하는 데 사용된다. |
| **인덱스(Index)**       | 데이터 검색 속도를 향상시키기 위해 사용되는 오브젝트이다.<br>인덱스는 테이블의 하나 또는 여러 개의 열을 기준으로 생성될 수 있으며, 데이터 검색 시 빠른 데이터 접근을 가능케 한다. |
| **시퀀스(Sequence)**    | 일련번호 생성기로 사용되며, 주로 자동 증가 필드(예: 기본 키)에 사용된다.<br>시퀀스를 통해 고유한 숫자 값을 차례대로 생성할 수 있다. |
| **함수(Function)**      | 특정 작업을 실행하는 SQL 문이나 코드 블록이다.<br>함수는 데이터 처리, 계산 수행, 데이터 변환 등 다양한 작업에 사용된다. |
| **프로시저(Procedure)** | 데이터베이스에서 실행할 수 있는 저장된 명령어 집합을 정의하여 데이터 처리를 자동화하고 효율성을 개선하는 역할을 한다. |
| **트리거(Trigger)**     | 특정 이벤트(예: 테이블에 대한 INSERT, UPDATE, DELETE 연산)가 발생할 때 자동으로 실행되는 함수이다.<br>데이터의 무결성을 유지하거나, 특정 조건에 따라 자동으로 작업을 수행하는 데 사용된다. |

#### 테이블 스페이스(Tablespace)

테이블 스페이스는 오브젝트가 파일 형태로 저장되는 위치를 나타내며 데이터 저장 공간을 관리할 목적으로 사용.

빈번하게 사용되는 오브젝트들은 SSD에, 사용이 적으면 디스크 영역에 테이블 스페이스를 구성하여 관리하기도 가능하다.

![image-20250301213625931](./images//image-20250301213625931.png)

* pg_default : 모든 DB에서 사용되는 기본 테이블 스페이스를 의미.  -> $PGDATA/base에 저장 
* pg_global : 클러스터레벨에서 관리되는 테이블들을 저장함.  -> $PGDATA/global에 저장 

#### 릴레이션(Relation)

테이블이나 인덱스와 같이 데이터를 포함하는 데이터베이스 개체. PG는 모든 개체를 릴레이션이라고 함

#### Page

페이지란 디스크 I/O가 발생하는 최소 단위이며, 고정 길이의 데이터 블록.

기본 페이지 크기는 8KB이며 32Kb까지 정의 가능. 

모든 테이블과 인덱스는 **페이지 배열**로 이뤄져 있으며, 각 페이지는 헤더 영역과 데이터 영역으로 나눠진다.

#### 튜플(튜플)

테이블의 행이 물리적으로 저장된 형태.

튜플의 헤더에는 트랜잭션 Id, Visible Map등 다양한 메타데이터가 존재한다.

MVCC 적용에 따라 Live 튜플과 데드 튜플이 존재할 수 있다. 라이브 튜플은 데이터 처리시 현재 버전의 튜플을 의미하며 데드 튜플은 DML에 의해 변경된 이전 버전의 튜플을 의미한다.

데드 튜플은 참조하는 트랜잭션이 없으면 지워져야 할 이미지 의미하므로 Vaccum에 의해 제거할 수 있다.



### 3.2 물리 구조 (Physical Strcture)

디렉토리와 파일과 포크로 구성되어 있다. 

### 디렉토리 구조

<img src="./images//image-20250301214008423.png" width = 650>

크게 데이터 디렉토리, 로그 디렉토리, 환겴정 디렉토리, 기타 영역으로 나눌 수 있다.

#### 데이터 디렉토리

실제 사용자 데이터가 저장되는 공간. Global, Base, pg_tblspc 디렉토리로 구분

* Global 디렉토리 : 클러스터에 속한 데이터베이스들의 공유 정보가 저장된다. 아래 파일들이 존재
  * pg_internal.init, pg_filenode.map : DB내에 존재하는 오브젝트의 속성 정보, Data 파일과의 Mapping 정보 
* Base 디렉토리
  * DB 내의 테이블, 인덱스, 함수 등 오브젝트가 실제로 저장되는 공간이며, 저장 경로는 $PGDATA/base/{database_OID}/{objectId} 순으로 구성된다. 
* pg_tblspc 디렉토리
  * 사용자 정의 테이블 스페이스 정보를 저장하는 공간. 심볼릭 링크를 통해 연결 

#### 로그 디렉토리

* pg_wal
  * 장애 발생시 복구 역할을 수행하는 WAL 파일 을 저장하는 곳. 리플리케이션을 구현을 위해서도 사용
* Log : 데드락, 바큠 수행 결과 등 특이 사항들을 기록하는 공간

#### 환경설정 디렉토리

* pg_version
  * 데이터베이스 버전 정보 표시 
* pg_hba.conf : 인증시스템 관련 정보 및 데이터 전송방식, 암호화 전송방식 설정
* postgresql.conf : 환경설정 파일
* postmaster.pid postmaster : 프로세스의 pid, data path, 시작 시간 및 port 정보 저장

### 포크(Fork)

물리적 파일을 포크라고 하며, 데이터를 여러 포크로 분할하여 데이터 저장 및 검색의 다양한 츠겸ㄴ을 관리하고 최적화 한다.

![image-20250301214825672](./images//image-20250301214825672.png)

포크는 데이터 저장과 효율성을 높이기 위해 구분됌.

테이블 생성시 해당 테이블에 대해 3개의 파일이 존재한다.

* 메인 포크 : 주요 데이터가 저장되며 테이블 OID 명으로 파일 생성
* 여유 공간 맵 : 메인 포크 내의 여유 공간을 관리하기 위한 파일
* 가시성 맵: 메인 포크의 어느 페이지에 모든 활성 트랜잭션이볼 수 있는 튜플의 포함여부를 기록하는 파일 

#### OID (Object Identifier)

OID Types를 사용하여 내부에 존재하는 모든 오브젝트들을 구분하고 관리함.

객체가 생성될때마다 자동 부여, OID와 파일명이 동일하게 생성됌

#### 메인 포크

테이블이나 인덱스의 로우 같은 실제 데이터가 저장되는 파일 시스템.

초기에는 단일 파일이며 파일의 용량이 1GB까지 증가하면 해당 포크에 다른 파일이 생성된다.

이 파일을 세그먼트라고 하며, 세그먼트가 계속해서 증가하면 세그먼트에 시퀀스 번호가 할당된다.

1GB까지 파일에 제한을 두는것은 대용량 파일 처리시 발생할 수 있는 문제를 제거하기 위함이다.

테이블과 인덱스를 생성하게 되면, 메인 포크의 파일 이름은 OID 이며 pg_class 테이블에 존재하는 Relfilenode 컬럼값과 동일하다.

#### 여유 공간 맵 (Free Space Map)

데이터가 변경되면 처리되는 과정에서 데이터 페이지에 여유 공간이 생기게 된다.

이 여유공간 정보를 저장해서 새 데이터 테이블에 입력시, 기존 데이터 페이지에 적절한 크기의 여유 공간을 찾는 역할을 한다.

사용 목적

* 디스크 공간 낭비 줄이고, 데이터 페이지 공간 최적화
* 데이터 입력 시 기존 페이지 여유 공간을 빠르게 탐색

특정 로우에 인설트나 업데이트가 발생하면 데드 튜플이 생기고, 바큠이 진행되면 데드 튜플이 삭제되는데 이 공간은 여유 공간으로 FSM이 등록되게 되어, 새 데이터 입력시 FSM을 이용해 기존 페이지의 여유 공간에 데이터를 저장함. 

#### 가시성 맵 (Visibility Map, VM)

활성 트랜잭션들이 페이지 내의 모든 튜플의 가시성 여부를 추저하기 위해 사용된다.

가시성 맵을 통해 Vaccum 및 인덱스 스캔을 최적화 할 수 있다.

VM 파일은 relfilenode 값 뒤 _vm 이라는 형태로 관리되며, 각 테이블에 대해 별도로 존재한다.

두 개의 비트 값을 가진 비트맵 배열로 구성되어 있다. 튜플의 상태 정보를 축약해서 저장하고 있다.

2가지 비트를 사용하는 목적은 값에 따라서 Vaccum 작업에 대해 시간을 단축하고 불필요한 작업을 수행하지 않아 Vaccum 성능을 향상시키기 위함이다.

* 테이블에는 VM 파일이 존재하지만 인덱스에는 존재하지 않음
* 데이터 조회시 가장 먼저 테이블의 VM 정보 확인
* Vaccum이 필요 없는 페이지는 Skip 하여 바큠 작업 최소화

하나의 페이지에 2개의 비트 값을 별도로 가지고 있다

1. all_visible : 페이지의 Visible 상태를 비트 정보로 표시

   * 1일경우(true) : 모든 튜플이 트랜잭션에서 가시성이 보장되며 데드 튜플이 없는 상태.

   * 쿼리 수행 시 모든 페이지 VM 비트 정보가 al_visible = 1일 경우 가시성을 보장하여 테이블 스캔하지 않고, index only scan 만으로 조회 결과 반환 
   * 0인경우(false) : 모든 튜플 또는 일부 튜플에 Vaccum이 정리할 튜플이 있는 상태 -> 데드 튜플

2. all_frozen : 페이지의 모든 Frozen 상태를 비트 정보로 표시 (**Frozen(동결) 상태**는 **페이지 내의 모든 행(tuple)의 트랜잭션 ID(XID)가 더 이상 변경되지 않으며, 자동으로 유지보수되는 상태**)

   * PG는 MVCC를 이용하는데, 각 행에 트랜잭션 아이디(XID)를 두지만, 32비트 정수형이기 때문에 약 20억 개의 트랜잭션이 지나면 재사용 되어야 해서 이를 위해 Frozen 상태를 사용 
     * **Frozen 상태**는 특정 행(tuple)이 **더 이상 업데이트되거나 삭제되지 않으며, 트랜잭션 ID wraparound(오버플로우) 방지를 위해 xmin 값을 "특수한 FrozenXID"로 설정한 상태**

   * 1일경우 (true) : all_visible = 1 인경우에만 해당하며, 페이지의 모든 튜플이 Fronzen XID가 해당된 상태
   * 0인경우(false) : 모든 튜플이나 일부 튜플이 Frozen XID가 적용되지 않은 상태
   * all_frozen = 1인 페이지는 all_visible = 1인 상태이며 Vaccum eㅐ상에서 제외

**Frozen 상태 확인 방법**

### 📌 **pg_visibility 모듈을 사용한 Frozen 상태 확인**

```
SELECT * FROM pg_visibility;
```

### 📌 **pg_stat_all_tables을 통해 Frozen 상태 확인**

```
SELECT relname, relfrozenxid, age(relfrozenxid)
FROM pg_class c
JOIN pg_stat_all_tables s ON c.oid = s.relid
WHERE s.schemaname = 'public';
```

- `relfrozenxid`: 테이블의 가장 오래된 frozen XID
- `age(relfrozenxid)`: 현재 트랜잭션 ID와 비교하여 얼마나 오래된 frozen 상태인지 나타냄

VM 정보 비트는 Vacuum 수행 및 데이터 변경에 따라 상태 값이 변경된다.

*  테이블을 생성 후 데이터가 입력되면 VM 상태 값은(0, 0)이다.

*  Vacuum 수행 시 VM 상태 값은(1, 0) 또는(1, 1)이다.

*  Vacuum Freeze 옵션으로 수행하면 VM 상태 값은 항상(1, 1)이다.

*  Delete나 Update가 수행되면 VM 상태 값은 항상(0, 0)이다. -> 데드 튜플 

## 4. Shared Buffer

데이터 페이지를 메모리에 캐싱해 디스크 IO를 최소화하여 DB 성능을 향상시키기 위해 존재하는 메모리 영역.

### 4.1 Shared Buffer 구성 요소

Shared Buffer의 가장 큰 목적은 디스크 IO를 최소화해 데이터에 더 빠르게 접근하는것.

데이터가 Shared Buffer에 존재하지 않으면 디스크에서 필요한 데이터를 버퍼로 읽어 처리한다.

* 캐싱된다.

![image-20250302001254922](./images//image-20250302001254922.png)

해시 함수, 해시 테이블, 버퍼 디스크립터, 버퍼 풀 네 가지 구성 요소로 이루어짐

* 해시 함수
  * Backend 프로세스(커넥션)에서 요청한 데이터, 즉 버퍼 태그는 해시 함수를 통해 해시 테이블에 접근한다. 
  * 버퍼 태그 : 해시 키, 결괏값 : 해시 벨류
* 해시 테이블 : 커넥션이 요청한 데이터 페이지가 메모리 어디 존재하는지 빠르게 찾음,
  * 원하는 페이지가 메모리에 없다면, 디스크로부터 읽어 테이블과 페이지를 매핑해 캐시
* 버퍼 디스크립터 : 데이터 페이지에 대한 메타 정보를 저장하고 관리함. 
  * 버퍼의 현재 상태를 추적하여 데이터 페이지가 디스크와 동기화 여부 결정
* 버퍼 풀 : 데이터가 실제 저장되는 공간 . 디스크 데이터를 버퍼 풀 영역에서 저장하고 관리
  * 대부분은 버퍼 풀이 차지하고 있따. 자주 사용되는 데이터 페이지는 오래 상주, 자주 사용 안되면 교체하여 효율적으로 사용

#### 해시 테이블

![image-20250302001956281](./images//image-20250302001956281.png)

해시 함수를 이용해 빠르게 검색하기 위해 설계뙘.

Shared Buffer는 모든 프로세스가 공용으로 사용하는 리소스. 때문에 데이터 정합성에 문제가 발생할 수 있음.

* 동시에 동일한 데이터(예: WAL 로그, 인덱스 페이지, 버퍼 캐시 등)

그래서 LW(Light Weight)락에 의해 보호됌.

Backend 프로세스는 공용 리소스를 사용하기 위해 반드시 LW 락을 획득! 해야함. 

* LW락 : 경량 락.
  * **LWLock은 Deadlock이 발생하지 않도록 설계됨**.
    → **락을 획득하지 못하면 바로 포기하고 대기(Spinlock) 또는 재시도(Retry) 방식 사용.**
  * **Spinlock을 사용하여 빠르게 락 상태를 확인**하고, 가능한 경우 즉시 획득(소스코드에) 

> 파티션(n) > 세그먼트(1) > 테이블(1) > 엘리먼트(n) 

그림을 보면, Shared buffer의 효율성을 높이기 위해 테이블을 여러 개의 버퍼 파티션으로 구성하였다.

* LW 락 하나가, 해시 테이블 전체를 관리하면 동시에 접근시 당연히 대기하게 된다.
* 때문에 각 파티션마다 LW 락을 할당해 대기 시간을 줄임.
* 기본값은 128. NUM_BUFFER_PARTITIONS 파라미터 값으로 정의되어 있음.

* 해시 테이블을 여러 파티션으로 분리해서 사용하면 프로세스 사이에서 경합을 줄여 줄 뿐만 아니라 메모리와 CPU도 효율적으로 사용 가능.

버퍼 파티션은 다시 여러 해시 세그먼트로 나눠진다.

* 해시 세그먼트는 해시 테이블의 데이터를 여러 세그먼트로 나눠 저장하고, **각 세그먼트는 독립적으로 해시 테이블을 관리함 .**
* 해시 세그먼트는 해시 버킷과 연결되어 있음.
* DEF_SEGSIZE 파라미터 설정. 기본값 256

해시 테이블의 구성은 버킷, 배열이다. **해시 충돌이 발생할 수 있으므로 체이닝 방식으로 구현되어 있다.** 

해시 충돌이 발생할수록 탐색 속도는 저하되므로, 하나의 큰 세그먼트 대신 여러 논리 세그먼트로, 또 여러 세그먼트마다 해시 테이블을 두어서 충돌을 완화 시킨다.

해시 세그먼트에 대한 장점을 정리하면 다음과 같다.

- ﻿﻿데이터를 분할 관리하여 해시 충돌을 줄일 수 있다. 따라서 데이터 검색 성능이 향상될 수 있다.
- ﻿﻿각 독립적으로 데이터를 관리하여 페이지 교체 알고리즘의 효율성을 높여 전체 시스템의 성능 을 향상시킬 수 있다.
- ﻿﻿메모리를 독립적으로 사용할 수 있어 불필요한 메모리 낭비를 줄일 수 있다.

##### 해시 엘리먼트

해시 엘리먼트를 해시 엔트리라고도 하는데 해시 테이블에서 키를 식별하고 매핑 된 값을 저장한다.

해시 테이블의 버킷은 여러 개의 해시 엘리먼트를 저장할 수 있다.

![image-20250302012459423](./images//image-20250302012459423.png)

해시 엘리먼트는 데이터베이스 시 작 시점에 일정 개수만큼만 할당되었다가 요청이 발생하면 그 때 다시 할당된다.

해시 엘리먼트의 구성 요소는 Hash Value, 버퍼 태그(Buffer Tag)와 버퍼 ID(Buffer ID)로 구성된다

* Hash Value : 해시 함수에 의해 생성된 결괏값. 해시 테이블에서 고유한 식별값
* 버퍼 Id : 버퍼 풀에서 특정 버퍼 식별 인덱스. 데이터 페이지가 존재하는 배열의 위치
* 버퍼 태그 : 클러스터 데이터베이스에서 Shared Buffer에 캐시된 데이터 페이지를 식별할 수 있는 정보. 이 정보로 파일이나 튜플의 위치를 알 수 있다.

#### 버퍼 태그를 이용한 해시 테이블 검색 

![image-20250302171242135](./images//image-20250302171242135.png)

* 1의 버퍼 태그는 (1228, 12438, 16636), 0, 0 ) 이것의 해시 함수의 키값.
  * 테이블 스페이스 OID : 1228
  * DB OID : 12438
  * 테이블 OID : 16636
  * 4번째는 포크의 유형, 0은 메인 포크.
    * 4번째 포크 유형중 1번은 fsm 파일이고, 2는 VM 파일을 의미.  
  * 5번째는 데이터 파일에서 페이지 위치
* 해시 값이 12533467으로 계싼되고, 해당 해시 버킷을 찾는다. 
* 해시버킷 12533467에 연결된 해시 엘리먼트의 buffer_id는 0이며, 버퍼 풀의 위치가 0번째 배열에 존재한단 의미 -> 버퍼에 있단뜻

Backend 프로세스에 의해 버퍼 태그가 생성되는 절차에 대해 요약하면 다음과 같다.

1. ﻿﻿﻿Backend 프로세스가 쿼리를 수행한다.
2. ﻿﻿﻿쿼리가 수행 중 특정 데이터 페이지에 접근 요청을 한다.
3. ﻿﻿﻿요청에 의해 데이터 페이지에 대한 버퍼 태그를 생성한다.
4. ﻿﻿﻿버퍼 태그를 이용해 Shared Bufer에서 데이터 페이지를 찾거나 존재하지 않으면 디스크로부 터 로드한다.

데이터 입력시

* Backend에서 insert 쿼리 수행.
* 버퍼 태그 생성 후 해시 함수를 수행해서 해시값을 얻음
* 해시 값을 해시 테이블의 특정 버킷에 매핑
* 버킷에 해당하는 페이지에 해시값, 버퍼태그, 버퍼풀 ID 엘리먼트를 저장
  * 해시 충돌 발생한 경우, 동일 버킷 내에서 체이닝
* 버퍼 풀 id 7에 데이터 페이지를 로드 후 데이터를 입력. 

데이터 검색시

* Backend에서 select 쿼리 수행
* 요청 쿼리의 버퍼 태그 생성 후 해시 함수를 수행해 해시 값을 얻음
* 해시 값으로 해시 테이블의 버킷을 찾음
* 버킷에서 데이터를 검색해 해시값에 해당하는 해시 엘리먼트를 찾음
* 엘리먼트에 저장된 메타 정보를 이용해 버퍼 풀에서 해당 데이터를 읽음.
* 요청한 데이터를 backend 프로세스에 전달

### 4.1.3 버퍼 디스크립터.

버퍼 디스크립터는 메모리에서 사용하는 데이터 페이지에 대한 상태, 참조 카운트, 락 정보 등을 저장하고 관리한다.

구성요소 

* buffer id : 버퍼가 저장된 버퍼 풀 배열에 해당하는 위치
* status flag : 페이지가 사용되고 있는 상태를 나타내는 플러그
* reference count : 페이지가 참조되고 있는 프로세스의 수. 이 수치로 페이지 교체 대상을 결정하는데 사용

버퍼 디스크립터의 상태

* empty : 버퍼 풀 슬롯에 페이지가 없는 상태
  * 버퍼와 프로세스가 사용하지 않은 상태. usage_count =0  & RefCount = 0
* Pinned : 버퍼 풀 슬롯 페이지가 존재하고 프로세스가 페이지를 사용중인 상태
  * 페이지 n번사용, M개의 프로세스가 현재 사용중 : RefCount >= 1 & usage_count >= 1
* Unpiined : 버퍼풀 슬롯에 페이지가 존재하지 프로세스가 사용하지 않는 상태
  * usage_count >= 1 & Refcount = 0

usage_count와 refcount는 페이지 교체 알고리즘에서 사용된다.

### 4.1.3 버퍼 풀 (buffer pool)

버퍼 풀은 실제 데이터 페이지가 저장되는 장소이며 디스크 I/O를 줄여 성능 향상 시키는것이 목적.

![image-20250302172107499](./images//image-20250302172107499.png)

버퍼 풀은 테이블 이나 인덱스 같은 데이터 페이지를 저장하기 위한 배열로 구성되어 있다.

이러한 배열의 인덱스를 buffer_id라고 함

![image-20250302172143965](./images//image-20250302172143965.png)

버퍼의 크기는 데이터 페이지 크기와 동일하며 기본값은 8kb

* 테이블, 인덱스 등 데이터 파일 페이지와 FSM, VM에 대한 정보도 저장됌 

버퍼의 헤더에는 페이지의 상태정보와 메타정보가 있음

![image-20250302173219799](./images//image-20250302173219799.png)

pg_buffercache 익스텐션 이용시, Shared Buffer가 어떻게 사용되고 있는지 살펴볼 수 있다.

```sql
create extension pg_buffercache ;

select * from pg_buffercache
```

| 컬럼명             | 설명                                                         |
| ------------------ | ------------------------------------------------------------ |
| `bufferid`         | 버퍼의 고유 ID                                               |
| `relfilenode`      | 테이블 또는 인덱스가 저장된 파일의 ID                        |
| `reltablespace`    | 해당 테이블이 속한 테이블스페이스 ID                         |
| `reldatabase`      | 해당 데이터가 속한 데이터베이스 ID                           |
| `relforknumber`    | 해당 블록이 **메인 테이블(0), FSM(1), VM(2)** 중 어디에 속하는지 |
| `relblocknumber`   | 테이블 내 블록 번호                                          |
| `isdirty`          | 해당 페이지가 변경되었지만 아직 디스크에 기록되지 않았는지 여부 (`t`: 변경됨, `f`: 변경 안 됨) |
| `usagecount`       | LRU(Least Recently Used) 캐시 정책에서 사용된 횟수           |
| `pinning_backends` | 현재 해당 블록을 참조 중인 백엔드 프로세스 수                |

캐시된 특정 테이블의 버퍼 확인

특정 테이블이 얼마나 버퍼에 캐싱되었는지 확인하려면 **`pg_class`와 조인**하여 확인할 수 있습니다.

```sql
SELECT c.relname, count(*) AS buffers, sum(case when b.isdirty then 1 else 0 end) AS dirty_buffers
FROM pg_buffercache b
JOIN pg_class c ON b.relfilenode = pg_relation_filenode(c.oid)
WHERE c.relname = 'my_table'
GROUP BY c.relname;
```

| relname  | buffers | dirty_buffers |
| -------- | ------- | ------------- |
| my_table | 150     | 20            |

- **buffers**: 현재 **버퍼 풀에 캐싱된 블록 개수**
- **dirty_buffers**: 아직 **디스크에 기록되지 않은 변경된 블록 개수**

 전체 캐시된 데이터베이스 상태 확인

버퍼 풀 전체에서 어떤 테이블이 가장 많이 캐싱되고 있는지 확인할 수 있습니다.

```sql
SELECT c.relname, count(*) AS buffers, round(100 * count(*) / (SELECT count(*) FROM pg_buffercache), 2) AS percentage
FROM pg_buffercache b
JOIN pg_class c ON b.relfilenode = pg_relation_filenode(c.oid)
GROUP BY c.relname
ORDER BY buffers DESC
LIMIT 10;
```

### **결과 예시**

| relname      | buffers | percentage |
| ------------ | ------- | ---------- |
| orders       | 500     | 35.71%     |
| customers    | 300     | 21.43%     |
| transactions | 200     | 14.29%     |

- **orders 테이블이 35.71%를 차지**, 즉 **이 테이블이 가장 많이 캐싱됨**.

특정 데이터베이스 캐시 점유율 확인

현재 데이터베이스가 버퍼 풀에서 차지하는 비율을 확인할 수 있습니다.

```sql
SELECT d.datname, count(*) AS buffers, round(100 * count(*) / (SELECT count(*) FROM pg_buffercache), 2) AS percentage
FROM pg_buffercache b
JOIN pg_database d ON b.reldatabase = d.oid
GROUP BY d.datname
ORDER BY buffers DESC;
```

### **결과 예시**

| datname | buffers | percentage |
| ------- | ------- | ---------- |
| mydb    | 1000    | 78.9%      |
| testdb  | 200     | 15.8%      |

- 현재 **mydb가 78.9%를 차지**, 즉 **이 데이터베이스가 가장 많이 캐싱됨**.

Dirty Page 확인 (디스크에 기록되지 않은 데이터)

```sql
SELECT count(*) AS dirty_pages
FROM pg_buffercache
WHERE isdirty = true;
```

- PostgreSQL에서 아직 **디스크에 기록되지 않은(Dirty) 페이지 개수**를 확인할 수 있음.
- `CHECKPOINT`을 실행하면 해당 페이지들이 디스크에 저장됨.

```sql
CHECKPOINT;
```

현재 **버퍼 풀 전체 크기**와 **사용 중인 크기**를 확인할 수 있습니다.

```sql
SELECT count(*) AS total_buffers,
       sum(case when isdirty then 1 else 0 end) AS dirty_buffers,
       sum(case when pinning_backends > 0 then 1 else 0 end) AS pinned_buffers
FROM pg_buffercache;
```

### **결과 예시**

| total_buffers | dirty_buffers | pinned_buffers |
| ------------- | ------------- | -------------- |
| 8192          | 500           | 10             |

- `total_buffers`: 전체 버퍼 개수
- `dirty_buffers`: 아직 디스크에 기록되지 않은 페이지 개수
- `pinned_buffers`: 현재 참조 중인 버퍼 개수

## 4.2 Shared Buffer에서 데이터 읽기

backend(커넥션) 프로세스가 데이터 요청시 데이터 페이지를 읽는 과정 3가지 케이스

- ﻿﻿버퍼 풀에서 요청한 페이지를 읽기
- ﻿﻿버퍼 풀에서 요청한 페이지가 존재하지 않는 경우
- ﻿﻿버퍼 풀에서 데이터 페이지를 교체한 후 읽기

### 버퍼 풀에서 요청한 페이지 읽기

Backend 프로세스에서 데이터를 요청하면 메모리에서 데이터를 찾은 후 데이터를 반환한다.

(데이터 요청 > 메모리에 데이터 존재 페이지 읽기)

![image-20250302174212000](./images//image-20250302174212000.png)

1. Backend 프로세스에서 데이터를 요청하기 위해 버퍼 태그를 생성한다.

   - ﻿﻿이 때 버퍼 태그는 Tag_A라고 가정한다.

   - ﻿﻿Tag_A를 해시 함수를 이용해서 해시 버킷 슬롯을 계산한다.

   - ﻿﻿계산된 해시값은 5436이다.

2. 해당 버퍼 파티션에 공유 모드의 BufMappingLock를 획득한다.

3. ﻿﻿﻿해시 테이블에서 버킷 슬롯을 검색한 후 엘리먼트를 통해 버퍼 디스크립터 배열 인덱스를 찾는다.
   *  Buffer Jd= 2이므로 디스크립터의 배열은 2가 된다.

4. 해당 디스크립터의 배열에 PIN을 고정한다.
   *  Refcount(핀의 수)와 usage_count(사용 횟수) 숫자를 1씩 증가한다.

![image-20250302174351955](./images//image-20250302174351955.png)

5. ﻿﻿﻿BufMappingLock을 해제한다.

6. ﻿﻿﻿버퍼 디스크립터 배열에 content_lock을 획득한다.

7. ﻿﻿﻿버퍼 풀에서 페이지를 읽는다.

8. ﻿﻿﻿버퍼 디스크립터 배열에 content_ock과 PIN을 해제한다.
   *  Refcount 값을 1씩 감소

### 버퍼 풀에서 요청한 페이지가 존재하지 않는 경우

Backend 프로세스에서 요청한 페이지가 메모리에 존재하지 않아 빈 페이지를 할당 받은 후 페이지

를 읽고 데이터를 반환한다.

(데이터 요청 메모리에 요청한 데이터 존재하지 않음 〉 빈 페이지에 페이지 로딩 》 페이지 읽기)

![image-20250302174443583](./images//image-20250302174443583.png)

1. Backend 프로세스에서 데이터를 요청하기 위해 버퍼 태그를 생성한다.

   - ﻿﻿이 때 버퍼 태그는 Tag_F라고 가정한다.

   - ﻿﻿Tag_F를 해시 함수를 이용해서 해시 버킷 슬롯을 계산한다.

   - ﻿﻿먼저 해당 버퍼 파티션에 공유 모드로 BufMappingLock을 획득한다.

   - ﻿﻿버킷에 매핑 되는 해시값이 존재하지 않는 것을 확인하고 즉시 BufMappingLock을 해제한다.

2. Free List를 탐색해 빈 버퍼 디스크립터 중 첫 번째 배열에 해당하는 버퍼에 PIN을 고정한다.
   * Refcount 값이 1 증가한다.

3. 해당 버퍼 파티션에 배타 잠금 모드로 BufMappingLock 락을 획득한다.

4. ﻿﻿﻿해시 엘리먼트 풀에서 새로운 엘리먼트를 할당 받고 새 데이터 항목을 생성한 후 저장한다.
   *  해시 엘리먼트의 Buffer_Id와 버퍼 디스크립터의 배열 인덱스 [5]로 매핑 된다.

5. 해당 버퍼 디스크립터 배열에 락을 설정 후 플래그 비트를 설정한다.

   - ﻿﻿버퍼 디스크립터 [5]에서 락을 설정한다.

   - ﻿﻿다른 프로세스들의 접근을 방지하기 bm_jo_in_progress 플래그 비트를 1로 설정한다.

   - ﻿﻿버퍼 디스크립터 배열에 락을 해제한다.

![image-20250302174814255](./images//image-20250302174814255.png)

6. ﻿﻿﻿디스크에서 원하는 페이지를 버퍼 풀 슬롯에 로드한다.

7. ﻿﻿﻿해당 버퍼 디스크립터 배열에 락 해제 후 플래그 비트를 설정한다.

   - ﻿﻿버퍼 디스크립터 배열 인덱스 [5]에 락을 설정한다.

   - ﻿﻿bm_io_in_progress 플래그 비트를 0로 설정한다.

   - ﻿﻿버퍼 디스크립터 배열 인덱스 [5]에 락을 해제한다.

8. ﻿﻿﻿버퍼 파티션에 BufMappingLock을 해제한다.

9. ﻿﻿﻿버퍼 풀 배열에서 데이터를 읽는다.

   - ﻿﻿PIN을 해제한다.

   - ﻿﻿refcount 값이 1 감소된다.

#### 버퍼 풀에서 데이터 페이지 교체 후 읽기 

버퍼 풀이 가득 찬 경우, 페이지 교체 대상을 선택한 후 디스크에 기록하고 요청한 데이터 페이지를 로드해야 한다

(데이터 요청 요청한 페이지가 존재하지 않음〉 할당될 빈 페이지가 없음 > Clock Sweep 알고리 즘 수행 > 빈 페이지에 페이지 로딩 〉 페이지 읽기)

![image-20250302175424539](./images//image-20250302175424539.png)

### 4.3 Clock Sweep

### 4.3.1 Clock Sweep 알고리즘.

pg는 효율적 메모리 사용을 위해 Clock Sweep 알고리즘을 사용하고 있다.

Clock Sweep 알고리즘은 DB에서 메모리에 상주해 있는 버퍼 중에서 자주 사용되지 않는 페이지를 효율적으로 선정하는 것.

교체 대상 페이지는 교체 발생 전 디스크에 기록 되어야 하며 교체 대상으로 선정되어 디스크로 기록되는 버퍼를 **Victim** 버퍼라고 한다.

* Victim: 교체대상이 됌 

```
Clock-Sweep Algorithm

WHILE true:
    (1) 현재 nextVictimBuffer가 가리키는 버퍼 후보를 가져온다.
    
    (2) 만약 해당 버퍼가 'unpinned' 상태라면: 
        (3) usage_count 값을 확인한다.
        
        (3.1) 만약 usage_count = 0이라면:
            - 이 버퍼는 교체(victim) 후보가 될 수 있다.
            - WHILE 루프를 종료한다. (교체할 버퍼를 찾았음)
        
        (3.2) 그렇지 않다면 (usage_count > 0):
            - usage_count 값을 1 감소시킨다. (버퍼를 사용할 가능성이 줄어들었음을 반영)
    
    (4) nextVictimBuffer를 다음 버퍼로 이동시킨다. (시계 방향으로 진행)

END WHILE

(5) 찾아낸 victim 버퍼의 ID를 반환한다.
```

* Clock-Sweep 알고리즘은 **LRU (Least Recently Used) 알고리즘을 근사적으로 구현**하는 방식
* **시계바늘(clock hand)처럼 원형으로 버퍼를 순회하면서 교체할 버퍼를 찾는 방식**이기 때문에 "Clock" 알고리즘

### 4.3.2 Clock Sweep 알고리즘 동작 방식

![image-20250302180834697](./images//image-20250302180834697.png)

* P는 Pin Count, U는 Usage Count

1. ﻿﻿﻿버퍼의 사용횟수(U)가 0이 아니고 핀(P) 상태이면 Victim 대상에서 제외
2. ﻿﻿﻿버퍼의 사용 횟수(U)가 0이 아니고 핀(P) 상태가 아니면 사용 횟수 -1
3. ﻿﻿﻿버퍼의 사용 횟수(U)가 0이고 핀(P) 상태가 아니라면 Victim 대상으로 선정

만약 버퍼를 아주 짧은 시간 동안만 과다하게 사양 한 후 오랜시간동안 사용하지 않는다면 이 버퍼는 Victim 버퍼로 선정되지 않을 수 있음.

이 문제를 해결하기 위해 메모리에 존재하는 버퍼를 아무리 과하게 써도 Usage Count 값은 BM_MAX_USAGE_COUNT 파라미터의 값까지만 증가하며 기본값은 5

또한 슬롯 버퍼를 6번 순회하는동안 한 번도 사용되지 않은 버퍼는 사용횟수가 0으로 변경

### 4.4  Postgresql IO 전략

### 대량 데이터 처리를 위한 IO 전략

일시적인 배치 작업으로 대량 데이터를 처리해야 한다면 Shared buffer는 대부분 일회성 배치 데이터들로 채워짐.

또한 제거된 페이지들이 다시 캐싱 되려면 한번에 다량의 IO가 발생하여 쿼리 성능에 문제 발생 가능.

Vacuum 또는 대규모 Sea Scan처럼 많은 데이터 페이지를 일회성으로 읽어 처리하는 경우 링 버퍼 (Ring Buffer)를 사용한다. 링 버퍼는 Shared Buffer 내에 존재하는 임시 버퍼 영역이며 일정 크기의 배열을 순환 방식으로 사용한다.

메모리 할당 로직

```
switch (btype) {
    case BAS_NORMAL:
        return NULL;

    case BAS_BULKREAD:
    case BAS_VACUUM:
        ring_size = (256 * 1024) / BLCKSZ;
        break;

    case BAS_BULKWRITE:
        ring_size = (16 * 1024 * 1024) / BLCKSZ;
        break;

    default:
        return NULL;
}
```

NORMAL은 링 버퍼를 사용하지 않을 경우고, 나머지는 용도에 따라 달라진다.

NORMAL을 제외한 아래 3가지 중 한가지라도 해당하면 링 버퍼를 사용한다

* 대량 읽기(Bulk Reads) : 링 버퍼를 사용하려면 Shared Buffer의 1/4 이상인 테이블에 대해 Seq Scan이 수행될때 사용된다.
  * 읽기는 변경이 발생하지 않아 버퍼를 교체하기 위해 Dirty 페이지를 디스크에 기록하지 않아도 된다.
  * 256kb(32페이지)의 크기
* 대량 쓰기(Bulk Writer) : 메모리 데이터를 계속해서 디스크에 기록해야 하므로 가능한 크게 할당된다.
  * Copy Table, Create Table As Select, Create Materialized View 등 
  * 16MB(2048 페이지 )
* Vacumming : Vaccum 프로세스에 의해 수행되며 테이블 전체 스캔 발생.
  * 대량 읽기와 같이 256kb 할당

### pg_prewarm 사용하기

디비 재기동시, 기존 사용하던 버퍼들은 메모리에서 모두 제거됌. Shared buffer가 다 채워지기 전까지 쿼리 성능 저하됨

그래서 재시작 전 환경으로 버퍼 풀을 설정 가능

* 함수를 이용한 수동 캐싱
* DB 환경 설정을 이용한 수동 캐싱



함수를 이용한 수동 캐싱

```
create extension pg_prewarm;

pg_ctl restart

select pg_prewarm('public.tb_warm') // 캐싱 
```

DB 환경 설정을 이용한 수동 캐싱

postgresql.conf 파일 환경 서렁

```
Shared_preload_libraries = 'pg_prewarm'
pg_prewarm.autoprewarm = true
pg_prewarm.autoprewarm_interval = 300s
```

* autoprewarm_interval : 기본값 300초, 값이 0이되면 db 종료시 1회만 변경됌

명령어로 미리 파일을 만든다

```
-- 명령어로 파일 생성 
select autoprewarm_dump_now()

cat autoprewarm.blocks

-- 이후 재시작
pg_ctl restart

-- tb_warn 캐시 확인
select count(*) from pg_buffercache where relfilenode = pg_relation_filenode('tb_warm'::regclass);;
```

## 5. WAL (Write-Ahead Log )

데이터 무결성을 위해 먼저 로그에 기입하는 방식인 WAL을 사용한다.

데이터가 변경되면 SharedBuffer에서 데이터가 변경되며, 동시에 WAL 버퍼에 변경된 데이터들에 대한 로그가 기록된다. 메모리에서 변경이 완료되면 WAL 세그먼트에 기록한 후 데이터 파일에 최종 저장된다. 

만약 장애로 데이터 파일에 저장하지 못했다면 데이터 복구가 가능하다.

트랜잭션 세션들은 WAL 세그먼트 파일에 기록 시, 내용을 읽어서 수정하지 않고 단순 Append 형태로 기록한다.

때문에 IO 비용이 적다. 

* 하지만 Unlogged 테이블이나 Temporary 테이블을 사용하는 트랜잭션 작업은 WAL 세그먼트 파일 에 데이터 변경에 대한 로그를 기록하지 않는다.

PostgreSQL에서 WAL을 사용하는 이유는 다음과 같다.

- ﻿﻿트랜잭션이 Commit 될 때마다 변경된 데이터들을 데이터 파일에 기록할 필요가 없다.
- ﻿﻿트랜잭션 취소 시 디스크에서 수행하지 않고 WAL에서 실행 취소가 가능하다.
- ﻿﻿WAL에 쓰기 작업은 데이터를 읽어 변경하지 않고 Append 형태로 순차 작성하기 때문에 쓰기비용이 적다
- 온라인 백업이 가능하다

### 5.1 WAL 세그먼트 파일

세그먼트 파일은 트랜잭션에 대한 변경 사항을 기록한다. 

![image-20250302184337540](./images//image-20250302184337540.png)

* WAL 파일명에 대한 규칙
* 앞자리 8자리는 타임라인이며, 특정 시점으로 복구하기 위한 시간을 나타내는 ID. 부호없는 4바이트
* 다음 8자리는 logId이며, 논리 개념의 트랜잭션 로그 시퀀스 넘버. (LSN)
* 마지막 8자리는 세그먼트 ID이며 물리 개념의 로그 시퀀스 넘버. 

처음 세그먼트 파일의 정해진 크기 모두 사용하면, 다음 두번째 세그먼트 파일이 생성됌.

파일 이름에 사용되는 숫자는 16진수로 0~9, A~F로 표현

Pg_ls_waldir 조회하기

```sql
select * from pg_ls_waldir() order by modification desc limit 5;

000000010000001100000060,16777216,2025-03-02 08:41:45.000000 +00:00
00000001000000110000005F,16777216,2025-02-21 14:50:34.000000 +00:00
00000001000000110000005E,16777216,2025-02-21 14:50:32.000000 +00:00
00000001000000110000005D,16777216,2025-02-21 14:50:29.000000 +00:00
00000001000000110000005C,16777216,2025-02-21 14:50:26.000000 +00:00
```

한 WAL 세그먼트 파일 크기는 16MB이며, wal-segsize initdb 옵션에서 크기 변경 가능.

각 WAL 레코드에는 고유한 LSM이 할당된다. 이  LSN을 통해 WAL 세그먼트 파일 내에서 레코드의 위치를 식별할 수 있으며, 트랜잭션이 발생한 순서대로 증가한다. 

* 따라서 각  WAL 레코드는 LSN 순서대로 나열되어 있따.

저장 위치

```
root@761b43114ddf:/var/lib/postgresql/data/pg_wal# pwd
/var/lib/postgresql/data/pg_wal
```

*  **WAL 파일은 개별 테이블마다 생성되지 않고, 데이터베이스 전체에서 단일 WAL 로그 파일 세트로 관리됩니다.**
  즉, **PostgreSQL 인스턴스 전체에서 변경 사항을 기록하는 중앙 로그 시스템**

WAL 레코드는 헤더, 데이터 파트로 구분되어 있다.

* 헤더 : LSN, 레코드 크기,트랜잭션 ID
* 데이터 파트 : 실제 변경된 데이터와 페이지 ID, 오프셋

![image-20250302185011883](./images//image-20250302185011883.png)

WAL **페이지 구성 요소**는 다음과 같다.

- ﻿﻿Page Header : 각 페이지의 메타데이터를 저장한다. 여기에는 페이지 번호, 페이지 크기, 타임 라인 ID, 체크섬, 페이지의 시작 위치를 나타내는 LSN 등이 포함된다.
  - ﻿﻿Magic Number: WAL 파일 형식을 식별한다.
  - ﻿﻿Page Size 및 Version : 페이지의 크기 및 버전 정보를 저장한다.
  - ﻿﻿Log Sequence Number(LSN): 이 페이지의 위치를 나타낸다.
  - ﻿﻿Page Number : 파일 내에서 페이지의 위치를 나타낸다.
  - ﻿﻿Previous Page Pointer : 이전 페이지의 번호를 가리키는 포인터이다.
  - ﻿﻿Timeline ID: 페이지가 속한 타임라인을 나타낸다.
  - ﻿﻿CRC32 Checksum: 페이지 무결성을 확인하기 위한 체크섬
- ﻿﻿XLog Record : 실제 트랜잭션 데이터가 저장되는 영역이다.

- ﻿﻿Page Trailer : 페이지의 마지막 부분에 대한 정보를 저장한다.

WAL 레코드의 구성요소는 다음과 같다.

- ﻿﻿레코드 헤더 : 각 트랜잭션 레코드의 메타 데이터를 저장한다.
  - ﻿﻿XLogRecptr : 레코드의 시작 위치를 가리키는 LSN 정보를 저장한다.
  - ﻿﻿XLog record Type: 레코드의 유형 정보(삭제, 변경, 입력 등)를 저장한다.
  - ﻿﻿XLog record Length: 레코드의 길이에 대한 정보이며 레코드의 끝을 식별하는 데 사용된다.
  - ﻿﻿Checkpoint Information : 레코드의 복구 시점을 기록한다.
  - ﻿﻿Previous LSN: 이전 레코드의 위치를 나타내는 LNS 정보를 저장한다.
  - ﻿﻿Record Version : 레코드의 형식이나 구조의 버전을 나타낸다.
- ﻿﻿XLog data: 실제 트랜잭션 데이터.
- ﻿﻿CRC checksum: 데이터 손상을 감지하는 체크섬(CRC) 정보를 저장한다.

트랜잭션 시작시, 시작 지점에 LSN에 먼저 저장, 이후 데이터가 변경되면 변경된 내용들이 고유한 LSN과 함께 WAL 레코드에 기록. 데이터 변경이 완료되고 커밋이 수행되면 커밋 레코드가 생성되고 커밋 LSN도 WAL에 저장

