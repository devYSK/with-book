# 가상면접 사례로 배우는 대규모시스템 설계 2

[toc]

* https://github.com/alex-xu-system/bytebytego



# 1장 근접성 서비스

기능 요구사항

* 사용자의 위치 (경도와 위도 쌍)와 검색 반경 정보에 매치되는 사업자 목록을 반환
  * 주변 식당 검색, 가까운 n개 주유소 검색 등
  * 주어진 검색 반경을 사용자가 UI에서 변경 가능하다.

* 사업장 정보가 추가 삭제 갱신은 되지만 실시간으로 반영될 필요는 없다.

비기능 요구사항

* 낮은 응답지연(레이턴시) : 신속한 검색
* 데이터 보호 : 위치 기반 서비스(LBS)는 사용자 정보를 언제나 보호해야 함.
* 트래픽이 급증해도 고가용성을 유지해야 함.

## QPS 계산

* DAU 1억명, 사업장수 2억개
* 1일 = 86400초, 계산 쉽게하기위해 100,000으로 두고 , 1억 x 5회 / 100,000 한 사용자당 평균 검색량 5회 => QPS 5000



### 데이터베이스 선정

#### **성능순**:

Elasticsearch > Redis > MongoDB > PostgreSQL > Cassandra

#### **비용순**:

PostgreSQL > MongoDB > Redis > Elasticsearch > Cassandra

#### **성능-비용 균형**:

MongoDB > Elasticsearch > Redis > PostgreSQL > Cassandra

#### **기타 고려 사항에 따른 추천**:

- **고급 위치 기반 검색**: Elasticsearch
- **데이터 저장과 검색 간의 균형**: MongoDB
- **단순한 반경 검색과 캐싱**: Redis
- **데이터 일관성과 관계형 처리**: PostgreSQL

## 데이터 스키마

읽기 연산이 압도적인 시스템은 관계형 데이터베이스가 바람직할 수 있다.

핵심이 되는 테이블은 geospatial index table이다.

### 개략적 설계

<img src="./images//image-20241221014613750.png" width = 550 height =550>

위치 기반 서비스 (lbs, Location-Based Service)는 다음과 같은 특징이 있다.

* 주로 쓰기보다 읽기 요청이 빈번한 서비스.
* QPS가 높으며 인구 밀집 지역일수록 경향이 심함.
* stateless 서비스여서 수평 규모 확장이 쉬움.



실제로는 많은 회사가 redis geohash나 postgis를 많이 사용한다.

면접관은 내부 구조보다는 지리적 위치 index가 **어떻게 동작하는지 설명**하는것이 좋다. 



지리적 정보에 인덱스를 만드는 방법

* 해시 기반 방안 : 균등 격자(even grid), 지오해시(geohash), 카르테시안 계층(cartesian tiers)
  * **균등 격자 방식**은 지리적 영역을 균일한 크기의 사각형 격자로 분할. 각 격자는 고유한 식별자를 가지며, 특정 지점이나 영역은 해당하는 격자 내에 매핑. 이 방식은 간단하고 구현이 쉽지만, 격자의 크기가 너무 크거나 작으면 검색 효율이 떨어질 수 있다.
    * 사업장 분포가 균등하지 않아서 특정 격자에 몰려있을수도, 없을수도 있어서 균등하지 않은 문제가 있다. 그리고 격자를 어떻게 나눌것인지 명확한 체계를 잡기가 어렵다. 
  * **지오해시**는 지리적 좌표를 하나의 문자열로 인코딩하는 방법. 이 방식은 좌표를 이진수로 변환한 후, 이진수를 기반으로 문자열을 생성. 인접한 위치들은 대체로 유사한 접두사를 가진 해시 값을 갖게 되며, 해시의 길이를 조정함으로써 정밀도를 조절할 수 있다. 이는 분산 시스템에서 지리적 데이터를 효과적으로 인덱싱하고 검색할 수 있다.
  * **카르테시안 계층**은 좌표계를 여러 계층의 격자로 나누어 인덱싱하는 방법. 각 계층은 다른 크기의 격자를 사용하며, 상위 계층의 큰 격자로부터 시작해 점점 작은 격자로 세분화되면서 위치 정보를 더 정밀하게 나타냄 이 방식은 공간의 효율적인 표현과 검색을 가능하게 합니다.
  
* 트리 기반 방안 : 쿼드 트리(quadtree), 구글(S2), R-tree
  * **쿼드 트리**는 공간을 네 개의 구역으로 재귀적으로 나누는 트리 기반의 데이터 구조. 각 노드는 네 개의 자식 노드(쿼드런트)를 가지며, 공간을 4분면으로 분할. 이 구조는 특히 이미지 처리나 지리적 데이터 처리에서 효과적으로 사용. 쿼드 트리는 검색 속도를 향상시키지만, 균형 유지가 필요할 수 있다.
  * **구글의 S2 라이브러리는 지구를 구형 셀로 분할하여 인덱싱**하는 방식을 사용. 이 시스템은 지구를 큐브로 투영한 후, 이 큐브를 계속해서 분할하여 더 작은 셀로 나눔. S2는 공간 검색을 위해 범위 쿼리, 최근접 이웃 검색 등을 지원하며, 공간의 효율적인 인덱싱을 가능하게 함.
  * **R-tree는 공간 데이터를 관리하기 위해 범위를 나타내는 사각형 또는 입체적 경계 상자를 이용하는 계층적 트리 구조**. 각 노드는 하나 이상의 공간적으로 인접한 객체를 포함하며, 이 구조는 주로 공간 데이터베이스에서 널리 사용. R-tree는 공간 검색을 최적화하기 위해 범위 쿼리에 매우 효율적.

![image-20240429234617634](./images//image-20240429234617634.png)



각 구현방법은 서로 다르지만, 개략적 아이디어는 같다.

<u>지도를 작은 영역으로 분할하고, 고속 검색이 가능하도록 하는것.</u> 

* 지오해시, 쿼드트리, 구글 S2는 실제로 가장 널리쓰이는 방법

### 지오해시

지오해시는 일반적으로 다음과 같은 구조를 가집니다:

- **문자 집합**: 지오해시는 보통 `0123456789bcdefghjkmnpqrstuvwxyz`의 32개 문자를 사용하여 이진 데이터를 압축합니다.
- **문자 길이**: 각 문자는 지리적 영역을 점점 더 세분화합니다. 예를 들어, 지오해시의 길이가 5이면 약 4.9km x 4.9km의 영역을 나타내고, 길이가 9이면 약 4.7m x 4.7m의 영역을 나타냅니다.

장점

- **효율적인 검색**: 지오해시는 공간 인접성을 유지하므로, 동일한 접두사를 가진 지오해시들은 지리적으로 가까운 위치를 나타냅니다. 이를 통해 데이터베이스에서 특정 지역 내의 데이터를 빠르게 검색할 수 있습니다.
- **간단한 구현**: 문자열 기반이기 때문에 기존의 문자열 검색 인덱싱 기술을 활용할 수 있습니다.
- **확장성**: 지오해시는 다양한 정밀도로 확장할 수 있어, 필요한 정확도에 따라 유연하게 사용할 수 있습니다.

단점

- **비균일한 셀 크기**: 지오해시는 위도와 경도의 비율에 따라 셀 크기가 다소 불균일합니다. 특히, 위도가 높아질수록 동서 방향의 셀 크기가 줄어드는 단점이 있습니다.
- **경계 문제**: 특정 영역의 경계에 위치한 지오해시는 인접한 셀에 있는 데이터와의 관계를 정확히 반영하기 어려울 수 있습니다. 이를 해결하기 위해 추가적인 쿼리가 필요할 수 있습니다.

지오해시는 균등격자보다 나은 방안이다.

지오해시는 2차원의 위도 경도 데이터를 1차원의 문자열로 변환한다.

이후 비트를 하나씩 늘려가면서 재귀적으로 세계를 더 작은 격자로 분할해나간다.

<img src="./images//image-20240430000611704.png" width = 500 height = 450>

- ﻿﻿위도 범위 [-90, 0]은 0에 대응
- ﻿﻿위도 범위 [0, 90]은 1에 대응
- ﻿﻿경도 범위 [-180, 0] 은 0에 대응
- ﻿﻿경도 범위 [0, 180]은 1에 대응

<img src="./images//image-20240430000817396.png" width = 450>

이 절차를 원하는 정밀도(precision)을 얻을 때까지 반복한다. 

지오해시는 통상적으로 base32표현법을 사용한다.

* 구글 본사 지오해시 (길이 = 6)
  * 1001 11010 01001 1001 11111 11110 -> 9q9hvu(base32)
* 메타 본사 지오해시 (길이 = 6)
  * 1001 11010 01001 10011 10001 11011 -> 9q9jhr(base32)

지오해시는 12단게 정밀도를 갖는다. 이 정밀도가 격자 크기를 결정하는데 너무 크면 격자가 너무 작아지고, 너무 작으면 격자가 너무 커진다.

<img src="./images//image-20240430002209403.png" width = 550>

최적 정밀도를 정하려면, 사용자가 지정한 반경으로 그린 원을 덮는 최소 크기 격자를 만드는 지오 해시 길이를 구해야 한다.

* 지오해시 길이는 반경에 따라 길이가 달라짐. 

| 반경 (킬로미터, 마일, 미터) | 지오해시 길이 |
| --------------------------- | ------------- |
| 0.5 km (0.31 mi, 500 m)     | 6             |
| 1 km (0.62 mi, 1000 m)      | 5             |
| 2 km (1.24 mi, 2000 m)      | 5             |
| 5 km (3.1 mi, 5000 m)       | 4             |
| 20 km (12.42 mi, 20000 m)   | 4             |

예시

```
노원구 주변 매장 검색.
위도(Latitude): 37.6543° N
경도(Longitude): 127.0562° E

지오해시(Geohash): xnj7c8 
- 예를 들어, 반경 1km 내의 매장을 찾고자 한다면, 지오해시의 길이를 6자리(xnj7c8)로 설정

xnj7c8와 동일한 접두사를 가진 매장들을 검색

SELECT * FROM stores
WHERE geohash LIKE 'xnj7c8%'

xnj7c8의 인접 지오해시
SELECT * FROM stores
WHERE geohash LIKE 'xnj7c8%'
   OR geohash LIKE 'xnj7c7%'
   OR geohash LIKE 'xnj7c9%'
   OR geohash LIKE 'xnj7c8a%'
   OR geohash LIKE 'xnj7c8b%'
```





### 격자 가장자리 관련 이슈

보통 해시값의 공통 prefix가 긴 격자들이 서로 더 가깝게 놓이도록 보장한다.

<img src="./images//image-20241221020137002.png" width = 550 height = 400>

그 역은 아닐 수 있다. 가까운 두 위치가 공통 접두어를 가지지 않을수도 있따. 

* ex) 프랑스의 u000과 30km 떨어진 ezzz는 접두어가 완전 다름 

때문에 단순히 접두어 기반 SQL을 사용하면 주변 사업장을 가져올 수 없다.

```
select * from geohash_table where geohash like '9q8zn%'
```



### 격자 가장자리 이슈 2

또 다른 문제점은 두 지점이 공통 접두어 길이는 길지만 서로 다른 격자에 놓이는 경우다

![image-20241221020723857](./images//image-20241221020723857.png)

현재 격자를 비롯한 인접한 모든 격자의 사업장 정보를 가져와 잘라 사용하면 된다. 

### 방안 4

다른 해결책은 쿼드트리다. 쿼드트리는 특정 기준 만족할 떄까지 2차원 공간을 재귀적으로 사분면 분할하는데 사용되는 자료구조다. ex) 격자에 담긴 사업장 수가 100이하가 될떄까지 분할.

* 쿼드트리는 메모리 안에 놓이는 자료구조지, db가 아니다. 즉 애플리케이션에 존재해야 함.

![image-20241221020929246](./images//image-20241221020929246.png)

* ex 전세계 2억개 사업장 있다고 가정

![image-20241221020957553](./images//image-20241221020957553.png)

#### 쿼드트리 저장에 사용되는 메모리 계산

말단 노드에 들어가는 데이터

* 격자를 식별하는 사용될 좌상단 우상돤 꼭지점 : 32바이트 (8바이트 x 4)
* 격자 내부 사업장 id 목록 : id당 8바이트 (한 격자에 허용되는 사업장 수 최댓값)

* 합계 832바이트 (100개니까)

내부 노드에 수록되는 데이터

* 격자 식별 좌상단 우하단 : 32바이트
* 하위 노드 4개 포인터 : 32바이트
* 합계 64바이트

격자 안에 최대 100개 사업장일경우

* 말단 노드 수 = 200m / 100 = 2백만
* 내부 노드 수 = 2m * 1/3 = 0.67백만
  * 각 내부 노드는 4개의 자식 노드를 생성하며, 생성된 자식 노드중 1개는 리프노드, 나머지 3개는 내부 노드가 될 가능성이 있기 때문 
  * 이 특성 때문에 쿼드트리에서 **리프 노드가 늘어날 때마다 내부 노드가 리프 노드의 약 3배로 증가**하는 구조적 특성
* 2m x 832바이트 + 0.67 x 64바이트 = 1.71gb

단, 모든 애플리케이션에 구축 해둬야 트래픽을 견딜 수 있다. (수평 확장)

또한, 애플리케이션 시작시 트리 구축에 드는 시간이 필요한데 (시간복잡도 n/100 log n /100)

몇분 정도 소요될 수 있어서 애플리케이션 시작 시간에 영향을 줄 수 있다. 

**배포시, 모든 서버에 동시 배포하면 200m개 사업장 정보를 n개의 애플리케이션에서 동시에 읽게되어 시스템 부하가 생길 수 있다는 점을 꼭 기억하자.**

또한, 사업장 추가/삭제시 쿼드트리 갱신 문제다. 점진적으로 갱신해야하는데 그동안 낡은 데이터가 반환될 수 있다는 점도 고려해야 한다. 

### 방안 5 구글 S2

구글 기하 S2 라이브러리. 이 방법도 메모리 기반이다.

지구를 힐베르트 곡선이라는 공간 채움 곡선을 사용하여 1차원 indexing 하는 방안이다. 

<img src="./images//image-20241221022606189.png" width = 450 height = 450>

### 지리 정보 색인 기술 사용 현황

| 색인 방법           | 회사                                                        |
| ------------------- | ----------------------------------------------------------- |
| 지오해시            | 빙(Bing) 지도, 레디스(Redis), 몽고DB(MongoDB), 리프트(Lyft) |
| 쿼드트리            | 엑스트(Yext)                                                |
| 지오해시 + 쿼드트리 | 일래스틱서치(Elasticsearch)                                 |
| S2                  | 구글 맵(Google Maps), 틴더(Tinder)                          |

면접 시에는 지오해시나 쿼드트리 가운데 하나를 선택하길 추천한다. S2는 면 접 시간 동안에 분명하게 설명하기에는 까다롭기 때문이다.

### 지오해시 vs 쿼드트리

지오해시

* 구현 사용 쉬움. 트리 구축 필요 없음. 지정 반경 이내 사업장 검색 지원
* 정밀도 고정시 격자 크기도 고정, 동적으로 격자 크기 조정 불가능
* 색인 갱신이 쉬움

쿼드트리

* 구현이 어려움 트리 구축 땜에
* n번째로 가까운 사업장까지의 목록 구할 수 있음. 
* 인구 밀도에 따라 격자 크기 동적 조정 가능. 
* 색인 갱신이 지오해시보다 까다로움. 말단 노드부까지 트리를 순해회서 갱신해야 하며, 멀티스레드 환경에서는 동시성 이슈때문에 락을 사용해야함. 해결방법은 말단 노드가 담당하는 구간 크기를 필요한 양보다 크게잡으면 됌 

## 3단계 상세 설계

- ﻿﻿데이터베이스 규모 확장
- ﻿﻿캐시(cache)
- ﻿﻿지역(region) 및 가용성 구역(availability zone)
- ﻿﻿시간대 또는 사업장 유형에 따른 검색
- ﻿﻿최종 아키텍처 다이어그램

### 규모 확장성

사업장 테이블과 지리 정보 인덱스 테이블의 확장성을 비교하자

사업장 테이블은 한 서버에 담을 수 없을만큼 많아지면 샤딩을 고려해야 한다. 부하를 고르게 분산해야 한다



지리정보 색인 테이블은 지오해시를 사용해본다.

* 방안 1: 각각의 지오해시에 연결되는 모든 사업장 id를 json 배열로 만들어 같은 열에 저장 
* 방안 2: 같은 지오해시에 속한 사업장 ID 각각을 별도 열로 저장하는 방안. 사업장마다 1개 레코드 필요 

읽기 연산의 빈도가 높다면 서버 한대와 네트워크 대역폭으로는 요청 전부 감당 불가능하여 여러 데이터베이스 서버로 분산해야 한다. 



## 캐시

캐시 도입 전에는 정말 필요한가를 고려해야 한다.

* 처리 부하가 읽기 중심이고 디비 크기는 상대적으로 작아서 모든 데이터는 한대 데이터베이스 서버에 수용 가능하므로, 이 경우 query 처리 성능은 i/o에 좌우되지 않으므로 메모리 캐시를 사용할때와 비슷하다. 
* 읽기 성능이 병목이라면 레플리카를 늘린다.

캐시 도입 의논시 벤치마킹과 비용 분석에 각별히 중요하자.

### 캐시 키

직관적 캐시 키는 사용자 위치의 위도경도 정보다. 그러나, 추정치일뿐 아주 정확하진 않다. 그리고 미세하게 변경되어서 캐시 키로는 적절하지 않다. 

키를

지오해시 - 해당 격자 내의 사업장 id 목록

사업장 id - 사업장 정보 객체

로 두게 되면 성능 향상이 가능하다. 



또한 지오해시를 사용할 경우, 검색 반경에 따른 정밀도(지오해시 키 길이)가 달라지기 때문에 여러 정밀도별로 검색 결과를 레디스에 캐시해 두는것이 좋다. 

#### 메모리 필요 요구량

* 값을 저장하기 위한 필요 공간 : 8바이트 x 200m(2억) x 3가지 정밀도 (4, 5, 6) = 5GB

### 지역(region) 및 가용성 구역(availability zone)

t사용자와 시스템사이 물리적 거리를 최소한으로 줄이기 위해 여러 지역과 가용성 구역에 설치한다.

그리고 인구 밀도가 높은 지역에 대해서 트래픽을 고르게 분산할 수 있다. 

### 추가질문, 시간대 혹은 사업장 유형별 검색

지금 영업중인 사업장 혹은 식당 정보만 받아오고 싶다면?

* 지오해시나 쿼드트리같은 메커니즘을 통해 작은 격자들로 분할하면 검색 결과로 얻어지는 사업장 수는 적다
* 그러므로 근처 사업장 id부터 전부 앱에 확보한 다음 전부 추출해서 영업 시간이나 사업장 유형에 따라 필터링한다 



최종 아키텍처 

![image-20241221024109692](./images//image-20241221024109692.png)

Redis를 **클러스터 환경**이나 **레플리케이션 환경**에서 여러 키를 빠르게 조회하는 것은 상황에 따라 약간의 제약과 추가 고려사항이 필요합니다. 아래에서 **클러스터**와 **레플리케이션**에서 각 방법의 사용성을 분석하고 추천합니다.

------

### **Redis 클러스터 환경에서의 고려사항**

Redis 클러스터는 키를 **Slot**으로 분산하여 저장합니다. 특정 명령은 **모든 키가 같은 Slot에 있어야** 실행됩니다.

- **문제점**: `MGET`과 같은 다중 키 조회는 **모든 키가 동일한 Slot**에 있을 때만 작동.
- **해결책**: 해시 태그 사용 (`{}` 안에 동일한 문자열 포함)으로 키를 강제로 같은 Slot에 저장.

#### **해시 태그 적용 예시**

```
SET {user:123}:key1 value1
SET {user:123}:key2 value2
MGET {user:123}:key1 {user:123}:key2
```

#### **클러스터에서 사용할 수 있는 방법**

1. **MGET**

   - **제약**: 모든 키가 같은 Slot에 있어야 가능.
   - **장점**: 다중 키 조회를 단일 요청으로 처리.

2. **Pipeline**

   - 클러스터 환경에서도 동작하며, 키가 서로 다른 Slot에 있어도 병렬로 처리.

   - 예시

     ```
     const pipeline = client.pipeline();
     pipeline.get("key1");
     pipeline.get("key2");
     pipeline.exec((err, results) => {
       console.log(results);
     });
     ```

3. **Lua Script (Cluster Mode 제한)**

   - Lua 스크립트는 단일 Slot에서만 동작.
     따라서 클러스터 모드에서는 스크립트 사용에 제한.

4. **Hash로 데이터 묶기**

   - 연관된 데이터를 하나의 Hash에 저장하면 클러스터 환경에서도 효율적으로 처리.

   - 예시

     ```
     HMSET {user:123} key1 value1 key2 value2
     HMGET {user:123} key1 key2
     ```

5. **SCAN + MGET**

   - **방법**: SCAN으로 키 조회 후 각 Slot에서 MGET 병렬 실행.
   - **제약**: 복잡하며 부하가 크므로 대규모 데이터에서는 비추천.



`Pipeline`은 Redis 클러스터에서 서로 다른 슬롯에 있는 키를 병렬로 처리할 수 있는 유용한 도구이므로 파이프라인을 고려하되, 완전히 병렬화 되지는 않는다.

비동기로 병렬로 동시에 요청하는것도 좋다. 

## 면접 예상 질문



1. 근접성 서비스에 적합한 데이터베이스를 성능순으로 나열하고, 각 데이터베이스의 장단점을 설명해주세요 
   1. 비용 순으로는 PostgreSQL이 가장 저렴하고, 레디스가 가장 비용이 많이 듭니다. 성능-비용 균형을 고려할 때는 MongoDB가 우수합니다.
   2. PostgreSQL의 R-트리 인덱스는 근접성 서비스에 어떻게 활용될 수 있나요?
      - **답변:** PostgreSQL의 R-트리 인덱스는 지리적 데이터를 효율적으로 검색하기 위해 사용됩니다. R-트리는 공간 데이터를 사각형으로 감싸는 방식으로 인덱싱하여, 범위 검색이나 근접 검색 시 빠른 응답을 가능하게 합니다. 예를 들어, 특정 위치에서 반경 내의 사업장을 검색할 때 R-트리 인덱스를 활용하면 효율적으로 데이터를 조회할 수 있습니다. 또한, PostgreSQL의 PostGIS 확장 기능을 사용하면 고급 지리 공간 기능을 추가로 활용할 수 있습니다.
   3. Elasticsearch를 근접성 서비스에 사용하는 주요 장점은 다음과 같습니다:
      - **강력한 검색 기능:** 텍스트 검색과 함께 지리적 검색을 고성능으로 지원합니다.
      - **스케일 아웃:** 클러스터링을 통해 쉽게 수평 확장이 가능하며, 대규모 데이터를 효과적으로 처리할 수 있습니다.
      - **실시간 검색:** 실시간으로 데이터를 색인하고 검색할 수 있어 신속한 응답이 가능합니다.
      - **복합 쿼리:** 다양한 필터와 집계 기능을 통해 복잡한 검색 요구사항을 만족시킬 수 있습니다.
2. 지리적 위치 인덱스의 종류와 어떻게 동작하는지 설명해주세요
   1.  R-트리 인덱스의 장점과 단점은 무엇인가요?
      - 답변:
        - 장점:
          - **효율적인 범위 검색:** R-트리는 공간 데이터를 사각형으로 감싸 인덱싱하기 때문에 범위 검색에 매우 효율적입니다.
          - **동적 삽입 및 삭제:** 데이터의 동적 삽입과 삭제가 용이하여 실시간 데이터 관리에 적합합니다.
          - **공간 활용 효율성:** 공간을 효율적으로 분할하여 메모리 사용을 최적화할 수 있습니다.
        - 단점:
          - **복잡성:** 트리 구조의 복잡성으로 인해 구현과 관리가 어려울 수 있습니다.
          - **균형 유지 어려움:** 데이터 삽입 및 삭제 시 트리의 균형을 유지하는 것이 어려울 수 있습니다.
          - **성능 저하 가능성:** 데이터 분포가 불균등할 경우 성능이 저하될 수 있습니다.

3. 근접성 서비스의 데이터베이스 확장성에 대해 설명해주세요

   * **주요 답변:** 데이터베이스 확장성은 두 가지 주요 테이블인 사업장 테이블과 지리 정보 인덱스 테이블을 중심으로 고려됩니다.

     - **사업장 테이블:** 사업장 수가 매우 많아지면 단일 서버에 저장할 수 없으므로 샤딩을 통해 데이터를 여러 서버에 분산 저장해야 합니다. 이를 통해 부하를 고르게 분산시키고, 읽기 및 쓰기 성능을 향상시킬 수 있습니다.

     - **지리 정보 인덱스 테이블:** 지오해시를 사용하여 데이터를 인덱싱할 경우, 각 지오해시에 해당하는 사업장 ID를 효율적으로 저장하고 검색할 수 있도록 설계해야 합니다. 두 가지 방안으로는:

       1. **JSON 배열로 저장:** 각 지오해시에 연결된 모든 사업장 ID를 JSON 배열로 저장.
       2. **별도 열로 저장:** 같은 지오해시에 속한 각 사업장 ID를 별도의 열로 저장하여 개별적으로 관리.

       높은 읽기 빈도에서는 여러 데이터베이스 서버로 분산하여 네트워크 대역폭과 서버의 부하를 효율적으로 관리해야 합니다.

   * 샤딩을 구현할 때 고려해야 할 주요 요소는 무엇인가요?

     - 답변:

        샤딩을 구현할 때 고려해야 할 주요 요소는 다음과 같습니다:

       - **샤드 키 선택:** 데이터를 균등하게 분산시키기 위한 적절한 샤드 키를 선택해야 합니다. 예를 들어, 지오해시의 특정 부분을 샤드 키로 사용할 수 있습니다.
       - **데이터 균등 분포:** 샤드 간에 데이터가 균등하게 분포되도록 설계하여 특정 샤드에 부하가 집중되지 않도록 합니다.
       - **확장 용이성:** 데이터 증가에 따라 쉽게 샤드를 추가할 수 있는 구조를 갖추어야 합니다.
       - **복구 및 백업:** 샤드 간의 데이터 복구 및 백업 전략을 수립하여 데이터 손실을 방지합니다.

4. MySQL과 PostgreSQL에서 R-트리 인덱스를 사용하는 방법과 장단점에 대해 설명해 주세요.

   1. **MySQL의 R-트리 인덱스:**

      - **사용 방법:** MySQL에서는 주로 MyISAM 스토리지 엔진에서 R-트리 인덱스를 지원하며, 공간 데이터 타입인 `SPATIAL` 인덱스를 통해 사용할 수 있습니다.
      - 장점:
        - **효율적인 공간 검색:** 범위 검색과 근접 검색에 효과적입니다.
        - **빠른 쿼리 성능:** R-트리 인덱스를 사용하면 지리적 쿼리의 성능이 향상됩니다.
      - 단점:
        - **스토리지 엔진 제한:** InnoDB에서는 R-트리 인덱스를 직접 지원하지 않으므로, MyISAM과 같은 다른 스토리지 엔진을 사용해야 합니다.
        - **동시성 제약:** MyISAM은 테이블 수준의 잠금을 사용하여 동시성 처리에 제약이 있습니다.

      **PostgreSQL의 R-트리 인덱스 (PostGIS와 함께 사용):**

      - 사용 방법:

         PostgreSQL에서는 PostGIS 확장 기능을 사용하여 R-트리 기반의 GiST(Generalized Search Tree) 인덱스를 생성할 수 있습니다.

        ```
        CREATE INDEX idx_geography ON stores USING GIST (geography_column);
        ```

      - 장점:

        - **고급 공간 기능:** PostGIS는 다양한 공간 함수와 데이터 타입을 지원하여 복잡한 지리적 쿼리를 처리할 수 있습니다.
        - **동시성 처리:** InnoDB와 유사한 MVCC(Multi-Version Concurrency Control) 방식을 사용하여 높은 동시성을 지원합니다.
        - **확장성:** 대규모 데이터를 효과적으로 관리하고, 고성능 검색을 지원합니다.

      - 단점:

        - **복잡한 설정:** PostGIS의 고급 기능을 활용하려면 설정과 관리가 다소 복잡할 수 있습니다.
        - **성능 튜닝 필요:** 최적의 성능을 위해 인덱스 설정과 쿼리 최적화가 필요합니다.

      - PostgreSQL의 GiST 인덱스와 R-트리 인덱스의 차이점은 무엇인가요?

        - **답변:** PostgreSQL에서 GiST(Generalized Search Tree) 인덱스는 다양한 데이터 타입과 검색 요구사항을 지원하는 범용 인덱스 구조입니다. R-트리는 GiST의 한 구현으로, 공간 데이터를 위한 인덱싱에 특화되어 있습니다. GiST 인덱스는 R-트리 외에도 다양한 트리 구조를 지원할 수 있어 유연성이 높습니다. 반면, R-트리는 주로 공간 데이터 검색에 최적화되어 있습니다.

3. 지오해시의 사용법과 장단점에 대해 설명해주세요 

   1. 지오해시의 격자 가장자리 이슈를 해결하기 위한 방안은 무엇인가요

   2. 지오해시의 비균일한 셀 크기가 서비스에 미치는 영향은 무엇인가요?

      - 답변:

         비균일한 셀 크기는 다음과 같은 영향을 미칠 수 있습니다:

        - **검색 정확도 저하:** 특정 지역에서 셀 크기가 너무 작거나 커져 검색 결과의 정확도가 떨어질 수 있습니다.
        - **인접 셀 처리 복잡성 증가:** 셀 크기가 비균일하기 때문에 인접 셀을 처리할 때 더 많은 로직이 필요할 수 있습니다.
        - **데이터 분포 불균형:** 인구 밀집 지역과 저밀도 지역 간의 데이터 분포가 불균형해질 수 있어, 특정 셀에 데이터가 몰리는 문제가 발생할 수 있습니다.

4. 근접성 서비스에서의 캐시를 도입할때 고려해야할 사항은 무엇인가요

   1. 캐시 키를 어떻게 설계하는 것이 효율적일가요 

   2. 캐시 키 설계 시 지오해시를 사용하는 것이 왜 효율적인가요?

      - **답변:** 지오해시는 공간 인접성을 유지하는 특징이 있어, 동일한 접두사를 가진 지오해시는 지리적으로 가까운 위치를 나타냅니다. 이를 캐시 키로 사용하면 특정 지역 내의 데이터를 빠르게 검색할 수 있으며, 인접 지오해시를 함께 캐싱함으로써 경계 문제를 해결할 수 있습니다. 또한, 지오해시 길이에 따라 다양한 정밀도로 데이터를 관리할 수 있어 유연한 캐시 전략을 구현할 수 있습니다.

   3.  캐시 일관성을 유지하기 위한 방법에는 어떤 것들이 있나요?

      - 답변:

         캐시 일관성을 유지하기 위해 다음과 같은 방법을 사용할 수 있습니다:

        - **캐시 무효화 전략:** 데이터가 변경될 때 관련 캐시를 무효화하거나 업데이트합니다.
        - **TTL(Time-To-Live) 설정:** 캐시 항목에 만료 시간을 설정하여 일정 시간이 지나면 자동으로 갱신되도록 합니다.
        - **쓰기 시 캐시 업데이트:** 데이터베이스에 데이터가 쓰여질 때 동시에 캐시도 업데이트하여 일관성을 유지합니다.

   4. 근접성 서비스에서 캐시를 도입하지 않아도 되는 경우는 어떤 경우인가요?

      - 답변:

         캐시를 도입하지 않아도 되는 경우는 다음과 같습니다:

        - **읽기 부하가 낮은 경우:** 데이터베이스의 읽기 요청이 적어 성능 병목이 발생하지 않을 때.
        - **데이터베이스가 충분히 빠른 경우:** 데이터베이스 자체의 성능이 매우 높아 캐시를 사용하지 않아도 충분한 응답 속도를 제공할 수 있을 때.
        - **데이터 일관성이 최우선인 경우:** 캐시 도입 시 발생할 수 있는 일관성 문제를 최소화해야 할 때.
        - **비용 효율성 고려:** 캐시 시스템을 도입할 경우 발생하는 추가 비용이 서비스의 성능 향상에 비해 합리적이지 않을 때.

   5. 캐시 서버(Redis)를 활용하여 검색 성능을 향상시키는 방법은 무엇인가요?

      - 답변:

         캐시 서버(Redis)를 활용하여 검색 성능을 향상시키는 방법은 다음과 같습니다:

        - **자주 사용하는 검색 결과 캐싱:** 자주 검색되는 지오해시와 사업장 목록을 Redis에 캐싱하여 데이터베이스 접근을 최소화합니다.
        - **캐시 키 최적화:** 지오해시와 검색 반경을 기반으로 효율적인 캐시 키를 설계하여 빠른 데이터 조회를 가능하게 합니다.
        - **TTL 설정:** 캐시된 데이터에 TTL(Time-To-Live)을 설정하여 오래된 데이터를 자동으로 갱신하고, 최신 데이터를 유지합니다.
        - **캐시 미스 처리:** 캐시 미스 발생 시 데이터베이스에서 데이터를 조회한 후, 캐시에 저장하여 이후 요청 시 빠르게 접근할 수 있도록 합니다.
        - **캐시 레이어 확장:** Redis 클러스터를 구성하여 캐시 용량을 확장하고, 고가용성을 유지합니다.

5. QPS 계산 시 어떤 가정을 했는지 설명해 주세요.

   * 동시 사용자 분포:** 사용자들이 하루 동안 균등하게 검색을 수행한다고 가정했습니다.

   - **검색 빈도:** 사용자당 하루 평균 5회의 검색을 한다고 가정했습니다.
   - **초당 평균 분포:** 일일 총 검색 요청을 하루 초 수로 나누어 초당 평균 요청 수를 계산했습니다.
   - **피크 타임 고려:** 실제 서비스에서는 피크 타임을 고려하여 QPS를 조정할 필요가 있습니다. 예를 들어, 특정 시간대에 검색 요청이 집중될 수 있습니다.

6. QPS가 예상보다 크게 증가할 경우 어떻게 대응할 수 있나요?

   - **수평 확장:** 서버 인스턴스를 추가하여 트래픽을 분산 처리합니다.
   - **캐싱:** 자주 요청되는 데이터를 캐시에 저장하여 데이터베이스 부하를 줄입니다.
   - **쿼리 최적화:** 데이터베이스 쿼리를 최적화하여 응답 시간을 단축시킵니다.
   - **로드 밸런싱:** 로드 밸런서를 활용하여 트래픽을 고르게 분산시킵니다.
   - **비동기 처리:** 비동기 처리를 도입하여 시스템의 처리 용량을 향상시킵니다.

7. 근접성 서비스에서 고가용성을 유지하기 위한 전략은 무엇인가요?

고가용성을 유지하기 위해 다음과 같은 전략을 적용할 수 있습니다:

- **다중 지역 및 가용성 구역 배치:** 사용자와 시스템 간의 물리적 거리를 최소화하기 위해 여러 지역과 가용성 구역에 서버를 분산 배치합니다.
- **수평 확장:** 트래픽 증가에 대비하여 서버를 수평으로 확장할 수 있도록 설계합니다. 이는 부하 분산과 장애 조치에 유리합니다.
- **데이터 복제:** 데이터베이스의 레플리카를 여러 서버에 복제하여 한 서버에 장애가 발생하더라도 서비스가 지속될 수 있도록 합니다.
- **캐시 사용:** 자주 접근하는 데이터를 캐시에 저장하여 데이터베이스 부하를 줄이고, 빠른 응답을 제공합니다.
- **모니터링 및 자동 복구:** 시스템 상태를 지속적으로 모니터링하고, 장애 발생 시 자동으로 복구할 수 있는 메커니즘을 구축합니다.
  - 장애 발생 시 자동 복구 시스템을 설계할 때 고려해야 할 요소는 무엇인가요?
    - 답변:장애 발생 시 자동 복구 시스템을 설계할 때 고려해야 할 요소는 다음과 같습니다:
      - **장애 감지:** 실시간으로 장애를 감지할 수 있는 모니터링 시스템을 구축합니다.
      - **복구 절차:** 장애 발생 시 자동으로 복구할 수 있는 절차와 스크립트를 정의합니다.
      - **재시도 메커니즘:** 일시적인 장애에 대비하여 자동 재시도 메커니즘을 도입합니다.
      - **서비스 이중화:** 주요 컴포넌트의 이중화를 통해 단일 장애 지점(SPOF)을 제거합니다.
      - **테스트 및 검증:** 자동 복구 시스템이 실제 장애 상황에서도 제대로 동작하는지 정기적으로 테스트하고 검증합니다.

# 2장 주변 친구

근접성 서비스의 경우 사업장 주소는 정적이지만 주변 친구 위치는 자주 바뀔 수 있기 때문에 고려해야 할게 많다.



 ## 1단계 : 문제 이해 및 설계 범위 확정

* 최소 가까운 거리 : 5마일(8km)
* 10억명 유저가있고 그 중 10%가 이 기능 활용
* 이동 기록은 보관한다.
* 10분이상 비활성 상태면 친구 목록에서 사라지도록 해야함 

기능 요구사항 

* 주변 친구 목록에는 해당 친구까지의 거리, 마지막으로 갱신된 시각이 표시되어야함
* 몇초마다 갱신되어야 한다. 

비기능 요구사항

* 낮은 레이턴시
* 때로 몇 개 데이터가 유실되는것 정도 용인 가능
* 결과적 일관성 : 강한 일관성을 지원하는 데이터 저장소는 필요 없음. 복제본 데이터가 원본과 동일하게 변경되기까지 몇 초 정도 걸리는 것은 용인할 수 있다.

문제 규모 추정

* 주변 친구는 5마일(8km)이내
* 친구 위치 정보는 30초주기로 갱신. 걷는 속도가 시간당 3~4마일 (4~6km)정도로 느림.
* 매일 활용하는 사용자는 1억명
* 동시 접속 사용자는 dau의 10% 즉 천만명
* 평균적으로 한 사용자는 400명의 친구 

QPS 계싼

* 1억 DAU
* 동시접속유저 천만
* 30초마다 자기 위치 전송
* 위치정보 **갱신** qps = 천만 / 30 = 334,000

## 2단계 : 개략적 설계안 

* 개략적 설계
* API 설계
* 데이터 모델

위치정보를 모든 친구에게 전송 해야하는 요구사항 때문에 http 프로토콜을 사용하지 못할수도 있다.

단순히 백엔드 서버를 두면, 30초마다 천만명 이 요청을 보내므로, 초당 334,000건의 위치 정보 갱신을 처리해야 한다.

### 소규모 백엔드를 위한 개략적 설계안 

<img src="./images//image-20241221143343036.png" width = 550 height = 550>

각 클라이언트는 웹소켓 연결을 지속적으로 유지하고 검색반경 내 친구 위치가 변경되면 해당 내역은 이 연결을 통해 클라이언트로 전송한다. 

레디스에 활성상태 사용자의 가장 최근 위치 정보를 캐시하고, TTL을 둔다. 이 기간이 지나면 비활성 상태로 바뀌고 레디스에서 삭제한다. 

레디스 펍/섭에 새로운 채널을 생성하는것은 아주 값싸다. 기가바이트급 메모리를 갖춘 레디스 서버에는 수백만개의 채널을 생성할 수 있다. 

![image-20241221143550699](./images//image-20241221143550699.png)

웹소켓 서버를 통해 수신한 특정 사용자의 위치 정보 변경 이벤트는 해당 사용자에게 배정된 펍/섭 채널에 발행한다. 

특정 사용자의 위치가 바뀌면 해당 사용자의 모든 친구의 웹소켓 연결 핸들러는 거리를 다시 계산하고, 계산한 거리가 검색 반경 이내면 갱신된 위치와 갱신 시각을 웹소켓을 통해 클라이언트 앱으로 보낸다. 

### 주기적 위치 갱신

모바일 클라이언트는 웹소켓으로 주기적으로 변경 내역을 전송한다

1. 모바일 클라이언트가 위치한 변경된 사실을 로드밸런서에 전송한다.
2. 로드밸런서는 그 위치 변경 내역을 해당 클라이언트와 웹소켓 서버 사이에 설정된 연결을 통해 웹소켓 서버로 보낸다
3. 웹소켓 서버는 해당 이벤트를 위치 이동 이력 데이터베이스에 저장한다

4. 웹소켓 서버는 새 위치 정보를 캐시에 저장하며 ttl도 갱신한다. 
5. 웹소켓 서버는 레디스 펍 섭 서버의 해당 사용자 채널에 새 위치를 발행한다. 3~5단계는 병렬로 수행된다
6. 새로운 위치 변경 이벤트는 모든 구독자에게 브로드 캐스트 한다. 
7. 메시지를 구독하여 수신한 웹소켓 서버는 새 위치를 보낸 사용자와 메시지 받은 사용자와 거리를 계산한다.
8. 7에서 계싼한 거리가 검색 반경을 넘지 않는다면 새 위치 및 해당 위치로의 이동이 발생한 시각을 나타내는 타임스탬프를 해당 구독자의 클라이언트 앱으로 전송한다. 넘는경우에는 보내지않는다. 



한 사용자당 평균 400명, 그 가운데 10% 가량이 주변에서 온라인 일것이므로 한 사용자 위치 바뀔시마다 위치 정보 전송은 40건정도다. 

### API 설계

웹소켓

1. 서버 - 주기적인 위치 정보 갱신.
   * 요청 : 위도 경도 시각 정보
   * 응답 : 없음
2. 클라이언트 - 클라이언트가 갱신된 친구 위치를 수신하는데 사용할 API
   * 친구 위치 데이터와 변경된 시각
3. 서버 - 웹소켓 초기화

4. 클라이언트 - 새 친구 구독 API

   요청 : 웹소켓 서버는 친구 ID 전송

   응답 ; 가장 최근의 위도 경도 시각 정보 전송

5. 클라이언트 - 구독 해지 

   * 요청 : 웹소켓 서버 친구 ID 전송
   * 응답 xx

### 데이터 모델

레디스 캐시 사용시 해당 캐시에 보관될 키 값 쌍은

* 사용자 ID : {위도, 경도, 시각}

왜 데이터베이스를 사용하지 않을까?

사용자의 현재 위치만을 이용하기 때문이다. 레디스는 이런 목적에 아주 적합한데, 읽기 및 쓰기 속도가 엄청 빠르고 TTL을 지원한다. 서버 하나가 장애 발생해도 클러스터나 다른 서버로 바꾼 다음 갱신 위치 정보가 채워지기 기다리면 충분하다. 

* 장애발생시 어떻게 대비, 처리해야 할까?, 오프라인 사용자의 마지막 위치정보도 알고 싶다면? 다른 TTL 데이터베이스나 캐시는 없을까?

위치 이동 이력 데이터베이스에는

userid, latitude, longitude, timestamp를 둔다.

막대한 쓰기 연산을 감당할 수 있고, 수평 규모 확장이 가능한 데이터베이스는 **아파치 카산드**라다. 관계형 데이터베이스는 샤딩을 하기에 복잡하다. 카산드라는 부하를 모든 샤드에 고르게 분산시킬 수 있다. 

## 3단계 상세 설계

개략적 설계안은 대형 규모에 감당하기 어려울것이다.

### 웹소켓 서버

웹소켓은 규모를 늘리는것은 어렵지 않지만 유상태라 기존 서버를 제거할때는 주의해야한다.

노드를 실제로 제거하기 전에 우선 기존 연결부터 종료될 수 있도록 해야한다. 로드밸런서에 연결 종료 상태로 두고, 모든 연결이 종료되면 서버를 제거한다. 

### 사용자 데이터베이스

사용자 데이터베이스에는 사용자 id, 사용자명, 프로필이미지 등 사용자 상세정보와

친구 관계 데이터를 보관한다.

한대의 관계형 데이터베이스로는 감당할 수 없다. 사용자 ID 기준으로 데이터를 샤딩하면 수평적 규모 확장이 가능하다.

### 위치정보 캐시

레디스 캐시 키에 TTL을 두므로 최대 메모리 사용량은 일정 한도 아래로 유지된다.

천만명의 사용자 활성화 상태이며 위치 정보 보관에 100바이트 사용한다고 가정시,   수기가 바이트면 충분하다.

천만명의 활성 사용자가 30초마다 변경 위치 정보 전송시, 갱신 연산 수는 초당 334K이다. 

* 초당 10만~120만까지 처리 가능 (인텔 제온 3.1 100K~200K, AMD EPYC 3.5 300K~500K, m1,m2 150~300k)
* 마스터-슬레이브 구조시, 쓰기는 마스터 읽기는 레플리카. 마스터는 100K 레플리카는 50~100K
* 클러스터 구조시, 3개 샤드라면 샤드당 약 100K 300K, 
  * 6샤드 (각 샤드 1마스터 1레플리카) - 400K~1M
  * 12샤드 (각 샤드 1마스터 2레플리카) -> 1M ~ 2M
  * 레디스 엔터프라이즈 최대 250M QPS 달성 사례도 조재 

각 사용자의 위치 정보는 서로 독립적이므로 사용자 ID 기준 여러 서버에 샤딩하면 부하 분배 가능. 

가용성 높이려며 프라이머리-스탠바이 노드에 복제해두면 된다. 

### 레디스 펍 섭 서버

채널 생성 비용이 아주 저렴하다. 구독자가 없는 채널로 보내는 메시지는 버려지는데 이 과정의 부하는 거의 없다.

채널 하나를 유지하기 위해 구독자 관계를 추적하기 위한 해시 테이블과 링크드 리스트가 필요한데 아주 소량의 메모리만을 사용한다. 

1. 주변 친구 기능을 활용하는 모든 사용자에 채널 하나씩 부여한다. 초기화 시 모든 친구의 채널과 구독 관게를 설정한다. 
2. 더 많은 메모리를 사용하겠지만, 메모리가 병목이 될 가능성은 낮다. 

얼마나 많이 서버와 메모리가 필요할까?

#### 메모리 사용량 

필요한 채널의 수 : 1억개 (10억의 10% ) 

한 사용자의 활성화 상태 친구 가운데 100명이 주변 친구 기능 사용, 구독자 한명 추적시 내부 해시테이블과 연결리스트에 20바이트 상당 포인터를 저장한다면,

모든 채널 저장시 200GB (1억 x 20바이트 x 100명의 친구 / 10의9승)의 메모리가 필요하다.

100GB 메모리 설치할 수 있는 최신 서버 사용하는 경우 모든 채널 보관시 레디스 펍섭 서버 두대면 된다

#### cpu 사용량

대략 위치정보 업데이트량은 초당 1400만건이다. 보수적으로 기가비트 네트워크의 서버한대 가능한 구독자 수는 10만이라고 하면 1400만 / 100,000 = 140대이다. (매우 보수적으로)

이 계산을 통해 레디스 펍섭 서버의 병목은 메모리가 아닌 CPU 사용량이다. 

분산 레디스 펍 섭 클러스터가 필요하다

### 분산 레디스 펍 섭 클러스터

수백 대 레디스 서버에 채널을 분산할 방법은 무엇인가? 다행인점은 모든 채널은 서로 독립적이다.

메시지를 발행할 사용자 ID 기준으로 펍 섭 서버들을 샤딩하면 됀다. 

서비스 디스커버리를 도입하여 이문제를 해결할 수 있다. 

다음의 두가지 기능을 서비스 디스커버리에서 사용한다

1. 가용한 서버 목록을 유지하는 기능 및 해당 목록을 갱신하는데 필요한 UI나 API.
2. 클라이언트(웹소켓 서버)로 하여금 값에 명시된 레디스 펍섭 서버에서 발생한 변경 내역을 구독할 수 있도록 하는 기능

키 : /config/pub_sub_ring

값: {"p_1", "p_2", "p_3"}

안정 해시 설계에 사용되는 해시링을 이용해서, 레디스 펍섭 서버는 메시지를 발행할 채널이나 구독할 채널을 정해야 할 때 해시 링을 참조한다. 

<img src="./images//image-20241221151818097.png" width = 350 height =450>

1. 웹소켓 서버는 해시 링을 참조하여 메시지 발행할 레디스 서버를 선정한다. 서비스 디스커버리에 보관되어 있지만 성능을 위해서 웹소켓 서버에 해시 링 사본을 캐시하는것도 괜찮다. 
2. 웹소켓 서버는 해당 서버가 관리하는 사용자 채널에 위치 정보 변경 내역을 발행한다. 

#### 규모 확장 고려사항

레디스 펍섭 클러스터는 유상태로 취급하는것이 바람직하다. 

혼잡 시간대 트래픽을 무리없이 감당하고 불필요한 크기 변화를 피할 수 있도록 어느정도 여유를 두고 오버 프로비저닝 하는것이 보통이다.

규모를 늘려야 할 경우 다음과 같은 문제가 발생할 수 있다.

* 클러스터 크기 조정 시 많은 채널이 같은 해시 링 위 다른 여러 서버로 이동한다. 서비스 디스커버리 컴포넌트가 모든 웹소켓 서버에 해시 링이 갱신되었음을 알리면 엄청난 재구독 요청이 발생한다
* 이 재구독 요청 처리시 클라이언트의 위치정보 변경 메시지 처리가 누락될 수 있다, 이 빈도는 최소화 해야 한다
* 서비스 상태 불안정 가능성이 높으므로 클러스터 크기 조정은 시스템 부하가 가장 낮은 시간을 골라서 시행해야 한다. 

클러스터 크기 조정시 다음 절차대로 한다

* 새로운 링 크기 계산한다.
* 해시 링의 키에 매달린 값을 새로운 내용으로 갱신한다
* 대시보드를 모니터링하여 웹소켓 클러스터의 cpu 사용량이 어느정도 튀는것이 보여야 한다. 

### 친구 추가/삭제

사용자가 친구를 추가하거나 삭제할 경우 클라이언트에 연결된 웹 소켓 서버에 알려 새 친구의 펍 섭 채널 구독 및 해제를 유지한다. 

### 친구가 많은 사용자 (핫 키 이슈 )

핫 키 이슈란 **특정 키에 너무 많은 트래픽이 집중**되어 Redis, 데이터베이스, 캐시 시스템 등에서 성능 저하를 유발하는 문제이다. 

이 시스템 역시 최대로 맺을 수 있는 친구의 수에 상한이 있는것이 좋다. (페이스북은 상한값이 5,000)

친구 관계는 양방향이다.

수천 명의 친구를 구독하는데 필요한 펍/섭 구독 관계는 클러스터 내의 많은 웹소켓 서버에 분산되어 있고, 나누어 처리하므로 핫키 이슈는 줄 수 있다. 클러스터안에 100대가 넘는 서버가 있다면 특정 서버에 막대한 부담을 줄 일은 없다.

### 주변의 임의 사용자

면접관이 설게를 좀 고쳐 위치 정보 공유에 동의한 주변 사용자를 무작위로 보여 줄 수 있도록 해보자고 한다면?

기존 설계안을 크게 훼손하지 않으면서 지원하는 방법은, 지오해시에 따라 구축된 펍/섭 채널 풀을 두는것이다.

지오해시 격자로 나눈 다음 격자마다 채널을 하나씩 만들어 두면 된다. 

![image-20241221153946953](./images//image-20241221153946953.png)

1. 사용자 2의 위치가 변경되면 해당 사용자의 지오해시 id를 계산한 다음, 해당 지오해시 id를 담당하는 채널에 새 위치 전송
2. 근방에 있는 사용자 가운데 해당 채널을 구독하고 있는 사용자는 사용자 2의 위치가 변경되었다는 메시지 수신 

### 레디스 펍/섭 외 대안

레디스 펍섭 대신 얼랭이 유용한 해결책이 될 수 있다. 

얼랭은 고도로 분산된 병렬 애플리케이션을 위해 고안된 프로그래밍 언어이자 런타임 환경이다.

BEAM VM에서 실행되는 가벼운 프로세스는 최소 300바이트만의 메모리를 사용한다. 

웹소켓 서비스를 얼랭으로 구현하고 레디스 펍 섭 클러스터는 분산 얼랭 애플리케이션으로 대체할 수 있다.

 ## 4단계 마무리

핵심 컴포넌트

* 웹소켓 : 클라-서버 사이 실시간 통신
* 레디스 - 위치 데이터 빠른 읽기 쓰기 
* 펍 섭 : 위치 정보 변경 내역을 모든 온라인 친구에게 전송하는 라우팅 계층 



## 면접 질문

1. 결과적 일관성을 채택한 이유는 무엇이며, 어떤 상황에서 적합한가요?
   - 결과적 일관성을 채택한 이유는 시스템의 고가용성과 확장성을 유지하면서도 성능을 최적화하기 위함입니다. 특히, 실시간 위치 정보와 같은 데이터는 몇 초의 지연을 허용할 수 있으므로 강한 일관성보다 결과적 일관성이 더 적합합니다. 이는 대규모 분산 시스템에서 데이터 복제를 용이하게 하고, 장애 시 빠른 복구를 가능하게 합니다.

2. 실제 서비스에서는 QPS를 어떻게 더 정확하게 추정할 수 있나요?

   * 로그 분석:** 기존 서비스의 로그 데이터를 분석하여 실제 트래픽 패턴을 파악합니다.

   * 사용자 행동 분석:** 사용자 행동 데이터를 기반으로 검색 빈도와 패턴을 분석합니다.

   * 부하 테스트:** 예상되는 트래픽을 시뮬레이션하여 시스템의 부하를 테스트하고 QPS를 측정합니다.

   * 트렌드 분석:** 사용자 증가율과 트래픽 트렌드를 분석하여 미래의 QPS를 예측합니다.

3. 근접성 서비스의 위치 정보 갱신 및 실시간 업데이트를 어떻게 구현할 것인지 설명해 주세요.

   * 주요 답변:** 근접성 서비스에서 위치 정보 갱신 및 실시간 업데이트는 고빈도 위치 변경을 효율적으로 처리하고, 사용자에게 실시간으로 반영되도록 하는 것이 중요합니다. 이를 위해 웹소켓과 Redis pub/sub를 활용한 아키텍처를 설계할 수 있습니다.

   * 개략적 설계안:**

     - **웹소켓 연결 유지:** 각 클라이언트는 웹소켓 연결을 지속적으로 유지하여 실시간으로 위치 정보를 전송하고, 실시간 업데이트를 수신합니다.

     - **Redis 캐시 사용:** 활성 상태 사용자의 최신 위치 정보를 Redis에 캐시하고, TTL을 설정하여 비활성 상태 사용자를 자동으로 관리합니다.

     - **Redis Pub/Sub:** 웹소켓 서버는 Redis Pub/Sub을 사용하여 위치 정보 변경 이벤트를 브로드캐스트합니다. 특정 사용자의 위치가 변경되면 해당 사용자의 친구들에게 실시간으로 위치 업데이트를 전송합니다.

     - **비동기 처리:** 위치 정보 변경 이벤트는 병렬로 처리하여 높은 QPS를 효과적으로 관리합니다.

4. 웹소켓을 사용하여 실시간 위치 정보를 전송할 때의 주요 장점과 단점은 무엇인가요?

   * 장점:

     - **실시간 통신:** 클라이언트와 서버 간에 실시간으로 데이터를 주고받을 수 있습니다.
     - **양방향 통신:** 클라이언트와 서버가 자유롭게 데이터를 주고받을 수 있어 위치 정보 갱신에 유리합니다.
     - **효율적인 데이터 전송:** HTTP 요청/응답의 오버헤드 없이 지속적인 연결을 유지하여 효율적인 데이터 전송이 가능합니다.

   * 단점:

     - **스케일링 복잡성:** 대규모 동시 연결을 관리하기 위해 서버의 리소스와 아키텍처가 복잡해질 수 있습니다.

     - **상태 관리:** 웹소켓은 유상태이므로, 서버 간 상태 동기화 및 장애 시 복구가 어렵습니다.

     - **보안:** 지속적인 연결을 유지해야 하므로, 보안 취약점이 발생할 수 있으며, 인증과 권한 관리가 필요합니다.

5. 웹 소켓 서버가 Redis Pub/Sub을 통해 위치 정보 변경 이벤트를 처리할 때 발생할 수 있는 병목 현상을 어떻게 해결할 수 있나요?
   * **수평 확장:** 웹소켓 서버를 수평으로 확장하여 병목 현상을 분산시킵니다.
   * **비동기 처리:** 위치 정보 변경 이벤트를 비동기적으로 처리하여 서버의 응답성을 유지합니다.
   * **효율적인 메시지 브로드캐스팅:** Pub/Sub 메시지를 효율적으로 브로드캐스트하기 위해 메시지 필터링과 타겟팅을 최적화합니다.
   * **로드 밸런싱:** 메시지 브로드캐스팅 부하를 여러 Redis 인스턴스로 분산시켜 처리합니다.
   * **모니터링 및 튜닝:** Redis 및 웹소켓 서버의 성능을 지속적으로 모니터링하고, 필요에 따라 튜닝하여 병목을 최소화합니다.

6. Redis Pub/Sub 대신 사용할 수 있는 다른 메시징 시스템은 무엇이며, 그 장단점은 무엇인가요?

   * **Apache Kafka:**

     - **장점:** 높은 내구성과 확장성을 제공하며, 대용량 데이터 스트림을 효율적으로 처리할 수 있습니다. 메시지 보존 기능을 지원하여 데이터 유실을 방지합니다.
     - **단점:** 설정과 운영이 복잡하며, 실시간 메시지 전송에 Redis보다 지연 시간이 길 수 있습니다.

     **RabbitMQ:**

     - **장점:** 다양한 메시지 패턴과 플러그인을 지원하며, 신뢰성 높은 메시지 전달을 보장합니다.
     - **단점:** Redis Pub/Sub보다 성능이 낮을 수 있으며, 클러스터링과 확장이 다소 복잡할 수 있습니다.

     **Google Pub/Sub:**

     - **장점:** 클라우드 기반으로 관리가 용이하며, 자동 확장과 내결함성을 제공합니다.
     - **단점:** 클라우드 종속성이 있으며, 비용이 발생할 수 있습니다.

     **Erlang 기반 시스템 (예: Phoenix Channels):**

     - **장점:** 고도로 동시성 처리에 적합하며, 내결함성과 확장성이 뛰어납니다.
     - **단점:** Erlang 언어와 생태계에 대한 학습 곡선이 있으며, Redis Pub/Sub만큼 널리 사용되지 않습니다.

7. 근접성 서비스에서 핫 키(Hot Key) 이슈를 어떻게 해결할 것인가요?

   * 핫 키 이슈는 특정 키에 너무 많은 트래픽이 집중되어 Redis와 같은 데이터베이스에서 성능 저하를 유발하는 문제입니다. 근접성 서비스에서는 친구가 많은 사용자에게 핫 키 이슈가 발생할 수 있으므로 이를 효과적으로 해결해야 합니다.
   * **샤딩:** 사용자 ID를 기준으로 Redis를 샤딩하여 특정 샤드에 과도한 부하가 걸리지 않도록 합니다.
   * **제한된 친구 수:** 한 사용자가 가질 수 있는 친구 수에 상한을 설정하여 특정 키에 너무 많은 트래픽이 집중되지 않도록 합니다. 예를 들어, 페이스북은 상한값을 5,000명으로 설정합니다.
   * **다중 Redis 인스턴스 사용:** 핫 키를 여러 Redis 인스턴스로 분산시켜 부하를 분산 처리합니다.
   * **데이터 분할:** 친구 목록을 여러 키로 분할하여 각 키에 대한 부하를 분산시킵니다. 예를 들어, `user:{id}:friends:1`, `user:{id}:friends:2` 등으로 분할합니다.
   * **캐싱 전략 최적화:** 자주 조회되는 데이터는 캐시에 저장하고, 덜 조회되는 데이터는 캐시에서 제외하여 핫 키 문제를 완화합니다.
   * **비동기 처리:** 핫 키에 대한 업데이트 작업을 비동기적으로 처리하여 실시간 성능에 영향을 주지 않도록 합니다.

   7.1 핫 키 이슈를 사전에 예방하기 위한 설계 전략은 무엇인가요

   * **키 설계 최적화:** 키의 설계를 신중히 하여 특정 키에 트래픽이 집중되지 않도록 합니다. 예를 들어, 사용자 ID를 기준으로 고르게 분포된 키를 사용합니다.
   * **데이터 분할:** 데이터를 여러 키로 분할하여 특정 키에 과도한 부하가 걸리지 않도록 합니다.
   * **샤딩 전략:** 효과적인 샤딩 전략을 사용하여 데이터와 부하를 여러 샤드에 고르게 분산시킵니다.
   * **부하 모니터링:** 실시간으로 시스템의 부하를 모니터링하여 핫 키 이슈가 발생할 가능성이 있는지 사전에 감지합니다.
   * **지연 로딩:** 특정 키에 대한 요청이 급증할 경우, 일부 요청을 지연시키거나 분산 처리하여 시스템의 과부하를 방지합니다.
   * **비동기 처리:** 핫 키에 대한 작업을 비동기적으로 처리하여 실시간 성능에 영향을 주지 않도록 합니

8. 근접성 서비스에서 웹소켓 서버를 수평 확장하는 방법과 고려 사항은 무엇인가요?

소켓 서버를 수평 확장하는 것은 대규모 실시간 연결을 효율적으로 관리하기 위해 필수적입니다. 이를 위해 다음과 같은 방법과 고려 사항을 적용할 수 있습니다.

**수평 확장 방법:**

- **로드 밸런서 사용:** 로드 밸런서를 통해 클라이언트의 웹소켓 연결을 여러 서버에 분산시킵니다. 예를 들어, NGINX나 HAProxy를 사용하여 웹소켓 트래픽을 분산할 수 있습니다.
- **상태 비저장 서버 설계:** 웹소켓 서버를 상태 비저장으로 설계하여, 어떤 서버가 특정 클라이언트를 처리하더라도 다른 서버로 쉽게 전환할 수 있도록 합니다.
- **세션 고정:** 클라이언트의 세션을 특정 서버에 고정하여 지속적인 연결을 유지하고, 서버 간 세션 정보를 공유하지 않아도 되도록 합니다.
- **Redis Pub/Sub 또는 메시지 브로커 활용:** 서버 간에 메시지를 전달하기 위해 Redis Pub/Sub이나 Kafka 같은 메시지 브로커를 사용하여 실시간 이벤트를 동기화합니다.
- **자동 스케일링:** 클라우드 기반의 자동 스케일링 기능을 사용하여 트래픽 증가에 따라 웹소켓 서버를 자동으로 추가하거나 제거합니다.

**고려 사항:**

- **유상태 관리:** 웹소켓은 유상태 연결이기 때문에, 서버 간 상태 동기화가 필요할 수 있습니다. 이를 위해 Redis와 같은 공유 스토리지를 사용하여 상태 정보를 관리합니다.
- **세션 지속성:** 클라이언트의 웹소켓 연결이 특정 서버에 지속적으로 유지되도록 세션 지속성을 보장해야 합니다.
- **장애 복구:** 특정 서버가 장애가 발생했을 때, 연결된 클라이언트를 다른 서버로 원활하게 전환할 수 있도록 설계합니다.
- **리소스 할당:** 각 웹소켓 서버에 충분한 CPU와 메모리를 할당하여 높은 동시 연결을 처리할 수 있도록 합니다.
- **보안:** 웹소켓 연결의 보안을 강화하기 위해 SSL/TLS 암호화를 적용하고, 인증 및 권한 관리를 철저히 합니다.
- **모니터링:** 웹소켓 서버의 성능과 상태를 지속적으로 모니터링하여 이상 징후를 신속하게 감지하고 대응할 수 있도록 합니다.

9. 웹소켓 서버를 수평 확장할 때 상태 동기화를 어떻게 효율적으로 관리할 수 있나요?

**답변:** 웹소켓 서버를 수평 확장할 때 상태 동기화를 효율적으로 관리하기 위해 다음과 같은 방법을 사용할 수 있습니다:

- **공유 스토리지 사용:** Redis와 같은 인메모리 데이터베이스를 사용하여 서버 간에 상태 정보를 공유합니다. 예를 들어, 사용자 상태나 친구 목록을 Redis에 저장하고, 모든 서버에서 이를 참조할 수 있도록 합니다.
- **메시지 브로커 활용:** RabbitMQ나 Kafka와 같은 메시지 브로커를 사용하여 서버 간에 상태 변경 이벤트를 전달하고, 각 서버가 이를 구독하여 최신 상태를 유지할 수 있도록 합니다.
- **분산 캐시:** Memcached와 같은 분산 캐시를 사용하여 상태 정보를 빠르게 조회하고 업데이트할 수 있도록 합니다.
- **상태 복제:** 각 웹소켓 서버에서 상태 정보를 로컬에 복제하여 사용하되, 주기적으로 중앙 스토리지와 동기화하도록 합니다.
- **Event Sourcing:** 이벤트 소싱 패턴을 적용하여 상태 변경을 이벤트로 기록하고, 서버가 이를 재생하여 최신 상태를 유지하도록 합니다.



# 3장 구글 맵

사용자와 목적지가 경로를 찾을 수 있도록 돕는다. 2021년 3월 기준 DAU 10억명이다.

매일 2500만건의 업데이트를 반영한다. 매우 엄청나게 복잡한 제품이므로 어떤 기능에 초점을 맞추어야 하는지 확인해야 한다

## 1단계 문제 이해 및 설계 범위 확정

주 단말은 모바일 스마트폰이다.

주 기능 요구사항.

* 사용자 위치 갱신
* 경로 안내 서비스 (ETA 서비스 포함)
* 지도 표시 

비기능 요구사항 및 제약사항

* 정확도
* 부드러운 경로 표시
* 데이터 및 배터리 사용량 최소

### 지도 101

지구는 축을 중심으로 회전하는 구(sphere)다. 위경도 기반 측위 시스템의 경우 최상단 북극, 최하단 남극이 있다. 

위도는 위아래, latitude, 경도는 동, 서 longitude이다

### 3차원 위치의 2차원 변환

3차원 구의 위치를 2차원 평면에 대응시키는 절차를 지도 투영법이라고 한다.

실제 지형의 기하학적 특성을 왜곡한다는 공통점을 갖는다.

![image-20241221161220195](./images//image-20241221161220195.png)

구글맵은 메르카토르 도법을 조겸 변경한 웹 메르카토르 도법을 택하고 있다. 

### 지오코딩

주소를 지리적 측위 시스템의 좌표로 변환하는 프로세스다.지오코딩 결과를 반대로 주소로 변환하는 프로세스는 리버스 지오코딩이라고 한다.

### 경로 안내 알고리즘을 위한 도로 데이터 처리 

대부분의 경로 탐색 알고리즘은 다익스트라나 A* 알고리즘의 변종이다 

* 다익스트라 : **가중치 그래프**에서 **단일 출발지로부터 다른 모든 노드까지의 최단 경로**를 찾는 알고리즘. 탐욕 알고리즘의 일종
* A 경로 탐색 : **휴리스틱(Heuristic)** 정보를 이용하여 **최적의 경로**를 찾는 알고리즘. 다익스트라 알고리즘 기반, 그래프 탐색 알고리즘.

중요한것은 모든 경로 탐색 알고리즘은 교차로를 노드로, 도로는 엣지로 표현한다.

경로 탐색 알고리즘의 성능은 주어진 그래프 크기에 아주 민감하다. 메모리도 많이 필요하고 성능도 만족스럽지 않을것이다.

좋은 성능을 위해서는 그래프를 관리 가능 단위로 분할해야 한다. 

지오해싱과 같은 비슷한 분할기술을 적용하여 세계를 작은 격자로 나누고 격자 안의 도로망을 노드와 선으로 구성된 그래프 자료구조로 변환한다. 각 격자는 경로 안내 타일이라 한다. 각 안내 타일은 도로로 연결된 다른 타일에 대한 참조를 유지한다.

도로망을 경로 안내 타일로 분할해 놓으면 경로 탐색 알고리즘이 동작하는데필요한 메모리 요구량을 낮출 수 있을 뿐 아니라 한번에 처리해야 하는 경로의 양도 줄어든다 

![image-20241221163553673](./images//image-20241221163553673.png)

### 계층적 경로 안내 타일

경로 안내 타일이 너무 구체적이고 작게 쪼개져 있으면 거대해지며 메모리를 많이 사용하게 된다. 

그래서 구체성 정도를 상, 중 하로 구분하여 경로 안내 타일을 준비한다

* 상 : 아주 작은 타일, 중 : 비교적 큰 관할구를 잇는 간선 도로, 하 : 더 큰 영역 주요 고속도로 등 

### 개략적 규모 추정

도량형 변환 규칙을 참고하자.

* 1피트 = 0.3048 미터
* 1km : 0.6214 마일
* 1km : 1,000 미터

### 저장소 사용량

3가지 종류의 데이터를 저장해야 한다

* 세계 지도
* 메타 데이터 
* 도로 정보 : 외부에서 받은 수 TB 용량



#### 세계지도

지원하는 zoom level 별로 지도 타일 한벌씩 두어야 한다. 21번 확대하여 볼 수 있으려면 4.4조개의 타일이 필요하다. 

타일 한장이 256 x 256 png라면 한장당 100kb = 4.4 조 x 100kb = 440 PB

* 그러나 이들 중 90%는 인간이 살지 않는 자연 그대로의 지역이다. 즉 압축이 가능하다  -> 44 PB ~ 88PB

#### 서버 대역폭

서버 처리 요청은 크게 2가지다 

1. 경로 안내 요청
2. 위치 갱신 요청 -> 경로 안내를 진행하는 동안 변경된 사용자 위치를 전송하는 메시지



DAU는 10억이고 경로 안내 기능을 평균적으로 주당 35분 사용한다고 하면

주 350억 분, 하루 35억분.

GPS 좌표를 매초 전송하면 하루 3000억 건의 요청(50억 분 / 일  x 60 초/분 ) = 300만 QPS

15초마다 한번만 보낸다면, 300 / 15 = 20만 QPS. 최대 QPS는 5배로 100만 QPS를 잡아보자

## 2단계 개략적 설계안 제시 및 동의 구하기

![image-20241221170510124](./images//image-20241221170510124.png)

다음 세가지 기능을 제공한다.

1. 위치서비스
2. 경로 안내 서비스
3. 지도 표시



위치 서비스는 사용자의 위치를 기록하는 역할을 담당한다.

주기적으로 위치 정보 전송시, 데이터를 이용하여 실시간 교통상황 모니터링이 가능하다.

또한 데이터베이스는 어마어마하게 많은 쓰기 요청을 처리해야하므로, 쓰기 요청 빈도에 최적화 되어있꼬 규모 확장에 용이한 아파치 카산드라 같은 데이터베이스가 필요하다. 

### 경로 안내 서비스

사용자가 보낸 경로 안내 서비스 요청에 출발지와 목적지가 인자로 전달된다

```
GET /v1/nav?origin=1355+market+street, SF&destination=Disneyland
```

### 지도 표시

확대 수준별로 한벌씩 지도 타일을 저장하려면 수백 PB가 필요한데, 그 모두를 클라이언트가 가지면 실용적인 방법이 아니다. 확대 수준에 따라 필요한 타일을 서버에서 가져오는것이 바람직하다.

클라이언트는 언제 타일을 서버에서 가져오는가?

* 지도 확대 및 이동시키며 주변 탐색
* 경로 안내가 진행되는동안 사용자의 위치가 현재 지도 타일을 벗어나 인접한 타일로 이동할 때 



선택지 1 : 클라이언트가 보는 지도의 확대 수준에 근거하여 지도 타일을 즉서에서 만드는 방안

* 지도 타일을 동적으로 만들어야 하는 서버에 부하, 캐시 활용 불가

선택지 2 : 확대 수준별로 미리 만들어 둔 지도 타일을 클라이언트에 전달

현재 확대 수준에 근거하여 필요한 지도 타일 집합을 결정한 후 각 위치를 지오해시 URL로 변경하여 이미지를 CDN으로 내린다. CDN은 캐시여서, 다른 사용자가 같은 파일을 요청하면 CDN은 캐시에 보관한 사본을 서비스한다.

또한 클라이언트에도 캐시를 두면 데이터 사용량을 많이 줄일 수 있다. 

> 데이터 사용량
>
> 사용자가 30km/h 속도로 이동중이며 한 이미지가 200m x 200m 영역을 표현한다
>
> 1km x 1km 영역 표현하려면 25장이 필요.
>
> 100 kb * 25 = 2.5mb이고, 30km/h는 시간당 2.5x 30 = 75mb가 필요하며
>
> 분당 1.25mb가 필요하다

CDN 데이터 사용량 추정

>
>
>50억분 가량의 경로 안내 처리
>
>대략 분당 1.25  mb 이므로 50억분 x 1.25 mb = 6.25PB/일
>
>초당 전송해야 하는 지도 데이터의 양은 대략 72.34 gb다.
>
>OP는 데이터 센터, 서버, 라우터, 스위치, 그리고 기타 네트워크 장비로 구성된 네트워크의 접점으로 이걸 이용하면 각 수백 MB 의 트래픽만 처리하면 됀다. 

## 3단계 상세 설계

### 데이터 모델

4가지 데이터를 취급한다.

경로안내 타일, 사용자 위치, 지오코딩 데이터, 미리 계산해둔 지도 타일 데이터

#### 경로 안내 타일

이 데이터는 방대한 양의 도로 및 메타데이터로 구성된다. 이 데이터는 외부 사업자나 기관이 제공한것을 이용하므로 가공이 필요하다. 또한 해상도를 달리 하여 세 벌을 만들고, 각 타일에 노드와 선분으로 표현된 해당 지역 내 교차로와 도로 정보를 넣는다. 다른 타일의 도로와 연결되는 경우 해당 타일에 대한 참조 정보도 포함된다. 

경로 안내 타일 처리 서비스는 타일을 어디에 저장해야 할까?

그래프 데이터는 메모리에 인접리스트 형태로 보관하는것이 일반적이지만, 양이 너무 많다.

S3같은 객체 저장소에 파일을 보관하고 지오해시 기준으로 분류해두는것이 좋다.

그리고  그 파일을 이용할 경로 안내 서비스에서 캐싱하는것이 좋다. 그래야 위도 경도 주어질 시 타일을 신속하게 찾는다. 

#### 미리 계산해둔 지도 타일 데이터

경로 안내 타일과 마찬가지로 확대 수준별로 미리 만들어놓고 CDN을 통해 저장한다. 원본은 S3에 저장한다. 

### 위치 서비스

사용자 위치 데이터저장에는 키-값저장소를 활용한다.

초당 백만건의 위치 정보 업데이트가 발생한다는 점을 감안하면 쓰기 연산 지원에 탁월한 데이터 베이스가 필요하다. 

사용자 위치는 계속 변화하며 변경되고 나면 이전 정보는 무용해지기 때문에 일관성 보다는 가용성이 중요하다.

높은 가용성을 보장하면서 막대한 규모의 연산을 감당해주는 디비는 카산드라다.

키 값으로 user_id, timestamp 조합을 사용하며, 매달리는 값으로 위경도 쌍을 저장한다.

user_id는 파티션키, timestamp는 클러스터링 키로 활용한다. 

### 사용자 위치데이터

사용자 위치 데이터를 이용해서 실시간 교통현황을 파악하는 입력이 될 수도 있다.

사용자 위치를 카프카와 같은 메시지 큐에 로깅한다. 경로 안내 타일 처리 서비스는 해당 변경 내역을 객체 저장소의 경로 안내 타일에 반영함으로써 지도 품질을 개선한다.

![image-20241221181852744](./images//image-20241221181852744.png)

### 지도 표시

지도 타일 미리 만들어놓는 방법과 최적화 기법

지도 표시에 WebGL(웹 그래픽 라이브러리)을 이용해서 벡터 정보를 보내면 이미지에 비해 월등히 압축해서 네트워크 대역폭을 아낄 수 있고 매끄러운 지도 확대 경험을 얻을 수 있다. 

### 경로 안내 서비스

가장 빠른 경로를 안내하는 역할을 담당한다.

<img src="./images//image-20241222141225784.png" width = 450 height = 450>

#### 지오코딩서비스

주소를 위도와 경도 쌍, 위경도를 주소로 바꿔주는 API 서비스

#### 경로 계획 서비스

현재 교통상황과 도로 상태에 입각하여 최적화된 경로 제안.

#### 최단 경로 서비스

출발지와 목적지의 위경도를 받아 k개 최단 경로를 반환하는 서비스. 도로 구조에만 의존하여 계산 수행한다.

#### 예상 도착 시간 서비스

경로 계획 서비스는 최단 경로 목록 수신시 ETA Service를 호출하여 소요시간 추정치를 구한다. 

#### 순위 결정 서비스

경로 계획 서비스는 ETA 예상치를 구하고 나면 순위 결정 서비스에 괄년 정보를 모두 전달하여 사용자가 정의한 필터링 조건을 적용한다. 

#### 전송 프로토콜

데이터를 클라이언트에 전송할 방법이 필요하다.

모바일 푸시알림, 롱 폴링, 웹소켓, SSE 등이 있다.

* 모바일 푸시알림은 메시지 크기가 최대 4096바이트로 제한적이고, 웹 애플리케이션은 지원하지않는다
* 웹소켓은 서버에 주는 부담이 크지 않아서 일반적으로 롱 폴링보다 좋은 방안으로 본다
* 그러므로 웹소켓과 SSE가 있는데, 웹소켓이 양방향 통신을 지원해서 더 좋다. 

## 면접 질문

1. 대규모 사용자 기반을 가진 위치 서비스에서 사용자 위치 데이터를 효율적으로 저장하고 처리하기 위해 어떤 데이터베이스를 선택하시겠습니까? 그 이유는 무엇인가요?

사용자 위치 데이터를 저장하기 위해서는 높은 쓰기 처리량과 확장성이 중요한 요소입니다. 이러한 요구사항을 충족하기 위해 Apache Cassandra와 같은 분산형 키-값 저장소를 선택하겠습니다. Cassandra는 높은 가용성과 무중단 확장을 지원하며, 대량의 동시 쓰기 요청을 효율적으로 처리할 수 있습니다. 또한, 사용자 위치 데이터는 지속적으로 업데이트되므로 일관성보다는 가용성이 더 중요하기 때문에 Cassandra의 설계가 적합합니다.

2. Cassandra를 사용하면서 데이터 일관성을 어떻게 관리하시겠습니까? 그리고 가능하다면 다른 대안과 비교해보세요.

   **답변:**
   Cassandra는 최종 일관성(Eventual Consistency)을 제공하지만, 필요에 따라 일관성 수준을 조정할 수 있습니다. 예를 들어, 읽기 및 쓰기 요청 시 일관성 레벨을 설정하여 특정 수준의 일관성을 보장할 수 있습니다. 다른 대안으로는 MongoDB가 있지만, Cassandra는 쓰기 성능과 확장성 면에서 더 뛰어납니다. 또한, Redis와 같은 인메모리 데이터베이스는 속도는 빠르지만, 데이터 영속성 측면에서 Cassandra보다 제한적일 수 있습니다.

3. 지도 데이터와 실시간 경로 안내 정보를 클라이언트에 전송하기 위한 최적의 전송 프로토콜은 무엇이라고 생각하시나요? 그 이유를 설명해주세요.

   **답변:**
   웹소켓(WebSocket)을 최적의 전송 프로토콜로 선택하겠습니다. 웹소켓은 클라이언트와 서버 간의 양방향 통신을 지원하며, 지속적인 연결을 유지하여 실시간 데이터 전송에 유리합니다. 이는 경로 안내 서비스에서 사용자의 위치 업데이트와 실시간 경로 변경 정보를 신속하게 전달하는 데 효과적입니다. 또한, 웹소켓은 롱 폴링보다 서버 자원을 효율적으로 사용할 수 있어 대규모 사용자 기반에서도 성능을 유지할 수 있습니다.

   **꼬리 질문:**
   웹소켓을 사용할 때 발생할 수 있는 네트워크 문제는 무엇이며, 이를 어떻게 해결할 수 있을까요?

   **답변:**
   웹소켓을 사용할 때 발생할 수 있는 네트워크 문제로는 연결 유지에 따른 서버 부담 증가, 방화벽이나 프록시 서버에서의 차단, 네트워크 지연 및 패킷 손실 등이 있습니다. 이를 해결하기 위해 다음과 같은 방안을 고려할 수 있습니다:

   1. **서버 부하 관리:** 로드 밸런싱과 서버 클러스터링을 통해 웹소켓 연결을 효율적으로 분산 처리합니다.
   2. **재연결 로직:** 클라이언트 측에서 연결이 끊어졌을 때 자동으로 재연결을 시도하는 로직을 구현합니다.
   3. **보안 설정:** SSL/TLS를 사용하여 웹소켓 연결을 암호화하고, 필요한 경우 특정 포트를 열어 방화벽 문제를 최소화합니다.
   4. **데이터 압축:** 전송 데이터를 압축하여 네트워크 대역폭 사용을 최적화하고, 패킷 손실의 영향을 줄입니다.

4. 모바일 단말기에서 지도 서비스를 제공할 때 데이터 및 배터리 사용량을 최소화하기 위한 주요 전략은 무엇인가요?

   **답변:**
   데이터 및 배터리 사용량을 최소화하기 위해 다음과 같은 주요 전략을 사용할 수 있습니다:

   1. **데이터 압축 및 최적화:** 전송되는 지도 데이터와 위치 업데이트 데이터를 압축하여 데이터 사용량을 줄입니다. 벡터 타일을 사용하여 이미지 기반 타일보다 더 작은 데이터 크기를 유지할 수 있습니다.
   2. **효율적인 위치 갱신:** GPS 업데이트 주기를 조절하고, 필요 시에만 위치를 갱신하여 배터리 소모를 줄입니다. 예를 들어, 이동 속도나 거리 변화에 따라 위치 업데이트 빈도를 동적으로 조정합니다.
   3. **캐싱 활용:** 클라이언트 측에 지도 타일을 캐싱하여 동일한 데이터를 반복적으로 다운로드하지 않도록 합니다. 이는 데이터 사용량과 네트워크 트래픽을 줄이는 동시에 배터리 소모를 감소시킵니다.
   4. **백그라운드 처리 최적화:** 백그라운드에서 실행되는 작업을 최소화하고, 필요한 경우에만 활성화하여 배터리 사용을 줄입니다.
   5. **전력 효율적인 알고리즘:** 지도 렌더링 및 경로 탐색 알고리즘을 최적화하여 CPU와 GPU 사용을 최소화합니다.
   6. **네트워크 연결 최적화:** Wi-Fi와 모바일 데이터 간의 전환을 최적화하고, 네트워크 요청을 효율적으로 관리하여 배터리 소모를 줄입니다.

# 4장 분산 메시지 큐



# 5장 지표 모니터링 및 경보 시스템



# 6장 광고 클릭 이벤트 집계



# 7장 호텔 예약 시스템



# 8장 분산 이메일 서비스



# 9장 S3와 유사한 객체 저장소



# 10장 실시간 게임 순위표



# 11장 결제 시스템



# 12장 전자 지갑



# 13장 증권 거래소