# 데이터 중심 애플리케이션 설계

* https://github.com/ept/ddia-references 에서 항상 레퍼런스를 볼 수 있다. 

데이터 양, 복잡성, 데이터 변하는 속도 등 데이터가 주요 도전 과제인 애플리케이션을 데이터 중심적이 라고 말한다.

CPU 사이클이 병목인 경우 계산 중심적 이라고 함. 



# 1장 신뢰할 수 있고 확장 가능하며 유지보수 하기 쉬운 애플리케이션

현대 많은 애플리케이션은 cpu 계산 대신 데이터 중심적으로, 데이터 양 때문에 문제가 생김

많은 애플리케이션은 다음과 같은 컴포넌트를 필요로 함

* 데이터베이스 : 데이터 저장

* 캐시 : 읽기 속도 향상을 위한 수행 결과를 기억
* search index : 키워드로 빠르게 데이터 검색
* 스트림 처리 : 비동기 처리를 위한 다른 프로세스의 호출
* 배치 처리 : 대량의 데이터를 분석

대부분의 소프트웨어 시스템에서 중요하게 여기는 3가지 관심사

* 신뢰성 : 시스템은 어떤 일이 있어도 지속적으로 올바르게 동작해야 함 
* 확장성 : 데이터 양, 트래픽 양, 복잡도가 증가해도 이를 적절하게 처리할 수 있어야 함 
* 유지보수성  : 현재 작업을 유지보수하고 새로운 사례를 시스템에 적용할 수 있어야 함

## 신뢰성(Reliability)

소프트웨어의 경우 100% 오류 없이 동작하는 경우는 없으므로 올바르게 동작함이란건 무언가 잘못되더라도 지속적으로 올바르게 동작함으로 해석 할 수 있다.

용어

* 결함(fault ) : 잘못될 수 있는 일.
* 내결함성 또는 탄력성 : 결함을 예측하고 대처할 수 있는 시스템
  * 내결함성을 이야기할때 모든 종류의 결함을 견딜 수 있는 시스템은 절대 없다.

결함 != 장애. 결함은 사양에서 벗어난 시스템의 한 구성 요소지만, 장애는 시스템 전체가 멈춘 경우.

넷플릭스에서 개발한 도구인 카오스 몽키는, 시스템의 내결함성을 테스트하는 도구로, 실제 운영 환경에서 무작위로 서버나 인스턴스를 종료시켜, 예상치 못한 장애 상황에 시스템이 어떻게 반응하는지 확인할 수 있도록 도와준다.

### 하드웨어 결함

하드디스크의 평균 장애시간은 10~50년. 10,000개의 디스크로 구성된 클러스터는 평균 하루에 1개씩 죽음. 

* 이말이 무슨뜻이냐면, 개별 디스크의 수명은 길지만 대량의 하드디스크 운영시 매일 고장날 확률이 높다는것

데이터 양이 늘어나면서 더 많은 수의 장비가 필요해졌고, 이는 하드웨어 결함율을 높이게 됌 

이런 하드웨어 결함은 하드웨어 중복성을 추가해 전체 장비의 손실을 견딜 수 있는 시스템으로 점점 변하고 있다.

그리고 소프트웨어 오류보다는 오류 처리가 더 쉽다

### 소프트웨어 오류

시스템 내 오류는 하드웨어 결함보다 더 오류를 많이 유발하며 예상하기 어렵다.

* 리눅스 커널 버그, 공유 자원 과도 서비스, 동시성 문제, 매우 느린 응답 서버, 연쇄 장애

이런 버그들은 신속한 해결책이 없다. 

때문에

* 시스템 상호작용 주의 깊게 생각하기, 빈틈없는 테스트, 프로세스 격리, 프로세스 재시작, 모니터링

등으로 문제 해결을 해야만 한다

## 확장성

동시 사용자 수가 많아질수록 현재 시스템이 미래에도 안정적으로 동작한다는 보장은 없음.

확장성은 증가한 부하에 대처하는 시스템 능력을 설명함.

확장성을 논한다는 것은, 시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택이나 추가 부하를 다루기 위해 자원을 어떻게 투입할까 같은 질문을 고려한다

### 부하 기술하기

시스템의 현재 부하를 간결하게 계산 및 기술하여 부하가 몇배로 늘어날 경우 어떻게 될건지 논의 가능.

부하는 부하 매개변수라고 부를 숫자로 나타냄

* 웹 서버 초당 요청 수, 읽기 쓰기 비율, 동시 활성 사용자 수, 캐시 적중률 등이 될 수 있음.

2012년 트위터 데이터 토대로 계산 예시

* 트윗 작성 : 평균 초당 4.6k, 피크 초당 12k

초당 12,000건의 쓰기 처리는 쉽지만, 트위터의 트윗은 패아웃 방식으로 다수의 팔로워에게 전파되는 문제가 있음.

개별 사용자는 많은 사람을 팔로우 하고, 많은 사람이 개별 사용자를 팔로우 함.

2가지 방법

1. 트윗 작성시 전역 트윗 컬렉션에 삽입. 사용자가 자신의 홈 타임라인 요청시 팔로우하는 모든 사람을 찾고, 모든 트윗을 찾아 시간순으로 정렬해서 합침 

```sql
SELECT 
    tweets.*, 
    users.* 
FROM tweets
JOIN users ON tweets.sender_id = users.id
JOIN follows ON follows.followee_id = users.id
WHERE follows.follower_id = current_user;
```

2. 각 사용자용 타임라인을 만들고, 사용자가 트윗작성시, 해당 사용자를 팔로우하는 모든 사람을 찾아 각자의 타임라인에 새 트윗 삽입

![image-20250314170823166](./images//image-20250314170823166.png)

트위터는 초기 접근 방식 1을 사용, 그러나 유저가 늘어날수록 질의 부하가 어렵기 때문에 접근방식 2로 전환(각 사용자용 타임라인에 쓰기) 함.

근거: 트윗 게시 쓰기 요청량이 홈 타임라인 읽기 요청량보다 수백배 적음. 즉 쓰기 시점에 더 많은일을 하고, 읽기 시점에 적은일을 하게 함

> 잠깐, fan out의 종류
>
> 팬아웃(Fan-out)**이란, **한 사용자의 활동(예: 트윗 작성)이 다수의 팔로워에게 전파되는 방식**
>
> **쓰기 시 팬아웃(Write-time Fan-out)** → 데이터를 생성할 때 미리 전파
>
> * 데이터 생성시, 모든 수신자(팔로워)에게 복사하여 저장하는 방식 
>
> - 장점 : 팔로워가 타임라인 조회할때 빠름, 읽기부하 적음
> - 단점 : 팔로워 많을수록 쓰기부하 급증, 중복 데이터로 저장공간 증가 
> - 페이스북, 트위터(일반사용자)
>
> **읽기 시 팬아웃(Read-time Fan-out)** → 데이터를 가져올 때 전파
>
> * 읽기 요청 발생시에 그제서야 데이터를 불러오는 방식
> * 장점 : 쓰기 부하가 낮고, 팔로워 수가 많아도 부담 적음
> * 단점 : 팔로워가 타임라인 조회할때마다 DB 조회 부하 증가 
> * 트위터(셀럽계정), 인스타 피드조회 
>
> **하이브리드 팬아웃(Hybrid Fan-out)** → 상황에 따라 두 가지 방식을 조합
>
> * Write-time과 Read-time 팬아웃을 조합하여 최적화한 방식
> * 특정 기준(예: 팔로워 수, 인기도 등)에 따라 팬아웃 방식을 다르게 적용
>   * 일반 사용자는 **Write-time Fan-out** (팔로워가 적으므로 미리 저장)
>   * 셀럽이나 유명 계정은 **Read-time Fan-out** (팔로워가 많아서 실시간 조회)
>
> 트위터는 조합해서 사용함
>
> **팔로워가 적은 일반 유저** → **쓰기 시 팬아웃** (팔로워 타임라인에 미리 저장)
>
> **팔로워가 많은 유명인(셀럽)** → **읽기 시 팬아웃** (타임라인 조회 시 가져오기)
>
> - 예를 들어 **일론 머스크 같은 사용자가 트윗을 올리면**, 수천만 명의 타임라인을 업데이트하는 대신, **트윗 자체를 조회 시 불러오는 방식(Read-time Fan-out)을 사용**함.

그러나 적븐방식 2의 불리한점은, 트윗 작성이 많은 부가 작업을 필요로 함

* 평균 트윗이 75명의 팔로워에게 전달시, 초당 4.6k는 345k 쓰기.

* 팔로워 수가 늘어날수록 쓰기 부하는 당연히 늘어남.

그렇다면 사용자당 팔로워 분포랑 쓰기 량을 확인해서 팬아웃 부하를 줄여야 함. 

### 성능 기술하기

시스템 부하를 기술하면 부하 증가시 어떤일이 발생할지 조사 가능.

부하 매개변수: ex) 초당 4.6k, 피크 12k

* 부하 매개변수 증가시키고, CPU, 메모리 대역폭 등은 변경하지 않으면 시스템은 어떻게 될까
* 부하 매개변수 증가시, **성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까**.
  * 이것은 어떻게 조정하여 개선했다는 뜻임.

하둡같은 일괄 시스템은 초당 throughtput이 중요

온라인 서비스는 response time이 더 중요 



response time 생각시 고려할점

* 모든 요청이 다 매번 응답 시간이 다름. 때문에 단일 숫자 대신 측정 가능한 값의 **분포로 생각해야 함**

* 분포란, p95, p99 처럼 전체 응답 시간중 n퍼의 요청이 이 ms 내에 처리됨을 의미함 

  * 평균은 좋지 않음. 얼마나 많은 사용자가 실제로 지연을 경험했는지 알려주는 값이 아니기 떄문  
  * 평균(Mean)은 데이터의 **전체적인 중심값을 보여주지만**, **극단적인 값(아웃라이어, Outlier)의 영향을 많이 받기 때문에**임. 높은 평균이 나머지 아주 안좋은 값들을 평균처럼 끌어올림 

  * 때문에 백분위를 사용하는게 좋음. 가장 빠른시간부터 느린시간까지 쭉 정렬하고 사용. 예를들어 중간 응답 시간이 200 ms면 요청의 반이 200ms 미만으로 반환되고 나머지는 그거보다 오래걸린다는것. 

* 95, 99, 99.9 분위가 일반적임.

  * p95 가 1.5s라면 100개의 요청중 95개는 1.5s 미만이고 나머지는 그 이상 
  * 그렇다고 100%를 할 순 없는게, 0.1만 올리려고 해도 어마어마한 비용이 들 확률이 높아 트레이드 오프임 

queueing delay도 응답시간의 상당 부분을 차지함. 소수의 느린 요청 때문에 후속 요청 처리가 지체되는 현상을 head-of-line blocking 이라 함. 

때문에 시스템의 확장성을 테스트하는 부하테스트는 응답시간과 독립적으로 지속적으로 요청을 보내야 더 정확한 결과를 알 수 있음. 

### 부하 대응 접근 방식

부하 매개변수가 어느정도 증가하더라도 좋은 성능을 유지하려면?

아키텍처를 결정하는 요소는 읽기,쓰기 양, 저장할 데이터의 양, 데이터 복잡도, 응답 시간 요구사항, 접근 패턴 등이 있다.

예를 들어 각 크기가 1kB인 초당 100,000건의 요청을 처리하도록 설계한 시스템과 각 크기가 2GB인 분당 3건의 요청을 처리하기 위해 설계한 시스템은 서로 같은 데이터 처리량이라 해도 매우 다르다.

1. 초당 10만건의 경우

   * 특징 

     - 초당 100,000건 → **고처리량(High Throughput)**

     - 요청당 1KB → **작은 요청 크기(Small Payload)**

     - **높은 동시성(Concurrency) 필요**

     - 짧은 응답 시간(Low Latency) 요구 가능성 큼

   * **로드 밸런싱 (Load Balancing)**

     - 여러 애플리케이션 서버로 트래픽을 분산
     - **NGINX, Envoy, HAProxy** 같은 L7 로드 밸런서 사용
     - 필요하면 **L4 로드 밸런서**(AWS ELB, GCP Load Balancer) 도입

     **비동기 처리 (Asynchronous Processing)**

     - 웹 서버에서 직접 처리하지 않고 **메시지 큐(Kafka, RabbitMQ, Redis Streams)** 에 태우고 백엔드에서 비동기 처리
     - 응답 속도가 중요한 경우 **빠른 응답 후 백그라운드 처리**

     **수평 확장 (Horizontal Scaling)**

     - 애플리케이션 서버를 여러 대 배포하여 병렬 처리
     - **Kubernetes(K8s) 기반의 오토스케일링(Auto-scaling)**
     - 무상태(Stateless) 설계 → 서버 간 부하 분산 용이

     **효율적인 DB 설계**

     - **읽기/쓰기 분리 (Read/Write Splitting)** → 읽기 요청이 많다면 **레플리카 DB(Read Replica)** 활용
     - **캐싱 (Redis, Memcached)** → 자주 조회되는 데이터는 DB 부하 감소
     - **Sharding (분할 저장)** 고려

     **고성능 네트워크 설계**

     - HTTP/2 또는 gRPC 사용 → 작은 요청을 빠르게 처리하는데 유리
     - 커넥션 풀링(Connection Pooling)으로 TCP 오버헤드 감소

     **로그 및 모니터링**

     - **Prometheus, Grafana, ELK Stack(Elasticsearch, Logstash, Kibana)** 사용
     - 높은 트래픽에서 장애 탐지를 위해 **분산 트레이싱(OpenTelemetry, Jaeger)** 도입

2. 분당 3건 요청 (각 크기가 클때)

   * 특징

     - 분당 3건 → **낮은 요청 빈도**

     - 요청당 2GB → **대용량 데이터 전송(High Payload)**

     - 실시간성이 중요하지 않을 가능성 큼

     - 데이터 무결성(Data Integrity) 보장이 중요할 가능성이 높음

   * **전용 대역폭 및 네트워크 튜닝**
     - HTTP보다는 **gRPC, WebSocket, 또는 FTP/SFTP** 방식 활용 가능
     - 대량 데이터 전송을 위해 **MTU 조정 및 TCP 튜닝** 수행
     - 필요 시 **CDN(Content Delivery Network) 활용**하여 전송 최적화
   * **Chunking(청킹) 및 스트리밍 처리**
     - 대량 데이터를 한 번에 보내는 것이 아니라 **스트리밍 방식** 적용
     - HTTP/2, gRPC Streaming, WebRTC DataChannel 같은 프로토콜 사용
     - 파일 업로드의 경우 **멀티파트 업로드 (AWS S3 Multipart Upload 등)** 고려
   * **스토리지 및 데이터 무결성 보장**
     - 대용량 데이터를 저장하기 위해 **분산 스토리지 (Ceph, HDFS, MinIO)** 활용
     - 데이터 무결성을 위해 **파일 해시(Hash, Checksum) 검증** 추가
   * **배치 처리 및 오프로드**
     - 요청이 많지 않다면 **배치 처리(Batch Processing) 또는 예약된 작업(Cron, Airflow)** 활용
     - 실시간이 필요 없다면 **데이터 수집 후 비동기 분석**
   * **데이터 전송 최적화**
     - **압축(Compression)**: Zstandard(Zstd), Gzip 등 적용
     - **데이터 전송 프로토콜 최적화**: HTTP Keep-Alive, QUIC, TLS 튜닝
   * **로깅 및 장애 감지**
     - 장애 발생 시 **재전송(Retry) 및 체크포인트(Checkpointing) 지원**
     - **ELK, Loki, Prometheus** 로 대형 데이터 처리의 병목 감지

## 유지보수성

모두 레거시 시스템 유지보수를 각자의 이유로 싫어한다. 때문에 다음과 같이 설계하여 고통을 최소화 하는것이 좋다

* 운용성 : 운영팀이 시스템을 원활하게 운영할 수 있게
* 단순성 : 복잡도를 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게
* 발전성 : 쉽게 변경할 수 있도록 해야 함.



### 운용성

운영 중 일부 측면은 자동화 해야 하며, 시스템이 지속해서 원활하게 작동하려면 운영팀이 필수다. 다음과 같은 내용을 참고해서 자동화 혹은 시스템을 구축해보자.

- ﻿﻿좋은 모니터링으로 런타임(runtime) 동작과 시스템의 내부에 대한 가시성 제공
- ﻿﻿표준 도구를 이용해 자동화와 통합을 위한 우수한 지원을 제공

- ﻿﻿개별 장비 의존성을 회피, 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함.
- ﻿﻿좋은 문서와 이해하기 쉬운 운영 모델(예를 들어 "X를 하면 Y가 발생한다") 제공
- ﻿﻿만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여
- ﻿﻿적절하게 자기 회복(sell-healing)이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함
- ﻿﻿예측 가능하게 동작하고 예기치 않은 상황을 최소화함



## 정리

애플리케이션이 유용하려면 다양한 요구사항을 충족시켜야 함.

자주 나오는 용어로

* 기능적 요구사항 
  * 필요한 기능, 저장 조회 검색 등
* 비기능적 요구사항
  * 보안, 신뢰성, 법규 준수, 확장성, 호환성, 유지보수성 

신뢰성은 결함이 발생해도 올바르게 동작한다는 의미

확장성은 부하가 증가해도 좋은 성능을 유지하기 위한 전략.

유지보수성은 엔지니어와 운영 팀의 삶을 개선하는데 있음. 



# 2장 데이터 모델과 질의 언어

대부분 애플리케이션은 하나의 데이터 모델을 다른 데이터 모델 위에 계층을 둬서 만든다. 각 계층의 핵심적인 문제는 다음 하위 계층 관점에서 데이터 모델을 표현하는 방법이다.

예를들면

* 애플리케이션 개발자는 실 사물을 보고 객체나 데이터 구조, 그리고 데이터 구조를 다루는 API를 모델링함
* 데이터 구조 저장시 JSON, XML, 테이블,  그래프 모델 같은 모델로 표현
* DB를 개발하는 엔지니어는 위 데이터를 메모리나 디스크 또는 네트워크 상의 바이트 단위로 표현하는 방법을 결정한다. 이 표현은 다양한 방법으로 데이터를 질의 탐색 조작 처리할 수 잇게 한다
* 하드웨어 엔지니어는 전류, 빛의 파동, 자기장 등의 관점에서 바이트를 표현하는 방법을 알아냇다.

즉, 우리가 애플리케이션에서 다루는 데이터가 **다양한 계층을 거치면서 서로 다른 방식으로 표현되고 처리**되는 과정이 데이터 모델의 계층적 추상화이다.

관계형, 도큐먼트형, 그래프형 중 하나의 데이터 모델링도 어렵다. 그러나 데이터 모델은 데이터 모델 위에서 SW가 할 수 있는 일과 없는 일에 지대한 영향을 주므로, 적합한 데이터 모델을 선택하는 작업은 상당히 중요하다

## 관계형 모델과 문서 모델

관계형 모델의 목표는 정리된 인터페이스 뒤로 구현 세부 사항을 숨기는 것.

### NoSQL

NoSQL은 다음과 같은 이유들로 인해 채택이 된다. 

* 대규모 데이터셋이나 매우 높은 쓰기 처리량 달성을 RDBMS보다 쉽게 할 수 있는 확장성의 필요
* 상용 DB보다 무료 오픈소스 소프트웨어
* RDB에서 지원하지 않는 특수 질의 동작
* RDB 스키마의 제한에 대한 불만과 더 동적이거 표현력이 풍부한 데이터 모델의 바람

책에서는 나중에는 RDB가 NoSQL와 함께 폭넓게 사용될것이라 예상했고, 실제로 지금도 그렇다

### 객체 관계형 불일치

이력서를 표현할때는 RDB보다는 몽고디비 같은 JSON 모델이 적합하다.

또한 다중 테이블 조인을 해서 비용이 들지만 JSON은 한곳에 저장하니 조인 비용이 줄어든다. 

* 요즘은 RDB에도 JSON 컬럼을 지원

### 다대일과 다대다 관계

![image-20250315133802620](./images//image-20250315133802620.png)

위 사진을 보면, region_id와 industry_id는 평문인 '그레이터 시애틀 구역'과 '자선활동'이 아닌 id로 주어짐.

지리적 지역과 업계의 표준 목록을 제공할라면, 평문으로 저장되면 중복되므로, 따로 테이블을 만들어 관리할 수 있음.

 ID나 텍스트 문자열의 저장 여부는 중복의 문제임. 이런 중복을 제거하는 일이 RDB의 정규화 이면에 놓인 핵심 개념.

* 텍스트를 변경해도 해당 로우의 pk인 id는 변경할 필요가 없다.  

중복된 데이터를 정규화 하려면 다대일 관계가 필요하다. 그러나 도큐먼트 모델은 다대일에 적합하지 않다. 

* 몽고디비는 lookup을 조회하지만, 애초에 좋은 성능은 아니고, 보통 한번 더 조회해서 애플리케이션에서 조립하는 경우도 흔함

다대다 관계(M:N)는 **한 개체가 여러 개체와 연결될 수 있으며, 반대로 그 개체들도 여러 개체와 연결될 수 있는 관계**를 의미. 예시로 학생과 수업 관계가 있음.

- 한 학생은 여러 개의 강의를 들을 수 있음.
- 하나의 강의에는 여러 명의 학생이 참여할 수 있음.

서로 관계를 맺기 어려우므로, 다대다 관계를 표현하기 위해 **중간 테이블(조인 테이블, 매핑 테이블)**을 사용.

도큐먼트 모델은 2가지 방법이 있는데, 의도적으로 중복해서 임베디드 방식으로 내장하거나 아이디 값을 참조해야함

```json
// 학생 컬렉션
{
    "_id": "student_1",
    "name": "김영수",
    "course_ids": ["course_101", "course_102"]
}

// 강의 컬렉션
{
    "_id": "course_101",
    "title": "알고리즘 기초"
}
```

### 문서 데이터베이스는 역사를 반복하고 있나?

과거 1970년대 IBM의 IMS라는 시스템에서도 JSON 모델과 비슷하게 중첩된 트리 형식으로 DB 모델을 운영했었음.

IMS도 마찬가지로 일대 다는 쉽지만, 다대 다는 어려웠고 조인은 어려웠음. 때문에 개발자는 데이터를 중복할지 참조를 수동으로 해결할지 결정해야 했음. 

두드려지는 해결책은 관계형 모델과 네트워크 모델이였음.

#### 네트워크 모델

코다실이라 불리는 위원회에서 표준화해서 코다실모델이라고 부름. 1970년대에 하드웨어 성능이 낮았던 환경에서 **최적의 탐색 성능을 제공**하기 위해 고안되었지만, 코드의 복잡성과 유지보수 문제로 인해 점차 사용되지 않게 됌.

- **트리 구조를 확장하여 다중 부모(Multiple Parent)를 허용**.
- 즉, **하나의 레코드(데이터)가 여러 개의 부모를 가질 수 있음**.
- 레코드 간의 관계를 `포인터` 형태로 저장하여 **다대일(1:N), 다대다(M:N) 관계를 표현할 수 있음.**

예제.

```
Company
 ├── Department_A  ─── Employee_1
 │                  ├── Employee_2
 │
 ├── Department_B  ─── Employee_1
                     ├── Employee_3
```

- 여기서 **Employee_1은 Department_A와 Department_B에 동시에 속할 수 있음.**
- 데이터 중복이 없이 다대다 관계를 효과적으로 모델링 가능.

단점으로.

**질의(Query) 작성이 어려움**

- SQL 같은 질의 언어가 없고, **데이터 탐색을 직접 프로그래밍해야 함.**
- 데이터를 찾으려면 **포인터를 직접 따라가야 함**.

**경로가 없으면 데이터를 찾을 수 없음**

- 만약 기존 접근 경로로 찾을 수 없는 데이터가 필요하면?
- 새로운 경로를 만들기 위해 **데이터베이스 구조를 변경해야 함.**
- 예를 들어, 특정 직원이 속한 모든 부서를 빠르게 검색하는 기능이 필요하면 **데이터베이스 구조 자체를 변경해야 함.**

**데이터 모델 변경이 어렵고, 유지보수 복잡**

- 새로운 관계(예: 직원과 프로젝트 관계)를 추가하려면, 모든 기존 접근 경로를 다시 설계해야 함.
- 데이터베이스가 커질수록 유지보수 비용이 증가.

### 문서 데이터베이스와의 비교 - RDB와 Document DB

다대일과 다대다 표현시 RDB와 document는 근본적으로 다르지 않고 고유한 식별자로 참조함.

* RDB - 외래키, Document - document Reference

도큐먼트를 선호하는 주요 이유는 스키마 유연성과 지역성에 기인한 나은 성능 때문이다.

* 지역성(Locality)은 데이터가 **물리적으로 가까운 위치에 저장됨으로써 성능이 향상되는 개념**
* 도큐먼트 디비에서 조인 없이 임베디드 등으로 내장해버리므로 한번에 조회해서 성능이 향상됌. 
* 비정규화(Denormalization)**를 통해 관련 데이터를 한 도큐먼트에 저장하여 **공간 지역성과 시간 지역성을 극대화한것

> 읽기스키마 vs 쓰기 스키마
>
> 데이터베이스 모델링에서 **"읽기 스키마(Read Schema)"**와 **"쓰기 스키마(Write Schema)"**는 데이터의 **저장 방식과 조회 방식 간의 균형을 조정하는 전략
>
> 이 개념은 주로 **관계형 데이터베이스(RDBMS)와 NoSQL(특히 도큐먼트 모델)**을 비교할 때 등장.
>
> 쓰기스키마
>
> * 데이터가 **저장될 때** 스키마(데이터 구조)가 명확하게 정의됨.
>
>   **관계형 데이터베이스(RDBMS)**에서 사용되는 전통적인 방식.
>
>   데이터베이스가 **스키마를 엄격하게 강제**하며, 데이터가 스키마를 따라야 저장됨.
>
> **장점**
>
> - 데이터 구조가 명확하여 **일관성을 유지하기 쉬움**.
> - 데이터가 저장될 때부터 **무결성이 보장됨**.
>
>  **단점**
>
> - **유연성이 부족함** → 새로운 필드를 추가하려면 테이블 스키마를 변경해야 함.
> - **데이터 형식이 엄격하게 제한됨** → 데이터 구조가 자주 바뀌면 불편함.
>
>
> 읽기 스키마
>
> - 데이터가 저장될 때는 **스키마가 강제되지 않음**.
> - 데이터를 **읽을 때 해석하는 방식**.
> - **문서형 데이터베이스(NoSQL, MongoDB)**에서 많이 사용됨.
>
> **장점**
>
> - **유연성이 높음** → 데이터를 자유롭게 추가/변경할 수 있음.
> - **새로운 필드를 추가해도 기존 데이터를 변경할 필요 없음**.
>
> **단점**
>
> - **데이터 일관성이 떨어질 수 있음** → 일부 문서는 `email`이 있고, 일부 문서는 `preferences`가 있을 수도 있음.
> - **읽을 때 데이터 구조를 해석해야 하므로, 애플리케이션 코드에서 처리 로직이 복잡해질 수 있음**.

도큐먼트 모델의 스키마 유연성은 장점만있는게 아니다.

스키마가 없다는 것은, 임의의 키와 값을 문서에 추가할 수 있고, 읽을때 클라이언트는 문서에 포함된 필드의 존재 여부를 보장하지 않는다는 의미다.

도큐먼트 모델에서 읽었을때 데이터가 없다면 애플리케이션 코드에서 그냥 보정해주면 된다.

정적 타입의 RDB 스키마는 ALTER 등과 같은 문으로 컬럼을 추가해줘야 하는데, MySQL같은경우 컬럼 추가시 얼터 테이블을 사용하는데 전체 테이블 복사방식으로 동작 및 테이블 락도 걸리고 해서 너무 느리다.

또한, 읽기 스키마는 컬렉션 내의 도큐먼트들이 모두 동일한 구조가 아닐때 더 유리함.

* 스키마 변경시 마이그레이션 필요 없음.
* 필요한 필드만 저장할 수 있어, 데이터 저장 공간을 최적화할 수 있음

### 데이터를 위한 질의 언어

일반적인 프로그램 코드는 명령형 언어고, SQL은 선언형 질의 언어다.

명령형은 어떻게 가져올지 직접 명시해서 프로그래머가 세부적인 처리 과정을 직접 작성해야 한다. 즉 목표를 달성하기 위한 방법을 기술. 

선언형 질의 언어는, 무엇을 할지를 선언하는 방식으로, 결과가 충족해야 하는 조건과 데이터를 변환(정렬, 그룹화, 집계)를 할지 선언해서 가져오는것. 어떻게 데이터를 처리할지는 디비 엔진이 처리한다.

선언형 질의 언어는 더 쉽게 간결하게 작성할 수 있고, 엔진의 구현이 숨겨져 있어, 질의를 변경하지 않고도 DB성능을 향상시킬 수있는 장점이 있다.

#### 맵 리듀스 질의

맵 리듀스란 많은(분산) 컴퓨터에서 대량의 데이터를 처리하기 위한 프로그래밍 모델.

맵리듀스는 **"맵(Map)" 단계와 "리듀스(Reduce)" 단계**로 나뉘며, 대량의 데이터를 처리하는 **병렬 연산을 수행**

* map -> collect라고도 하고, reduce는 fold, inject 라고도 함

몽고 맵리듀스 예시

```
map 함수
var mapFunction = function() {
    emit(this.category, 1);
};

// reduce 함수
var reduceFunction = function(key, values) {
    return Array.sum(values);
};

// mapReduce함수
db.products.mapReduce(
    mapFunction,
    reduceFunction,
    { out: "category_counts" }
);

```

* 두 함수는 부수 효과 없는 순수 함수여야 함. 

몽고디비에서는 과거 map reduce를 지원했고, 요즘에는 선언형 질의 언어인 집계 파이프라인 지원을 추가함.

SQL의 `GROUP BY`, `SUM`, `COUNT` 같은 연산을 MongoDB에서 실행하는 방식이라고 보면 된다.

```json
db.products.aggregate([
    {
        $group: {
            _id: "$category",  // category 기준으로 그룹화
            total: { $sum: 1 } // 각 그룹의 개수 합산
        }
    }
]);
```

| 비교 항목          | MapReduce                      | 집계 파이프라인                     |
| ------------------ | ------------------------------ | ----------------------------------- |
| **쿼리 방식**      | 명령형(Imperative, JavaScript) | 선언형(Declarative, MongoDB 연산자) |
| **성능**           | 비교적 느림                    | 최적화되어 빠름                     |
| **유지보수**       | 복잡한 코드 필요               | 간결한 쿼리 가능                    |
| **병렬 처리**      | 가능                           | 가능 (내부 최적화 더 좋음)          |
| **사용 추천 여부** | 거의 사용되지 않음             | MongoDB에서 권장                    |



### 그래프형 데이터 모델.

다대다 관계까 매우 일반적이라면, 그래프로 데이터 모델링하면 자연스럽다.

그래프두는 정점(vertex)와 간선(edge)로 이루어짐.

많은 유형의 데이터를 그래프로 모델링할 수 있다.

 일반적인 예는 다음과 같다.

* 소셜 그래프 : 정점은 사람이고 간선은 사람들이 서로 알고 있음을 나타낸다.

* 웹 그래프 : 정점은 웹 페이지고 간선은 다른 페이지에 대한 HTML 링크를 나타낸다.

* 도로나 철도 네트워크 : 정점은 교차로이고 간선은 교차로 간 도로나 철로 선을 나타낸다.

![image-20250315153448851](./images//image-20250315153448851.png)

그래프에서 데이터를 구조화하고 질의하는 몇가지 방법이 있다.

* 속성 그래프 모델 : neo4j, titan, infinitegraph
* 트리플 저장소 모델 : datimic, allegrograph

그래프용 선언형 질의 언어 : 사이퍼, 스파클, 데이터로그

#### 속성 그래프

속성 그래프 모델에서 각 정점은 다음과 같은 요소로 구성된다.

- ﻿﻿고유한 식별자
- ﻿﻿유출(outgoing) 간선 집합
- ﻿﻿유입(incoming) 간선 집합
- ﻿﻿속성 컬렉션(키-값 쌍

각 간선은 다음과 같은 요소로 구성된다.

- ﻿﻿고유한 식별자
- ﻿﻿간선이 시작하는 정점(꼬리 정점)
- ﻿﻿간선이 끝나는 정점(머리 정점)
- ﻿﻿두 정점 간 관계 유형을 설명하는 레이블
- ﻿﻿속성 컬렉션(카-값 쌍)

Postgresql로 관계형 테이블로 구성된 그래프 저장소를 생각해보자

```sql
CREATE TABLE vertices (
    vertex_id INTEGER PRIMARY KEY,
    properties JSON
);

CREATE TABLE edges (
    edge_id INTEGER PRIMARY KEY,
    tail_vertex INTEGER REFERENCES vertices (vertex_id),
    head_vertex INTEGER REFERENCES vertices (vertex_id),
    label TEXT,
    properties JSON
);

CREATE INDEX edges_tails ON edges (tail_vertex);
CREATE INDEX edges_heads ON edges (head_vertex);
```

중요한 점

1. 정점은 다른 간선과 연결됌.
2. 정점이 주어지면 정점의 유입과 유출 간선을 효율적으로 찾을 수 있고 그래프를 순회할 수 있다. 일련의 정점을 따라 앞 뒤 방향으로 순회한다.
3. 서로 다른 유형의 관계에 서로 다른 label을 사용하면 단일 그래프에 따른 유형의 정보를 저장하면서도 데이터 모델을 깔끔하게 유지 가능

즉, 관계형 데이터베이스에서도 그래프 모델을 효과적으로 구현할 수 있으며, 이를 활용하면 전통적인 관계형 데이터 모델보다 더 유연하고 확장성이 뛰어난 데이터 구조를 만들 수 있다

**특정 정점의 인접 정점 찾기**

#### **Q1. "루시"가 태어난 곳(born_in)과 현재 거주하는 곳(lives_in) 조회**

```sql
SELECT v.vertex_id, v.properties 
FROM edges e
JOIN vertices v ON e.head_vertex = v.vertex_id
WHERE e.tail_vertex = (SELECT vertex_id FROM vertices WHERE properties->>'name' = '루시')
AND e.label IN ('born_in', 'lives_in');
```

**두 정점 간의 경로 찾기 (예: 루시가 알랭과 연결된 관계 찾기)**

#### **Q3. "루시"와 "알랭" 사이의 관계 조회**

```sql
WITH RECURSIVE path AS (
    SELECT e.tail_vertex, e.head_vertex, e.label, 1 AS depth
    FROM edges e
    WHERE e.tail_vertex = (SELECT vertex_id FROM vertices WHERE properties->>'name' = '루시')

    UNION ALL

    SELECT e.tail_vertex, e.head_vertex, e.label, p.depth + 1
    FROM edges e
    JOIN path p ON e.tail_vertex = p.head_vertex
    WHERE p.depth < 5 -- 최대 5단계까지만 탐색 (제한 안 하면 무한루프 가능)
)
SELECT * FROM path WHERE head_vertex = (SELECT vertex_id FROM vertices WHERE properties->>'name' = '알랭');
```

 **PostgreSQL의 관계형 테이블을 사용한 그래프 저장 방식은 성능 이슈가 발생할 가능성이 높다. 특히, **재귀적인 쿼리**(`WITH RECURSIVE`)를 사용한 그래프 탐색은 **연결 관계가 깊어질수록 성능 저하가 심할 수 있다**

#### 사이퍼 질의 언어

사이퍼는 속성 그래프를 위한 선언형 질의 언어로 neo4j 그래프 디비 용으로 만들어짐.

```
CREATE 
  (NAmerica:Location {name: 'North America', type: 'continent'}),
  (USA:Location {name: 'United States', type: 'country'}),
  (Idaho:Location {name: 'Idaho', type: 'state'}),
  (Lucy:Person {name: 'Lucy'}),

  (Idaho)-[:WITHIN]->(USA),
  (USA)-[:WITHIN]->(NAmerica),
  (Lucy)-[:BORN_IN]->(Idaho);
```

* 각 정점에는 USA(미국)나 Idaho(아이다호) 같은 상징적인 이름이 지정돼 있다. 
* 질의의 다른 부분에서 이 이름을 사용해 정점 간 간선을 화살표 표기를 사용해 만들 수 있다
*  즉, (Idaho)-[:WITHIN]->(USA)의 경우 꼬리 노드는 Idaho, 머리 노드는 USA인 WITHIN 레이블의 간선이 된다.

미국에서 유럽으로 이민 온 사람을 찾는 사이퍼 질의

```cypher

MATCH
	(person)-[:BORN_IN]-> () -[:WITHIN*0..]->(us:Location {name: 'United states'}),
                                                          
  (person) -[:LIVES_IN] -> () - [:WITHIN*0..]-> (eu:Location {name: 'Europe'})
```

질의는 다음과 같이 읽힌다.

다음 두 가지 조건을 만족하는 정점(person이라 부름)을 찾아라.

1. person은 어떤 정점을 향하는 BORN IN 유출 간선을 가진다. 이 정점에서 name 속성이 United states"인 Location 유형의 정점에 도달할 때까지 일련의 WITHIN 유출 간선을 따라간다.

2. 같은 person 정점은 LIVES_IN 유출 간선도 가진다. 이 간선과 WITHIN 유출 간선을 따라가면 결국 name 속성이"Europe"인 Location 유형의 정점에 도달하게 된다.

이걸 아까 Postgresql 문법으로 바꾸면..

```sql
WITH RECURSIVE
-- 🇺🇸 미국 내 모든 지역의 정점 ID 집합
in_usa(vertex_id) AS (
    SELECT vertex_id 
    FROM vertices 
    WHERE properties->>'name' = 'United States'
    
    UNION

    SELECT e.tail_vertex 
    FROM edges e
    JOIN in_usa ON e.head_vertex = in_usa.vertex_id
    WHERE e.label = 'WITHIN'
),

-- 🇪🇺 유럽 내 모든 지역의 정점 ID 집합
in_europe(vertex_id) AS (
    SELECT vertex_id 
    FROM vertices 
    WHERE properties->>'name' = 'Europe'
    
    UNION

    SELECT e.tail_vertex 
    FROM edges e
    JOIN in_europe ON e.head_vertex = in_europe.vertex_id
    WHERE e.label = 'WITHIN'
),

-- 🇺🇸 미국에서 태어난 모든 사람의 정점 ID 집합
born_in_usa(vertex_id) AS (
    SELECT e.tail_vertex 
    FROM edges e
    JOIN in_usa ON e.head_vertex = in_usa.vertex_id
    WHERE e.label = 'BORN_IN'
),

-- 🇪🇺 유럽에서 거주하는 모든 사람의 정점 ID 집합
lives_in_europe(vertex_id) AS (
    SELECT e.tail_vertex 
    FROM edges e
    JOIN in_europe ON e.head_vertex = in_europe.vertex_id
    WHERE e.label = 'LIVES_IN'
)

-- 미국에서 태어나 유럽에서 거주하는 사람을 조회
SELECT v.properties->>'name' AS person_name
FROM vertices v
JOIN born_in_usa b ON v.vertex_id = b.vertex_id
JOIN lives_in_europe l ON v.vertex_id = l.vertex_id;
```





처음보는 문법인데.. 얼마나 효율적일까.. 딱바도 29줄 -> 4줄 차이가 난다. 

## 정리

문서 데이터베이스와 그래프 데이터베이스는 다음과 같이 두가지 갈래가 있다.

1. ﻿﻿﻿문서 데이터베이스는 데이터가 문서 자체에 포함돼 있으면서 하나의 문서와 다른 문서 간 관계가 거의 없는 사용 사례를 대 상으로 한다.
2. ﻿﻿﻿그래프 데이터베이스는 문서 데이터베이스와는 정반대로 모든 것이 잠재적으로 관련 있다는 사용 사례를 대상으로 한다.

관계, 문서, 그래프 모두 각자의 영역에서는 훌륭하다. 한모델을 다른 모델로 흉내내봤자 엉망이다..



# 3장 저장소와 검색

로그 구조 계열 저장소 엔진

- **기본 원리:**
   데이터를 디스크에 순차적으로 기록하는 로그 파일 형태로 저장
- **장점:**
  - **쓰기 최적화:** 순차적 기록으로 인해 쓰기 작업이 빠르고, 대량의 쓰기 작업에 유리
  - **충돌 감소:** 업데이트 시 데이터 전체를 덮어쓰지 않고, 새로운 로그 항목을 추가하는 방식으로 진행되어 동시 쓰기 작업 시 충돌이 줄어듬
- **단점:**
  - **읽기 성능:** 데이터 조회 시 로그 전체 또는 여러 로그 구간을 탐색해야 할 수 있어, 랜덤 읽기 성능이 상대적으로 떨어질 수 있다.
  - **정리 작업:** 로그에 중복되거나 삭제된 데이터가 쌓이면 주기적으로 정리(컴팩션) 과정을 거쳐야 하므로, 추가적인 관리 오버헤드가 발생

페이지 지향 계열 저장소 엔진 (B-트리 기반)

- **기본 원리:**
   데이터를 고정된 크기의 페이지(블록) 단위로 관리하며, 각 페이지 내에서 데이터를 배열하거나 B-트리 같은 인덱스 구조를 사용해 빠른 접근을 지원
- **장점:**
  - **랜덤 읽기 최적화:** 인덱스를 통해 특정 데이터를 빠르게 찾을 수 있어, 조회 및 검색 성능이 우수
  - **업데이트 및 삭제:** 페이지 단위로 데이터를 갱신하므로, 기존 데이터를 수정하는 작업이 비교적 효율적
- **단점:**
  - **쓰기 성능:** 페이지 내에서 수정 작업을 할 때, 페이지 전체를 다시 읽고 쓸 필요가 있어 쓰기 작업에 부하가 발생
  - **공간 활용:** 페이지 단위 관리로 인해 내부 단편화(internal fragmentation)가 발생





DB에서 특정 키의 값을 효율적으로 찾기 위해선 index를 이용한다

index의 기본 개념 : 기본 데이터로부터 파생된 메타데이터.

저장소 시스템의 중요한 트레이드 오프로, 읽기 질의 속도를 향상시키지만, 모든 인덱스는 쓰기 속도를 떨어트린다.

### 해시 색인

key-value 저장소는 보통 해시-맵, 테이블로 구현한다.



많은 데이터베이스는 내부적으로 append only 형식의 로그 파일을 많이 사용해서 여기에 데이터를 기록한다.

파일에 항상 추가만 한다면 디스크 공간이 부족해지므로, 특정 크기의 segment로 로그를 나눈다.

특정 크기 도달시 세그먼트를 닫고 새 세그먼트 파일을 연다. 

<img src="./images//image-20250323173129449.png" width = 450>

그리고 세그먼트 파일들에 대해 compaction을 수행하여 최신 갱신값을 유지하면서 용량을 절약할 수 있다.

세그먼트가 쓰여진 후는 변경할 수 없기 때문에 다른 세그먼트와 병합을 통해 용량을 다시 줄이고,

새로 병합한 세그먼트로 읽기를 처리한다. 전환 후에는 이전 세그먼트 파일을 삭제하면 끝이다.



이후, 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시테이블을 갖는다. 

키의 값을 찾으려면 최신 세그먼트 해시 맵을 확인하고, 키가 없다면 두번째 최신 세그먼트 파일을 확인하면서

키벨류로 값을 조회할 수 있다.

실제 구현에서 고려할 내용들

* 파일 형식 : CSV는 로그에 가장 적합하지 않다. 바이트 단위 문자열 길이를 부호화 한 다음, 원시 문자열을 부호화하는 바이너리 형식을 사용하는 편이 더 빠르고 간단하다. 

```
key1,value1
key2,value2
key3,value3

문제점 : 
1. 줄단위로 읽고 ,를기준으로 나눠야함. 
2. 문자열 길이가 얼마인지 알 수 없어 전체를 먼저 읽어야 함.
3. 줄 끝을 찾아야 함 -> 느림 
```

효율적인 바이너리 방식

```
[4][key1][6][value1]

[4] -> 키의 길이
[key1] -> 실제 키 문자열
[6] -> 값 길이
[value1] -> 실제 값 문자열 

위 값을 바이너리 16진수으로 표현하면 아래처럼 표현도 가능.  
\x04key1\x06value1

파싱할 때 먼저 길이를 읽고, 정확히 필요한 만큼만 읽으면 됨 → 빠름

구분자(쉼표, 개행 등) 필요 없음

이진 로그 파일은 디스크에 순차적으로 쓰기 좋고, 공간 낭비도 적음
```

* 레코드 삭제 : 키와 관련된 값 삭제하려면 파일에 툼스톤을 추가해서 로그 세그먼트 병합시, 삭제된 키의 이전 값을 무시하게 함.

  * 툼스톤은 "이 키는 삭제되었음"을 나타내는 마커(marker)

  * ```
    [4]key1 [6]value1   ← 실제 저장
    [4]key1 [0]         ← 툼스톤 (값의 길이가 0, 즉 삭제 표시)
    ```

* crash 복구 : DB 재시작시 인메모리 해시 맵은 손실되므로 재로딩해야하는데 파일이 크면 재시작이 느려짐. 스냅숏을 디스크에 저장해 복구하는 방식 등을 고려해야 함

* 부분적 레코드 쓰기 : 체크섬 등을 통해 손상 로그 복구

* 동시성 제어 : 하나의 쓰기 쓰레드만 사용

덮어 써서 갱신하는것보다 추가 전용 로그가 훨씬 좋다. 낭비가 아니다. 왜?

* 추가와 병합은 순차 쓰기작업이라, HDD, SSD 디스크 특성상 훨씬 빠르다
* 세그먼트 파일이 추가 전용이고 불변이면, 동시성과 고장 복구가 훨씬 간단함.

해시 테이블 색인의 제한 사항

* 키가 많으면 메모리가 부족함.
* 해시 테이블은 range query에 부적합함.

이런 제한이 없는 index 구조는 무엇이 있을까?

### SS 테이블(정렬된 문자열 테이블) 과 LSM 트리



정렬된 문자열 테이블 이란, **LSM 트리 기반 저장소(예: Cassandra, RocksDB 등)**에서 사용하는 **불변(immutable) 정렬된 키-값 파일 포맷**

SS 테이블은 위 해시 색인 로그 세그먼트보다 몇가지 큰 장점이 있다.

1.**디스크 기반 인덱스 가능 → 메모리 사용 최소화**

- 해시 색인은 **전체 키를 메모리에 유지**해야 해서, 키 수가 많아지면 메모리 폭발
- SSTable은 **디스크에 인덱스 + 요약 인덱스 + Bloom filter**를 두어 메모리 효율적

2.  **정렬된 데이터 → 범위 쿼리 가능**

- SSTable은 key가 정렬돼 있어 `key > A and key < C` 같은 **범위 쿼리** 가능
- 해시 색인은 범위 쿼리 불가 → 오직 정확한 키 조회만 가능

3.  **컴팩션(merge) 최적화**

- 여러 SSTable을 효율적으로 병합/정리 가능 (merge-sort 방식)
- 로그 세그먼트는 정렬이 안돼서 중복 제거/정리 시 비효율적

4. **빠른 존재 여부 확인 (Bloom Filter 사용)**

- SSTable은 Bloom Filter를 이용해 **키가 있는지 없는지 빠르게 확인**
- 디스크 접근 줄여서 성능 향상
- Bitcask 스타일 로그는 메모리 해시에만 의존

5. 메모리의 모든 키의 색인을 유지할 필요가 없음
   * 정렬되어있으므로, 특정 키값 들의 오프셋을 이용해 그 사이를 스캔하면 됌. 
   * 수 kb정도는 스캔이 빠르므로, 파일 내 수 kb당 키 1개씩 띄엄띄엄 두면 됌 

또한 아래 읽기 요청에 대한 특성도 있다. 읽기 최적화를 위해 압축 블록을 처리한다

```
읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에
→ 예: WHERE key >= 'user100' AND key <= 'user200' 같은 범위 조회가 들어옴
→ SSTable은 정렬된 구조니까 범위 조회가 가능하지만, 디스크에서 여러 키-값을 읽어야 함

해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다
→ 데이터를 그냥 하나씩 저장하지 않고,
→ 예를 들어 4KB 또는 64KB 같은 덩어리(= 블록)로 묶은 다음,
→ 그 블록 전체를 압축해서 디스크에 저장함 (gzip, snappy 등)

희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리킨다
→ 메모리에 있는 인덱스는 모든 키가 아니라,
→ 몇 개의 키(희소하게 추려낸)만 저장하고,
→ 그 키가 시작하는 압축된 블록의 디스크 위치(offset)를 가리킴

디스크 공간을 절약한다는 점 외에도 압축은 I/O 대역폭 사용도 줄인다
→ 압축된 데이터를 한 번에 읽어오니까:

디스크 공간 덜 씀

디스크 → 메모리로 데이터 복사 시 전송량이 줄어듦
```

* 희소 인덱스 : 데이터 공간 절약을 위해, 특정 구간마다 몇개 키만 인덱싱해서 저장하는것 

### SS 테이블 생성과 유지

쓰기는 임의 순서로 발생함. 하지만 ss table은 키를 기준으로 정렬하는데 어떻게 정렬할까?

메모리에 트리 데이터 구조를 이용해서 메모리에 먼저 저장하고, 디스크에 기록한다.

1. 쓰기가 들어오면 메모리 상 banacend tree 자료구조에 추가한다.(비트리나 레드블랙) 멤테이블이라고 한다
2. 보통 수 메가바이트 임계값보다 커지면 디스크에 flush 한다. 이미 정렬되어있다. 새로운 SS 테이블은 DB의 최신 세그먼트가 된다
3. 읽기 요청시 멤테이블에서 키를 찾아 최신 세그먼트에서 찾는다. 없으면 그다음 오래된 세그먼트를 뒤진다.
4. 가끔 세그먼트 파일을 합치고 덮어 씌우고 병합과 컴펙션을 백그라운드에서 수행한다.

중간에 DB 고장이라던가 등 손실되는 경우를 방지하기 위해, WAL용 로그를 무조건 사용함.

* 메모리에만 쓰면 위험하니까, **WAL로 디스크에 먼저 로그를 쓰고**,그다음에 MemTable에 반영

### SS 테이블에서 LSM(Log-Strucuted Merge-Tree) 트리 만들기

LSM 트리는 RokcsDB, 카산드라, HBase, Influx, Scylladb 등에서 사용한다.

정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

**Lucene**은 LSM 트리 기반의 데이터 저장소는 아니지만, 비슷하게 **쓰기 최적화된 구조**를 가지고 있고,
 그 핵심은 **역색인(inverted index)** + **세그먼트(segment)** 구조에 있다.

> **SSTable과 유사한 '불변의 정렬된 세그먼트 파일(segment)'** 구조를 사용

그래서 본질적으로 SSTable과 매우 유사한 개념이지만 목적은 다르다 

| Lucene            | SSTable               |
| ----------------- | --------------------- |
| 검색 엔진용       | 일반적인 키-값 저장용 |
| 역색인 저장       | 정렬된 키-값 저장     |
| 세그먼트(segment) | SSTable과 유사        |
| 병합 (merge)      | 컴팩션과 유사         |

#### 성능 최적화

LSM 트리 기반 저장소 엔진은 기본 구조만으로도 꽤 괜찮지만, 성능을 높이기 위해 다양한 최적화 기법을 사용

#### 문제점: 존재하지 않는 키를 찾을 때 느리다

LSM 트리는 데이터를 멤테이블부터 오래된 세그먼트까지 여러 계층에 나눠서 저장한다.
 어떤 키가 데이터베이스에 존재하지 않으면, 가장 최신인 멤테이블부터 시작해서 가장 오래된 세그먼트까지 거슬러 올라가며 모두 확인해야 한다.
 이 과정에서 디스크를 읽는 경우가 생기므로 성능이 떨어질 수 있다.

#### 해결책 1: 블룸 필터

블룸 필터는 어떤 키가 "존재하지 않는다"는 것을 빠르게 판단할 수 있게 해주는 메모리 효율적인 자료구조다.
 블룸 필터를 사용하면 해당 키가 없다는 것을 빠르게 알 수 있기 때문에, 불필요하게 디스크를 읽는 일을 줄일 수 있다.
 정확히 존재하는지 여부를 100% 확실하게 알려주진 않지만, 없다는 건 확실하게 판단할 수 있다.

#### 해결책 2: 컴팩션 전략

LSM 트리는 시간이 지나면 SS테이블(정렬된 테이블 파일)을 백그라운드에서 병합한다.
 이 병합 작업을 어떻게 하느냐에 따라 성능이 크게 달라진다. 대표적인 전략은 두 가지가 있다.

1. 사이즈 계층 컴팩션 (Size-Tiered Compaction)
    새롭고 작은 SS테이블을 오래된 크고 긴 SS테이블에 순차적으로 병합하는 방식이다.
    HBase가 이 방식을 쓴다.
2. 레벨드 컴팩션 (Leveled Compaction)
    SS테이블을 키 범위에 따라 더 작게 나누고, 오래된 데이터는 특정한 "레벨"로 이동시킨다.
    점진적으로 병합을 진행하므로 디스크 공간을 더 효율적으로 쓸 수 있다.
    LevelDB와 RocksDB는 이 방식을 사용한다.
    카산드라는 두 가지 방식을 모두 지원한다.

#### LSM 트리(로그 구조화 색인)의 핵심 개념

LSM 트리의 핵심은 SS테이블을 백그라운드에서 계속 병합(compaction)하는 구조다.
 이 덕분에 메모리보다 훨씬 큰 데이터셋도 효율적으로 관리할 수 있다.
 데이터가 정렬된 상태로 저장되기 때문에 범위 질의(range query)도 빠르게 처리할 수 있다.
 또한 디스크에는 순차적으로 쓰기 때문에 매우 높은 쓰기 성능을 낼 수 있다.



### B 트리

가장 널리 색인되는 자료구조. NoSQL도 많이 사용함(몽고디비, couchbase)

SS테이블처럼 키로 정렬된 키-값쌍을 유지해서 키-값 검색과 범위 질의에 효율적임.

로그 구조화 색인은 DB를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록하지만,

B 트리는 전통적으로 OS 페이지에 맞게 4KB 또는 8KB의 고정 크기 블록이나 페이지로 나누고 한번에 하나의 페이지에 읽기 또는 쓰기를 한다.

![image-20250323182929650](./images//image-20250323182929650.png)

* 한 페이지가 다른 페이지를 포인터(메모리 말고 디스크)로 참조해서 페이지 트리를 구성한다.

B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수(BranchingFactor 라고 한다)

* 한 노드가 가질 수 있는 자식 노드 수

* 자식 노드 수가 6이면 b factor는 6

*  **한 페이지 크기(예: 4KB) 안에 들어갈 수 있는 키 + 포인터의 개수에 따라 결정 됌**

  * ```
    페이지 크기: 4096 바이트 (4KB)
    키 하나 저장: 16바이트
    포인터 하나 저장: 8바이트
    
    n * (16 + 8) ≤ 4096
    → n ≤ 170 = 분기 계수 
    
    실제로는 훨씬 더 많이 잡을수도 있음. 
    ```

  * 분기계수가 클수록 트리 높이가 낮아져 디스크 접근 횟수는 줄어들지만, 한 페이지에 너무 많은 키가 있으면 캐시 적중률이 낮아짐. 

  * 또한 key 크기가 작을수록 한 페이지에 더 많은 키를 저장하므로 분기계수 증가. 연산속도 증가 -> 성능 향상 

* 현실의 B-트리에서는 보통 **분기 계수 수백~수천 개**도 가능 

  * 이 계수를 이용해 트리 높이 계산도 가능

  * ```
    h≈log b N 
    
    h: 트리의 높이
    b: 분기 계수 (한 노드가 가질 수 있는 자식 수)
    N: 전체 데이터(키)의 개수
    ```

B 트리에서의 키 update는

1. **리프 노드(페이지)**에서 해당 키를 찾고
2. 값을 바꾼 뒤
3. 해당 페이지를 **디스크에 다시 저장(write back)** 하면 끝

**트리 구조는 바뀌지 않음** → 모든 인덱스 포인터는 여전히 유효

키 insert는

1. 키가 들어가야 할 범위의 **리프 페이지를 찾고**
2. 거기에 키와 값을 **추가**

🔸 그런데 리프 페이지에 공간이 없다면?

- 해당 페이지를 **두 개로 분할(split)**
   → 두 페이지는 각각 반쯤만 데이터를 가짐
- 그리고 **상위 부모 노드**에
   → 분할된 페이지의 경계 키 정보를 **갱신**

→ 이 과정이 **트리의 균형**을 유지하게 해줌

<img src="./images//image-20250323183703185.png" width = 550>

#### 신뢰할 수 있는 B트리 만들기 

B트리의 기본적인 쓰기 동작은 디스크 상의 페이지에 덮어쓴다. 

장애발생 시 디스크상에 WAL을 추가해 모든 B 트리의 변경사항을 기록해야 장애가 나도 복구할 수 있다.

또한 멀티스레드에서 같은 페이지 갱신시 래치나 가벼운 lock으로 트리의 구조를 보호해야 한다

### 비트리 최적화

* 페이지 덮어 쓰기와 WAL 대신 쓰기 시 복사 방식 사용. 변경된 페이지를 다른 위치에 기록하고 트리에 상위 페이지의 새 버전을 만들어 가리키게 함
* 전체 키를 저장하지 않고 **일부분(공통 접두사 제외)**만 저장. 내부 노드에서는 **경계 역할만 하면 되기 때문에 전체 키 불필요**
* 각 리프페이지에 양쪽 더블 링크드 리스트로 참조를 가져서 레인지 스캔
* 프랙탈 트리. B-트리 변형 구조로, 일부 **로그 구조(LSM)의 개념을 차용**. 삽입·삭제 시 **버퍼를 사용**해 디스크 접근을 줄임



### B트리와 LSM 트리 비교

경험적으로 LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다 고 여긴다. 읽기가 보통 LSM 트리에서 더 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS테이블을 확인해야 하기 때문이다.

#### LSM 트리의 장점.

* B트리 인덱스는 최소한 두번 기록이 필요함. 쓰기 전 로그 한번과 트리 페이지에 한번. 한번에 전체 페이지도 교체해야는 케이스도 있음.

* LSM는 보통 B트리보다 쓰기 처리량이 높다. 트리에서 여러 페이지를 덮어 쓰는것이 아닌 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문. (sequence 쓰기는 HDD에서 속도가 꽤 빠름 )
* 컴팩션 기반 구조로 파편화 적음, LSM 트리는 압축률이 더 좋음. 
   → 주기적인 SSTable 병합으로 공간 낭비 최소화
   → B-트리는 페이지 분할 등으로 파편화 발생

* 디스크 대역폭 활용 효율적
   → 데이터가 압축되어 있어 더 많은 I/O 처리 가능
   → 디스크가 처리할 수 있는 쓰기량을 극대화 가능

#### LSM 트리의 단점.

1. **컴팩션이 읽기/쓰기 성능에 영향**

- 컴팩션(compaction)은 백그라운드에서 실행되지만, **디스크 I/O를 공유**하기 때문에  진행 중인 읽기·쓰기 요청에 **지연**이 생길 수 있음
- 특히 디스크 자원이 부족한 상황에서는  요청이 컴팩션 종료까지 **대기**하게 됨
- 평균 처리량이나 응답 시간에는 영향이 적지만,
   → **최악의 응답 시간(상위 백분위 응답 시간)**은 종종 매우 길어짐
   → 지연 시간의 예측이 어려움

2. 쓰기 대역폭 경쟁
   * WAL 로그 기록과 Memtable flush가 같은 쓰기 대역폭을 경쟁적으로 사용해서 병목 발생 가능

3. 강력한 트랜잭션 지원에 불리

- B-트리는 키 범위에 **잠금**을 걸 수 있고, 트리에 직접 잠금 구현 가능 → 트랜잭션 격리 수준 구현에 유리
- LSM 기반 구조는 키가 여러 곳에 존재할 수 있어→ **정확한 잠금 구현이 어렵고 복잡함**

4. 중복된 key 존재 가능
   * LSM 트리는 **다양한 SSTable에 같은 키가 중복 저장**될 수 있음 → 항상 **가장 최신 값을 찾는 추가 작업 필요**

### 색인 안에 값 저장하기 - 클러스터링 인덱스

색인은 데이터를 빠르게 찾기 위한 구조이며, 색인의 **키는 검색 대상**, **값은 실제 데이터 또는 해당 데이터의 위치를 가리키는 참조**다. 만약, 값이 데이터를 포함하지 않고 위치를 가리키는 경우가 있는데 가리키는 곳을 힙 파일이라고 한다 (데이터 페이지).

* 힙 파일은 데이터를 특정 순서 없이 저장하며, 필요 시 삭제된 레코드를 기록하거나 새로운 레코드로 덮어쓰기 위해 사용된다
* 힙 파일을 사용하는 방식은 **값만 갱신하고 키는 그대로 둘 때 효율적**이다.

하지만 색인만 보고는 데이터를 다 알 수 없어, 힙 파일을 다시 읽어야 하는데 이건 **읽기 성능을 떨어뜨리는 단점**이 있다.
 그래서 어떤 경우에는 **색인 내부에 데이터를 직접 저장**하는 방식이 더 낫다. 이걸 **클러스터드 색인**이라고 부른다.
 예를 들어:

- MySQL의 InnoDB는 기본키가 항상 클러스터드 색인이며, 보조 색인은 힙 위치가 아니라 기본키를 참조한다.
- MS SQL Server는 테이블당 하나의 클러스터드 색인을 지정할 수 있다.

클러스터드 색인과 비클러스터드 색인에는 각각 장단점이 있는데, 이 둘의 **중간 형태**로 나온 게 **커버링 색인(covering index)**이다. 

* 색인 안에 **검색에 자주 사용되는 칼럼의 일부 데이터도 함께 저장**해서, 색인만 조회하고도 결과를 반환함.

이렇게 하면 **읽기 속도는 빨라진다**.
 하지만 그만큼 단점도 있다.

1. **저장 공간이 더 많이 필요하다**
   - 색인 안에 칼럼 데이터를 함께 저장하니까 전체 데이터 크기가 커진다.
2. **쓰기 작업이 느려질 수 있다**
   - 데이터를 추가하거나 수정할 때, 색인도 같이 수정해야 하니까 작업이 더 많아진다.
3. **데이터 복제 환경에서는 조심해야 한다**
   - 색인과 실제 데이터 사이에 불일치가 생길 수 있는데, 애플리케이션에서는 그걸 알아채기 어렵다.
   - 그래서 데이터베이스는 트랜잭션(정합성 보장)을 더 철저하게 관리해야 한다.

### 전문 검색(fulltext)과 퍼지 색인(fuzzy index)

**Lucene**은 LSM 트리 기반의 데이터 저장소는 아니지만, 비슷하게 **쓰기 최적화된 구조**를 가지고 있고,
 그 핵심은 **역색인(inverted index)** + **세그먼트(segment)** 구조에 있다.

단어가 어디에 저장되어 있는지를 매번 디스크를 뒤져서 찾으면 느리기 때문에,
 루씬은 메모리 안에 **작은 색인(in-memory index)**을 만들어 둔다.
 이 색인은 "이 키(단어)는 디스크 파일의 어디쯤 있어요"라고 **위치를 가리켜주는 역할**을 한다.

**루씬**은 훨씬 정교하게 만든다.
 인메모리 색인을 **유한 상태 오토마톤(FSA)**이라는 걸로 만든다.
 이건 **트라이(Trie)**라는 자료구조랑 비슷한데, 단어의 **문자 하나하나를 경로처럼 따라가면서 찾는 구조**

### 모든것을 메모리에 보관

캐시드 같은 일부 인메모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 캐시 용 도로만 사용된다. 하지만 다른 인메모리 데이터베이스는 지속성을 목표로 한다. 이 목표를 달성하는 방법은 (배터리 전원 공급 RAM과 같은) 특수 하드웨어를 사용하거나 디스크에 변경 사항의 로그를 기록하거나 디스크에 주기적인 스냅숏을 기록하거나 다른 장비에 인메모리 상태를 복제하는 방법이 있다.



안티 캐싱은 메모리가 부족할 때
 **가장 오래 안 쓰인 데이터**를 **디스크로 내보내고**,
 나중에 그 데이터가 다시 필요해지면 **다시 메모리로 불러오는 방식**이다.

→ 이 방식은 운영체제의 **가상 메모리 + 스왑(swap)** 방식과 비슷하지만,
 데이터베이스는 운영체제보다 더 **세밀하게 개별 레코드 단위**로 다룰 수 있어서
 **더 효율적**이다.

## 트랜잭션 처리나 분석

레코드가 사용자 입력 기반으로 삽입되거나 갱신되는 주로 통신하는 애플리케이션의 트랜잭션을 OLTP

데이터 분석, 집계 등에 의해 오래걸리는 배치성 분석 처리 트랜잭션을 OLAP 라고 한다.

| **특성**           | **트랜잭션 처리 시스템 (OLTP)**                  | **분석 시스템 (OLAP)**                                |
| ------------------ | ------------------------------------------------ | ----------------------------------------------------- |
| **주요 읽기 패턴** | 질의당 적은 수의 레코드, 키 기준으로 가져옴      | 많은 레코드에 대한 집계                               |
| **주요 쓰기 패턴** | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기 (Bulk import, ETL) 또는 이벤트 스트림 |
| **주요 사용처**    | 웹 애플리케이션을 통한 최종 사용자/소비자        | 의사결정 지원을 위한 내부 분석가                      |
| **데이터 표현**    | 데이터의 최신 상태 (현재 시점)                   | 시간이 지나며 일어난 이벤트 이력                      |
| **데이터셋 크기**  | 기가바이트에서 테라바이트                        | 테라바이트에서 페타바이트                             |

### 데이터 웨어하우징

OLTP 시스템은 사업 운영에 실시간으로 중요하기 때문에 높은 가용성과 낮은 지연시간의 트랜잭션을 필요로 한다.

![image-20250323222756393](./images//image-20250323222756393.png)

데이터 웨어하우스는 분석가들이 OLTP 작업에 영향을 주지 않으려고, 따로 데이터베이스를 복제하고 스트림 등을 통해 Extract Trasanform Load 한다.

### 분석용 스키마 - start schema와 snowflake 스키마

**트랜잭션 처리(OLTP) 시스템**에서는 애플리케이션의 다양한 요구에 맞춰 데이터 모델이 매우 광범위하고 다양하게 사용 되지만, OLAP 시스템의 데이터 웨어하우스에서는 데이터 모델의 종류가 상대적으로 적음

- 대부분의 시스템이 **차원 모델링(Dimensional Modeling)**, 즉 **스타 스키마**로 대표됨
- 분석의 유연성과 성능을 위해 **사실 테이블(Fact Table)**과 **차원 테이블(Dimension Table)**을 중심으로 설계

**스타 스키마(Star Schema)의 구조와 특징**

* 이름은 사실 테이블이 중심에 있고 차원 테이블이 방사형으로 연결되어 있어 '별'처럼 보이기 때문

- **중심에 사실 테이블(Fact Table)**
  - 데이터 웨어하우스의 중심에는 사실 테이블이 위치. 예를 들어, 식료품 소매업 데이터 웨어하우스에서는 `fact_sales`라는 사실 테이블이 있을 수 있다.
  - 사실 테이블의 각 로우는 특정 시점에 발생한 이벤트(예: 고객이 제품을 구매한 사건)를 기록합니다. 웹사이트 트래픽 분석이라면 페이지 뷰나 클릭 이벤트를 나타낼 수 있다.
  - 사실 테이블은 개별 이벤트를 저장하여, 이후 분석 시 유연성을 극대화할 수 있지만, 동시에 데이터 양이 매우 커질 수 있다. 실제로 애플, 월마트, 이베이 같은 대기업은 수십 페타바이트의 트랜잭션 데이터를 보유하고 있있다.
- **사실 테이블의 구성**
  - 일부 컬럼은 제품이 판매된 가격, 공급자로부터 구매한 비용 등 이벤트와 관련된 속성을 담음.
  - 나머지 컬럼들은 외래 키로 구성되어, 각각의 로우가 어떤 차원(누가, 언제, 어디서, 무엇을, 어떻게, 왜)에 해당하는지를 나타낸다.
- **왜 '스타 스키마'라고 부를까?**
  - 사실 테이블이 중심에 있고, 차원 테이블들이 방사형으로 둘러싸고 연결되는 구조가 별 모양처럼 보이기 때문

### 눈꽃송이 스키마(Snowflake Schema)란?

- **정의와 구조**
  - 눈꽃송이 스키마는 스타 스키마의 변형으로, 차원 테이블을 **더 정규화하여** 세부적으로 분리한 형태
  - 예를 들어, `dim_product` 테이블에서 브랜드와 제품 범주 정보를 하나의 컬럼에 문자열로 저장하는 대신, 이를 별도의 `dim_brand`와 `dim_category` 테이블로 분리하고 외래 키로 연결할 수 있습니다.
- **장단점**
  - **장점:**
    - 정규화를 통해 중복 데이터를 줄이고 저장 공간을 절약할 수 있다.
  - **단점:**
    - 여러 테이블 간의 조인이 필요해져 쿼리가 복잡해지고, 분석가가 이해하기 어려워질 수 있다.
  - 실제 분석에서는 단순한 구조와 빠른 쿼리 성능 때문에 대부분의 분석가들이 스타 스키마를 선호

## 칼럼 지향 저장소

칼럼 지향 저장소의 기본개념은 간단하다. 모든 값을 하나의 로우에 함께 저장하지 않는 대신,

각 칼럼별로 모든 값을 함께 저장한다.

각 칼럼을 개별 파일에 저장하면, 질의에 사용되는 칼럼만 읽고 불필요한 다른 칼럼 데이터를 읽지 않아도 되므로 I/O 부하와 처리 시간이 줄어든다.

![image-20250323224550891](./images//image-20250323224550891.png)

즉 동일한 칼럼의 값들을 한 곳에 모아서 저장한다. 예를 들어, '나이' 칼럼의 모든 값이 하나의 파일이나 블록에 연속적으로 저장

* 아파치 카산드라와는 다름. 
* Cassandra는 데이터를 “컬럼 패밀리”라는 개념으로 저장함. 각 행은 키를 중심으로 여러 칼럼을 포함할 수 있으며, 각 파티션 내에서는 행 단위로 데이터가 관리

### 칼럼 압축

칼럼 압축은 **디스크에서 필요한 칼럼만 읽어들이는 작업 외에, 데이터를 압축하여 디스크 I/O를 더욱 줄이는 기법**

칼럼 지향 저장소는 같은 종류의 값들이 반복되어 저장되는 경향이 있어 압축하기에 매우 유리.

![image-20250323225332671](./images//image-20250323225332671.png)

보통 칼럼에서 고유 값의 수는 로우 수에 비하면 매우 적음 (유니크한 수).

n개의 고유 값을 가진 칼럼을 가져와 n개의 개별 비트맵으로 변환해서 비트맵 맵을 만들 수 있음.



## 정리

저장소 엔진은 OTLP와 OLAP라는 두가지 큰 범주로 나뉜다

* OLTP 시스템은 대량의 요청을받고, 저장소 엔진은 요청한 데이터를 찾기 위해 색인을 사용한다. 대게 디스크 탐색이 병목이다
* OLAP 시스템은 요청은 적지만 짧은 시간에 수백만개의 레코드를 스캔해야 하며, 디스크 대역폭이 병목이다.

로그 구조화 저장소 엔진은 비교적 최근에 개발됐다. 핵심 아이디어는 임의 접근 쓰기를 체계적으로 디스크에 순차 쓰기로 바꾼 것이다. 하드드라이브와 SSD의 성능 특성에 맞춰 쓰기 처리량을 높이는 것이 가능하다.



# 4 부호화와 발전

시간이 지날수록 애플리케이션은 필연적으로 변한다. 기능 변경시 저장하는 데이터도 변경되는 경우가 많다.

쓰기스키마와 달리 읽기스키마 데이터베이스는(몽고디비처럼) 이전 데이터 타입과 새 데이터 타입이 섞여 포함되기 좀 수월하다. 시스템이 원활하게 실행되려면 양방향으로 호환성을 유지해야 한다

* 하위 호환성 : 새 코드는 이전 코드가 기록한 데이터를 읽을 수 있어야 함
* 상위 호환성 : 이전 코드는 새 코드가 기록한 데이터를 읽을 수 있어야 한다

하위 호환성은 상대적으로 쉽지만, 상위 호환성은 다루기 더 어렵다.

JSON, XML, Protocol buffers, thrift, Avro 등에 대해 알아보자.

## 데이터 부호화 형식

프로그램은 보통 두가지 형태로 표현된 데이터를 사용해 동작

* object, structure, list, array, hash table, tree 등으로 데이터가 유지됌

파일이나 네트워크를 통해 전송하려면, 바이트 배열의 형태로 부호화 해야함. 

이를 다시 데이터로도 표현해야 하는데 이를 부호화(직렬화, 마샬링) 그리고 반대는 복호화(파싱, 역직렬화, 언마샬링)이라고 한다.

### 언어별 형식

인메모리 객체를 바이트열로 부호화하는 기능이 내장되어 있음.

* 자바는 Serializable

그러나 문제점이 많음

* 실수로 `serialVersionUID`를 생략하거나 잘못 지정하면 **`InvalidClassException`** 발생 가능
* 패키지 경로까지 포함해서 저장(FQCN)이라, 시스템간 공유하기 어려움. 

때문에 내장된 방법들을 사용하지 말고 다른 표준 포맷을 사용하는것이 좋음

### JSON과 XML, 바이너리 변형

XML은 너무 장황하고 불필요하게 복잡함.

CSV는 스키마가 없어서 각로우와 컬럼에 대해 정의와 약속이 모호함.

XML과 CSV는 수와 숫자로 구성된 문자열을 구분할 수 없어 JS에서 부동소수점 문제 발생 가능. 

### 이진 부호화(binary)

조직 내부에서만 사용하는 데이터라면, 꼭 복잡한 텍스트 형식(JSON, XML 등)을 사용할 필요 없이, 더 빠르고 효율적인 이진(binary) 형식을 써도 된다

* 최소공통분모 부호화 형식이란 JSON이나 XML 같은 **텍스트 기반 포맷**을 말하는거 같은데, 이것들은 저장 공간과처리 속도 면에서 비효율적.

### 스리프트와 프로토컬 버퍼

이진 부호화(바이너리) 라이브러리. 둘다 오픈소스

* 목적 : 데이터 구조를 직렬화(serialize)하고 역직렬화(deserialize)하기 위해 사용

* 특징 : 이진 포맷으로 작고 빠름, 텍스트보다 처리 효율이 높음

* 사용 분야 : 마이크로서비스 간 통신, RPC 시스템, 대규모 데이터 처리 등

* 텍스트 기반보다 : 더 빠르고, 더 적은 데이터 전송, 더 낮은 CPU 사용

둘다 스키마가 필요하다.

```
// 스리프트
struct Person {
  1: required string userName
  2: optional i64    favoriteNumber,
  3: optional list<string> interests
}

// 프로토 버프 스키마
message Person {
  required string user_name = 1;
  optional int64 favorite_number = 2;
  repeated string interests = 3;
}
```



스리프트는 binary  Protocol과 CompactProtocol 2가지를 지원한다.

![image-20250329171746153](./images//image-20250329171746153.png)

* 각 필드 에는 타입 어노테이션이 있음. 문자열의 길이와 목록의 수도 있음. 



스리프트 컴팩트 프로토콜 부호화는 동일한 정보를 더 줄여서 표현한다.

* 필드타입과 태그 숫자를 단일 바이트로 줄이고, 가변 길이 정수를 사용하여 직렬화 함. 

![image-20250329175840556](./images//image-20250329175840556.png)

프로토 버퍼는, 비트를 줄여 저장하는 처리 방식이 약간 다르지만 스리프트의 컴팩트 프로토콜과 매우 비슷하다.

* 셋다 보면 컴팩트프로토콜이랑 프로터 버퍼가 데이터 압축률이 제일 좋음

![image-20250329180054886](./images//image-20250329180054886.png)



### 필드 태그(tag)와 스키마 발전(Schema evolution)



직렬화된 데이터는 직렬화된 필드의 연결일 뿐이다. 

각필드는 태그 숫자로 식별하고, 데이터 타입을 주석으로 단다. 

필드 태그는 직렬화 데이터 해석을 위해 매우 중요하다. 필드에 새로운 태그 번호를 부여하는 방식으로 스키마에 새로운 필드를 추가할 수 있다.

이전 코드에서 새 코드로 기록한 데이터를 읽으려는 경우 해당 필드를 무시해서 상위 호환성을 유지하게 한다.



하위호환성을 유지하려면 스키마 초기 배포 이후에 추가되는 필드는 optional이나 기본값을 두면 된다. 그러면 터지지 않는다.

### 데이터 타입과 스키마 발전

필드의 데이터 타입 변경은 불가능하지 않지만 값이 정확하지 않거나 에러 발생 가능성이 있다.

프로토버퍼의 흥미로운 기능 중에 목록이나 배열 데이터 타입이 없고 repeated 표시자가 있다.

repeated 필드의 직렬화는 단순히 레코드에 동일 필드 태그가 여러번 나타나므로, 단일값인 optional 필드를 다중값인 repeated 필드로 변경해도 문제가 없다. 

이전 데이터를 읽는 코드는 0이나 1개의 엘레먼트가 있는 목록으로 보게되고, 새 데이터를 읽는 예쩐 코드는 목록의 마지막 엘리먼트만 보게된다.

### Apache Avro

아브로는 직렬화 데이터 구조를 지정하기 위해 스키마를 사용한다.

2개의 스키마 언어가 있는데, 하나는 사람이 편집할 수 있는 아브로 IDL, 하나는 기계가 읽기 쉬운 JSON 기반 언어다

```
// 아브로 IDL
record Person {
	string	userName;
	union {null, long} favoriteNumber = null;
	array<string>	interests;
}

// 스키마
{
	"type" : "record",
	"name" : "Person",
	"fields" : [
		{ "name" : "userNAme", "type" : "string"}
	]
}
```

이 스키말를 이용해 직렬화하면 아브로 이진 직렬화 길이는 32바이트로 가장 짧다.

![image-20250329181300482](./images//image-20250329181300482.png)

* 바이트배열을 보면, 필드나 데이터 타입을 식별하기 위한 정보가 없다. 단순히 연결된 값으로 구성됌
* 정수는 가변길이 부호화를 사용해서 직렬화된다.

아브로를 이용해 파싱하려면, 스키마에 나타난 순서대로 필드를 살펴보고 스키마를 이용해 각 필드의 데이터 타입을 미리 파악해야 한다. 

즉, 정확히 같은 스키마를 사용하는 경우에만 올바르게 역직렬화 할 수 있다.

아브로는 어떻게 스키마 진화를 제공할까?



아브로는 쓰기 스키마와 읽기 스키마가 동일하지 않아도 호환 가능하면 처리할 수 있다.

* 쓰기스키마 : 직렬화 할때 
* 읽기 스키마 : 역직렬화 할때 

![image-20250329182106540](./images//image-20250329182106540.png)

필드 순서가 달라도, 이름으로 필드를 일치 스키고 읽는 코드가 읽기 스키마에는 없고 쓰기 스키마에만 존재한다면 이 필드를 무시해서 호환성을 유지한다. 그리고 읽을 때 어떤 필드가 비어있따면 디폴트 값으로 채운다. 



아브로에서 상위 호환성은 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음을 의미. 

하위 호환성은 새로운 버전의 읽기 스키마와 예전 버전의 쓰기 스키마를 가질 수 있음을 의미.



기본값이 없는 필드 추가시, 새걸 읽을때 이전 기록한 데이터를 읽을수 없어 하위 호환성이 깨지고

기본값이 없는 필드 삭제시, 이전껄 읽을 때 새 데이터를 읽을 수 없어서 상위 호환성이 깨짐.

때문에 union 타입이라는 복합 타입 체계를 이용해 기본값을 null로 사용하도록 함.

* null의 그나마 장점.. 
* union {null, long, string} field의 경우 수, 문자열, 널일수 있단 의미임

**Avro는 데이터를 쓸 때 사용한 "쓰기 스키마"를 데이터와 함께 저장하거나, 별도로 버전/ID로 관리.**
 왜냐하면, 데이터를 읽을 때는 **원래 쓰기 스키마**와 현재 **읽기 스키마**를 비교해서 해석해야 하기 때문 

### 동적 생성스키마

프로토 버퍼와 스리프트에 비해 아브로는 한가지 장점이 있음.

아브로는 스키마에 태그 번호가 포함돼있지 않음.

**ProtoBuf**나 **Thrift**는 **숫자 태그(필드 번호)**로 데이터를 식별.

그래서 **Avro는 데이터베이스처럼 구조가 자주 바뀌는 상황**에서 **자동으로 스키마를 만들고 써먹기 쉬움**

* 필드를 이름으로 식별하기 때문임.
* 프로토버퍼나 스리프트는 숫자 태그가 바뀌면 수동 갱신해야 하며 문제가 생김

| 항목             | Avro                  | Protobuf / Thrift   |
| ---------------- | --------------------- | ------------------- |
| 필드 식별        | 이름으로              | 숫자 태그로         |
| 스키마 변경 대응 | 쉬움 (자동화 가능)    | 어렵고 관리 필요    |
| 필드 추가/삭제   | 유연함                | 주의 깊은 관리 필요 |
| DB 스키마 → 변환 | 자동 생성 쉬움        | 태그 번호 지정 필요 |
| 설계 철학        | 동적 생성 스키마 고려 | 정적 IDL 기반 설계  |

## 데이터 플로 모드

